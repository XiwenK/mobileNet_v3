2022-11-20 16:04:26,882 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.15 (default, Oct 12 2022, 19:14:55) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla T4
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.2, V11.2.152
GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.6.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMClassification: 0.24.1+32f6e53
------------------------------------------------------------

2022-11-20 16:04:26,882 - mmcls - INFO - Distributed training: False
2022-11-20 16:04:26,988 - mmcls - INFO - Config:
model = dict(
    type='BSConvClassifier',
    backbone=dict(
        type='MobileNetV3Cifar', arch='large', conv_cfg=dict(type='BSConvS')),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='StackedLinearClsHeadWithPred',
        num_classes=10,
        in_channels=960,
        mid_channels=[1280],
        act_cfg=dict(type='HSwish'),
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),
        topk=(1, 5)),
    train_cfg=dict(augments=[
        dict(type='BatchCutMix', alpha=1.0, prob=0.5, num_classes=10)
    ]))
dataset_type = 'CIFAR10'
img_norm_cfg = dict(
    mean=[125.307, 122.961, 113.8575],
    std=[51.5865, 50.847, 51.255],
    to_rgb=False)
train_pipeline = [
    dict(type='RandomCrop', size=32, padding=4),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(
        type='Normalize',
        mean=[125.307, 122.961, 113.8575],
        std=[51.5865, 50.847, 51.255],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(
        type='Normalize',
        mean=[125.307, 122.961, 113.8575],
        std=[51.5865, 50.847, 51.255],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=128,
    workers_per_gpu=2,
    train=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(type='RandomCrop', size=32, padding=4),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True),
    test=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True))
optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[100, 150, 180])
runner = dict(type='EpochBasedRunner', max_epochs=200)
checkpoint_config = dict(interval=10, max_keep_ckpts=1)
log_config = dict(
    interval=100,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
work_dir = './work_dirs/1.cifar10_data_with_bsconv'
gpu_ids = [0]

2022-11-20 16:04:26,988 - mmcls - INFO - Set random seed to 418194888, deterministic: False
2022-11-20 16:04:27,083 - mmcls - INFO - initialize MobileNetV3Cifar with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d'], 'nonlinearity': 'leaky_relu'}, {'type': 'Normal', 'layer': ['Linear'], 'std': 0.01}, {'type': 'Constant', 'layer': ['BatchNorm2d'], 'val': 1}]
Name of parameter - Initialization information

backbone.layer0.conv.weight - torch.Size([16, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.depthwise_conv.conv.weight - torch.Size([16, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.depthwise_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.depthwise_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.linear_conv.conv.pw1.weight - torch.Size([4, 16, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.conv.pw2.weight - torch.Size([16, 4, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.conv.dw.weight - torch.Size([16, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.expand_conv.conv.weight - torch.Size([64, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.expand_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.expand_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.depthwise_conv.conv.weight - torch.Size([64, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.depthwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.depthwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.linear_conv.conv.pw1.weight - torch.Size([16, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.conv.pw2.weight - torch.Size([24, 16, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.conv.dw.weight - torch.Size([24, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.expand_conv.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.depthwise_conv.conv.weight - torch.Size([72, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.linear_conv.conv.pw1.weight - torch.Size([18, 72, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.conv.pw2.weight - torch.Size([24, 18, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.conv.dw.weight - torch.Size([24, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.expand_conv.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.depthwise_conv.conv.weight - torch.Size([72, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.se.conv1.conv.weight - torch.Size([24, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv1.conv.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.se.conv2.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv2.conv.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.linear_conv.conv.pw1.weight - torch.Size([18, 72, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.conv.pw2.weight - torch.Size([40, 18, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.linear_conv.conv.pw1.weight - torch.Size([30, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.conv.pw2.weight - torch.Size([40, 30, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.linear_conv.conv.pw1.weight - torch.Size([30, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.conv.pw2.weight - torch.Size([40, 30, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.depthwise_conv.conv.weight - torch.Size([240, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.linear_conv.conv.pw1.weight - torch.Size([60, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.conv.pw2.weight - torch.Size([80, 60, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.expand_conv.conv.weight - torch.Size([200, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.expand_conv.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.expand_conv.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.depthwise_conv.conv.weight - torch.Size([200, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.depthwise_conv.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.depthwise_conv.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.linear_conv.conv.pw1.weight - torch.Size([50, 200, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.conv.pw2.weight - torch.Size([80, 50, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.expand_conv.conv.weight - torch.Size([184, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.expand_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.expand_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.depthwise_conv.conv.weight - torch.Size([184, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.depthwise_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.depthwise_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.linear_conv.conv.pw1.weight - torch.Size([46, 184, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.conv.pw2.weight - torch.Size([80, 46, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.expand_conv.conv.weight - torch.Size([184, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.expand_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.expand_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.depthwise_conv.conv.weight - torch.Size([184, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.depthwise_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.depthwise_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.linear_conv.conv.pw1.weight - torch.Size([46, 184, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.conv.pw2.weight - torch.Size([80, 46, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.expand_conv.conv.weight - torch.Size([480, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.expand_conv.bn.weight - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.expand_conv.bn.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.depthwise_conv.conv.weight - torch.Size([480, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.depthwise_conv.bn.weight - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.depthwise_conv.bn.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.se.conv1.conv.weight - torch.Size([120, 480, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv1.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.se.conv2.conv.weight - torch.Size([480, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv2.conv.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.linear_conv.conv.pw1.weight - torch.Size([120, 480, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.conv.pw2.weight - torch.Size([112, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.conv.dw.weight - torch.Size([112, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.bn.weight - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.linear_conv.bn.bias - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.expand_conv.conv.weight - torch.Size([672, 112, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.expand_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.expand_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.depthwise_conv.conv.weight - torch.Size([672, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.depthwise_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.depthwise_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.se.conv1.conv.weight - torch.Size([168, 672, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.se.conv1.conv.bias - torch.Size([168]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.se.conv2.conv.weight - torch.Size([672, 168, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.se.conv2.conv.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.linear_conv.conv.pw1.weight - torch.Size([168, 672, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.conv.pw2.weight - torch.Size([112, 168, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.conv.dw.weight - torch.Size([112, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.bn.weight - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.linear_conv.bn.bias - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.expand_conv.conv.weight - torch.Size([672, 112, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.expand_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.expand_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.depthwise_conv.conv.weight - torch.Size([672, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.depthwise_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.depthwise_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.se.conv1.conv.weight - torch.Size([168, 672, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.se.conv1.conv.bias - torch.Size([168]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.se.conv2.conv.weight - torch.Size([672, 168, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.se.conv2.conv.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.linear_conv.conv.pw1.weight - torch.Size([168, 672, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.conv.pw2.weight - torch.Size([160, 168, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.expand_conv.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.expand_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.expand_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.depthwise_conv.conv.weight - torch.Size([960, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.depthwise_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.depthwise_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.se.conv1.conv.weight - torch.Size([240, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.se.conv1.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.se.conv2.conv.weight - torch.Size([960, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.se.conv2.conv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.linear_conv.conv.pw1.weight - torch.Size([240, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.conv.pw2.weight - torch.Size([160, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.expand_conv.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.expand_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.expand_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.depthwise_conv.conv.weight - torch.Size([960, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.depthwise_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.depthwise_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.se.conv1.conv.weight - torch.Size([240, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.se.conv1.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.se.conv2.conv.weight - torch.Size([960, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.se.conv2.conv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.linear_conv.conv.pw1.weight - torch.Size([240, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.conv.pw2.weight - torch.Size([160, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer16.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer16.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer16.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.0.fc.weight - torch.Size([1280, 960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.0.fc.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.1.fc.weight - torch.Size([10, 1280]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.1.fc.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  
2022-11-20 16:04:30,754 - mmcls - INFO - Start running, host: root@6858a3a9595d, work_dir: /content/drive/MyDrive/mobilenet_v3_final/work_dirs/1.cifar10_data_with_bsconv
2022-11-20 16:04:30,754 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) TrainsetEvalHook                   
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) TrainsetEvalHook                   
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2022-11-20 16:04:30,755 - mmcls - INFO - workflow: [('train', 1)], max: 200 epochs
2022-11-20 16:04:30,755 - mmcls - INFO - Checkpoints will be saved to /content/drive/MyDrive/mobilenet_v3_final/work_dirs/1.cifar10_data_with_bsconv by HardDiskBackend.
2022-11-20 16:04:48,418 - mmcls - INFO - Epoch [1][100/391]	lr: 1.000e-01, eta: 3:20:36, time: 0.154, data_time: 0.029, memory: 1588, loss: 2.0757
2022-11-20 16:04:59,172 - mmcls - INFO - Epoch [1][200/391]	lr: 1.000e-01, eta: 2:50:04, time: 0.108, data_time: 0.001, memory: 1588, loss: 1.8575
2022-11-20 16:05:09,966 - mmcls - INFO - Epoch [1][300/391]	lr: 1.000e-01, eta: 2:39:56, time: 0.108, data_time: 0.001, memory: 1588, loss: 1.6790
2022-11-20 16:05:22,898 - mmcls - INFO - Epoch(val) [1][79]	train_accuracy: 35.9060, accuracy_top-1: 10.0000, accuracy_top-5: 50.0000
2022-11-20 16:05:35,979 - mmcls - INFO - Epoch [2][100/391]	lr: 1.000e-01, eta: 2:11:53, time: 0.130, data_time: 0.021, memory: 1588, loss: 1.6098
2022-11-20 16:05:47,021 - mmcls - INFO - Epoch [2][200/391]	lr: 1.000e-01, eta: 2:13:36, time: 0.110, data_time: 0.001, memory: 1588, loss: 1.4991
2022-11-20 16:05:58,244 - mmcls - INFO - Epoch [2][300/391]	lr: 1.000e-01, eta: 2:15:08, time: 0.112, data_time: 0.001, memory: 1588, loss: 1.3887
2022-11-20 16:06:11,378 - mmcls - INFO - Epoch(val) [2][79]	train_accuracy: 51.7020, accuracy_top-1: 26.7000, accuracy_top-5: 86.3700
2022-11-20 16:06:24,591 - mmcls - INFO - Epoch [3][100/391]	lr: 1.000e-01, eta: 2:04:52, time: 0.132, data_time: 0.021, memory: 1588, loss: 1.4112
2022-11-20 16:06:35,654 - mmcls - INFO - Epoch [3][200/391]	lr: 1.000e-01, eta: 2:06:30, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.3741
2022-11-20 16:06:46,731 - mmcls - INFO - Epoch [3][300/391]	lr: 1.000e-01, eta: 2:07:49, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.2705
2022-11-20 16:06:59,776 - mmcls - INFO - Epoch(val) [3][79]	train_accuracy: 57.3920, accuracy_top-1: 42.9900, accuracy_top-5: 92.5100
2022-11-20 16:07:12,967 - mmcls - INFO - Epoch [4][100/391]	lr: 1.000e-01, eta: 2:01:37, time: 0.132, data_time: 0.021, memory: 1588, loss: 1.2779
2022-11-20 16:07:24,072 - mmcls - INFO - Epoch [4][200/391]	lr: 1.000e-01, eta: 2:02:58, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.2684
2022-11-20 16:07:35,168 - mmcls - INFO - Epoch [4][300/391]	lr: 1.000e-01, eta: 2:04:06, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.2232
2022-11-20 16:07:48,197 - mmcls - INFO - Epoch(val) [4][79]	train_accuracy: 60.3540, accuracy_top-1: 29.4600, accuracy_top-5: 74.0500
2022-11-20 16:08:01,384 - mmcls - INFO - Epoch [5][100/391]	lr: 1.000e-01, eta: 1:59:40, time: 0.132, data_time: 0.021, memory: 1588, loss: 1.2025
2022-11-20 16:08:12,436 - mmcls - INFO - Epoch [5][200/391]	lr: 1.000e-01, eta: 2:00:43, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.2076
2022-11-20 16:08:23,475 - mmcls - INFO - Epoch [5][300/391]	lr: 1.000e-01, eta: 2:01:37, time: 0.110, data_time: 0.001, memory: 1588, loss: 1.1697
2022-11-20 16:08:36,531 - mmcls - INFO - Epoch(val) [5][79]	train_accuracy: 64.6980, accuracy_top-1: 71.5800, accuracy_top-5: 97.2500
2022-11-20 16:08:49,713 - mmcls - INFO - Epoch [6][100/391]	lr: 1.000e-01, eta: 1:58:10, time: 0.131, data_time: 0.021, memory: 1588, loss: 1.0269
2022-11-20 16:09:00,811 - mmcls - INFO - Epoch [6][200/391]	lr: 1.000e-01, eta: 1:59:03, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.1248
2022-11-20 16:09:11,915 - mmcls - INFO - Epoch [6][300/391]	lr: 1.000e-01, eta: 1:59:52, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.1178
2022-11-20 16:09:24,962 - mmcls - INFO - Epoch(val) [6][79]	train_accuracy: 67.3620, accuracy_top-1: 77.4500, accuracy_top-5: 98.6200
2022-11-20 16:09:38,128 - mmcls - INFO - Epoch [7][100/391]	lr: 1.000e-01, eta: 1:57:00, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.9636
2022-11-20 16:09:49,199 - mmcls - INFO - Epoch [7][200/391]	lr: 1.000e-01, eta: 1:57:44, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.1099
2022-11-20 16:10:00,286 - mmcls - INFO - Epoch [7][300/391]	lr: 1.000e-01, eta: 1:58:25, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.0298
2022-11-20 16:10:13,245 - mmcls - INFO - Epoch(val) [7][79]	train_accuracy: 70.1040, accuracy_top-1: 64.6400, accuracy_top-5: 95.9000
2022-11-20 16:10:26,401 - mmcls - INFO - Epoch [8][100/391]	lr: 1.000e-01, eta: 1:55:58, time: 0.131, data_time: 0.021, memory: 1588, loss: 1.0009
2022-11-20 16:10:37,462 - mmcls - INFO - Epoch [8][200/391]	lr: 1.000e-01, eta: 1:56:36, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.0365
2022-11-20 16:10:48,522 - mmcls - INFO - Epoch [8][300/391]	lr: 1.000e-01, eta: 1:57:10, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.0391
2022-11-20 16:11:01,765 - mmcls - INFO - Epoch(val) [8][79]	train_accuracy: 69.7220, accuracy_top-1: 75.0500, accuracy_top-5: 97.7700
2022-11-20 16:11:14,982 - mmcls - INFO - Epoch [9][100/391]	lr: 1.000e-01, eta: 1:55:04, time: 0.132, data_time: 0.021, memory: 1588, loss: 1.0287
2022-11-20 16:11:26,039 - mmcls - INFO - Epoch [9][200/391]	lr: 1.000e-01, eta: 1:55:36, time: 0.111, data_time: 0.001, memory: 1588, loss: 1.0079
2022-11-20 16:11:37,138 - mmcls - INFO - Epoch [9][300/391]	lr: 1.000e-01, eta: 1:56:07, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9873
2022-11-20 16:11:50,345 - mmcls - INFO - Epoch(val) [9][79]	train_accuracy: 70.8740, accuracy_top-1: 79.2900, accuracy_top-5: 99.0200
2022-11-20 16:12:03,546 - mmcls - INFO - Epoch [10][100/391]	lr: 1.000e-01, eta: 1:54:13, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.9759
2022-11-20 16:12:14,596 - mmcls - INFO - Epoch [10][200/391]	lr: 1.000e-01, eta: 1:54:41, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.9893
2022-11-20 16:12:25,641 - mmcls - INFO - Epoch [10][300/391]	lr: 1.000e-01, eta: 1:55:07, time: 0.110, data_time: 0.001, memory: 1588, loss: 1.0346
2022-11-20 16:12:35,645 - mmcls - INFO - Saving checkpoint at 10 epochs
2022-11-20 16:12:38,829 - mmcls - INFO - Epoch(val) [10][79]	train_accuracy: 71.6360, accuracy_top-1: 65.1800, accuracy_top-5: 97.4600
2022-11-20 16:12:52,036 - mmcls - INFO - Epoch [11][100/391]	lr: 1.000e-01, eta: 1:53:25, time: 0.132, data_time: 0.021, memory: 1588, loss: 1.0074
2022-11-20 16:13:03,092 - mmcls - INFO - Epoch [11][200/391]	lr: 1.000e-01, eta: 1:53:50, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9589
2022-11-20 16:13:14,163 - mmcls - INFO - Epoch [11][300/391]	lr: 1.000e-01, eta: 1:54:13, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9139
2022-11-20 16:13:27,179 - mmcls - INFO - Epoch(val) [11][79]	train_accuracy: 71.9360, accuracy_top-1: 79.1100, accuracy_top-5: 98.4700
2022-11-20 16:13:40,376 - mmcls - INFO - Epoch [12][100/391]	lr: 1.000e-01, eta: 1:52:39, time: 0.132, data_time: 0.021, memory: 1588, loss: 1.0369
2022-11-20 16:13:51,428 - mmcls - INFO - Epoch [12][200/391]	lr: 1.000e-01, eta: 1:53:01, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9996
2022-11-20 16:14:02,533 - mmcls - INFO - Epoch [12][300/391]	lr: 1.000e-01, eta: 1:53:23, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9515
2022-11-20 16:14:15,514 - mmcls - INFO - Epoch(val) [12][79]	train_accuracy: 72.3100, accuracy_top-1: 73.3300, accuracy_top-5: 97.9200
2022-11-20 16:14:28,699 - mmcls - INFO - Epoch [13][100/391]	lr: 1.000e-01, eta: 1:51:56, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.9577
2022-11-20 16:14:39,766 - mmcls - INFO - Epoch [13][200/391]	lr: 1.000e-01, eta: 1:52:15, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9817
2022-11-20 16:14:50,824 - mmcls - INFO - Epoch [13][300/391]	lr: 1.000e-01, eta: 1:52:34, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8983
2022-11-20 16:15:03,769 - mmcls - INFO - Epoch(val) [13][79]	train_accuracy: 72.4360, accuracy_top-1: 74.2800, accuracy_top-5: 98.0600
2022-11-20 16:15:16,957 - mmcls - INFO - Epoch [14][100/391]	lr: 1.000e-01, eta: 1:51:13, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.9496
2022-11-20 16:15:28,018 - mmcls - INFO - Epoch [14][200/391]	lr: 1.000e-01, eta: 1:51:30, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8506
2022-11-20 16:15:39,053 - mmcls - INFO - Epoch [14][300/391]	lr: 1.000e-01, eta: 1:51:46, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8817
2022-11-20 16:15:52,119 - mmcls - INFO - Epoch(val) [14][79]	train_accuracy: 74.8880, accuracy_top-1: 76.0300, accuracy_top-5: 97.8500
2022-11-20 16:16:05,312 - mmcls - INFO - Epoch [15][100/391]	lr: 1.000e-01, eta: 1:50:31, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.9636
2022-11-20 16:16:16,352 - mmcls - INFO - Epoch [15][200/391]	lr: 1.000e-01, eta: 1:50:46, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.9525
2022-11-20 16:16:27,396 - mmcls - INFO - Epoch [15][300/391]	lr: 1.000e-01, eta: 1:51:01, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.9084
2022-11-20 16:16:40,290 - mmcls - INFO - Epoch(val) [15][79]	train_accuracy: 73.3320, accuracy_top-1: 79.6900, accuracy_top-5: 98.7300
2022-11-20 16:16:53,458 - mmcls - INFO - Epoch [16][100/391]	lr: 1.000e-01, eta: 1:49:49, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8452
2022-11-20 16:17:04,539 - mmcls - INFO - Epoch [16][200/391]	lr: 1.000e-01, eta: 1:50:04, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9958
2022-11-20 16:17:15,613 - mmcls - INFO - Epoch [16][300/391]	lr: 1.000e-01, eta: 1:50:17, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9960
2022-11-20 16:17:28,450 - mmcls - INFO - Epoch(val) [16][79]	train_accuracy: 73.7980, accuracy_top-1: 81.1700, accuracy_top-5: 98.9000
2022-11-20 16:17:41,806 - mmcls - INFO - Epoch [17][100/391]	lr: 1.000e-01, eta: 1:49:12, time: 0.133, data_time: 0.021, memory: 1588, loss: 0.9389
2022-11-20 16:17:52,860 - mmcls - INFO - Epoch [17][200/391]	lr: 1.000e-01, eta: 1:49:24, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9557
2022-11-20 16:18:03,942 - mmcls - INFO - Epoch [17][300/391]	lr: 1.000e-01, eta: 1:49:36, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8964
2022-11-20 16:18:16,930 - mmcls - INFO - Epoch(val) [17][79]	train_accuracy: 72.7800, accuracy_top-1: 77.6500, accuracy_top-5: 98.5200
2022-11-20 16:18:30,085 - mmcls - INFO - Epoch [18][100/391]	lr: 1.000e-01, eta: 1:48:32, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.9397
2022-11-20 16:18:41,119 - mmcls - INFO - Epoch [18][200/391]	lr: 1.000e-01, eta: 1:48:42, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.9085
2022-11-20 16:18:52,175 - mmcls - INFO - Epoch [18][300/391]	lr: 1.000e-01, eta: 1:48:53, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9619
2022-11-20 16:19:05,090 - mmcls - INFO - Epoch(val) [18][79]	train_accuracy: 74.2160, accuracy_top-1: 79.6300, accuracy_top-5: 98.3800
2022-11-20 16:19:18,309 - mmcls - INFO - Epoch [19][100/391]	lr: 1.000e-01, eta: 1:47:52, time: 0.132, data_time: 0.021, memory: 1588, loss: 1.0165
2022-11-20 16:19:29,362 - mmcls - INFO - Epoch [19][200/391]	lr: 1.000e-01, eta: 1:48:02, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8008
2022-11-20 16:19:40,427 - mmcls - INFO - Epoch [19][300/391]	lr: 1.000e-01, eta: 1:48:12, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9126
2022-11-20 16:19:53,286 - mmcls - INFO - Epoch(val) [19][79]	train_accuracy: 74.3120, accuracy_top-1: 76.8800, accuracy_top-5: 98.6000
2022-11-20 16:20:06,475 - mmcls - INFO - Epoch [20][100/391]	lr: 1.000e-01, eta: 1:47:13, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.9089
2022-11-20 16:20:17,539 - mmcls - INFO - Epoch [20][200/391]	lr: 1.000e-01, eta: 1:47:23, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8510
2022-11-20 16:20:28,612 - mmcls - INFO - Epoch [20][300/391]	lr: 1.000e-01, eta: 1:47:31, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8630
2022-11-20 16:20:38,648 - mmcls - INFO - Saving checkpoint at 20 epochs
2022-11-20 16:20:41,709 - mmcls - INFO - Epoch(val) [20][79]	train_accuracy: 75.6400, accuracy_top-1: 79.7400, accuracy_top-5: 98.8900
2022-11-20 16:20:54,943 - mmcls - INFO - Epoch [21][100/391]	lr: 1.000e-01, eta: 1:46:36, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.8513
2022-11-20 16:21:06,026 - mmcls - INFO - Epoch [21][200/391]	lr: 1.000e-01, eta: 1:46:44, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8592
2022-11-20 16:21:17,088 - mmcls - INFO - Epoch [21][300/391]	lr: 1.000e-01, eta: 1:46:51, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.9014
2022-11-20 16:21:29,997 - mmcls - INFO - Epoch(val) [21][79]	train_accuracy: 74.8180, accuracy_top-1: 79.1400, accuracy_top-5: 98.9600
2022-11-20 16:21:43,188 - mmcls - INFO - Epoch [22][100/391]	lr: 1.000e-01, eta: 1:45:58, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.8500
2022-11-20 16:21:54,258 - mmcls - INFO - Epoch [22][200/391]	lr: 1.000e-01, eta: 1:46:05, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8973
2022-11-20 16:22:05,365 - mmcls - INFO - Epoch [22][300/391]	lr: 1.000e-01, eta: 1:46:12, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8363
2022-11-20 16:22:18,373 - mmcls - INFO - Epoch(val) [22][79]	train_accuracy: 76.3740, accuracy_top-1: 82.6000, accuracy_top-5: 99.1100
2022-11-20 16:22:31,525 - mmcls - INFO - Epoch [23][100/391]	lr: 1.000e-01, eta: 1:45:20, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8622
2022-11-20 16:22:42,576 - mmcls - INFO - Epoch [23][200/391]	lr: 1.000e-01, eta: 1:45:26, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8133
2022-11-20 16:22:53,615 - mmcls - INFO - Epoch [23][300/391]	lr: 1.000e-01, eta: 1:45:32, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8076
2022-11-20 16:23:06,651 - mmcls - INFO - Epoch(val) [23][79]	train_accuracy: 76.6140, accuracy_top-1: 80.0400, accuracy_top-5: 98.7000
2022-11-20 16:23:19,803 - mmcls - INFO - Epoch [24][100/391]	lr: 1.000e-01, eta: 1:44:42, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.9600
2022-11-20 16:23:30,835 - mmcls - INFO - Epoch [24][200/391]	lr: 1.000e-01, eta: 1:44:47, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8977
2022-11-20 16:23:41,868 - mmcls - INFO - Epoch [24][300/391]	lr: 1.000e-01, eta: 1:44:52, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7837
2022-11-20 16:23:54,653 - mmcls - INFO - Epoch(val) [24][79]	train_accuracy: 75.2780, accuracy_top-1: 79.0000, accuracy_top-5: 98.3200
2022-11-20 16:24:07,849 - mmcls - INFO - Epoch [25][100/391]	lr: 1.000e-01, eta: 1:44:04, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.8715
2022-11-20 16:24:18,889 - mmcls - INFO - Epoch [25][200/391]	lr: 1.000e-01, eta: 1:44:09, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8968
2022-11-20 16:24:29,926 - mmcls - INFO - Epoch [25][300/391]	lr: 1.000e-01, eta: 1:44:13, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8552
2022-11-20 16:24:43,025 - mmcls - INFO - Epoch(val) [25][79]	train_accuracy: 75.5380, accuracy_top-1: 82.9600, accuracy_top-5: 99.0400
2022-11-20 16:24:56,181 - mmcls - INFO - Epoch [26][100/391]	lr: 1.000e-01, eta: 1:43:26, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.9076
2022-11-20 16:25:07,204 - mmcls - INFO - Epoch [26][200/391]	lr: 1.000e-01, eta: 1:43:30, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8056
2022-11-20 16:25:18,240 - mmcls - INFO - Epoch [26][300/391]	lr: 1.000e-01, eta: 1:43:34, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8443
2022-11-20 16:25:31,180 - mmcls - INFO - Epoch(val) [26][79]	train_accuracy: 76.6100, accuracy_top-1: 75.7300, accuracy_top-5: 98.4100
2022-11-20 16:25:44,326 - mmcls - INFO - Epoch [27][100/391]	lr: 1.000e-01, eta: 1:42:48, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8509
2022-11-20 16:25:55,374 - mmcls - INFO - Epoch [27][200/391]	lr: 1.000e-01, eta: 1:42:52, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8113
2022-11-20 16:26:06,426 - mmcls - INFO - Epoch [27][300/391]	lr: 1.000e-01, eta: 1:42:55, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7510
2022-11-20 16:26:19,274 - mmcls - INFO - Epoch(val) [27][79]	train_accuracy: 77.3320, accuracy_top-1: 73.8600, accuracy_top-5: 98.0300
2022-11-20 16:26:32,433 - mmcls - INFO - Epoch [28][100/391]	lr: 1.000e-01, eta: 1:42:11, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.9372
2022-11-20 16:26:43,463 - mmcls - INFO - Epoch [28][200/391]	lr: 1.000e-01, eta: 1:42:14, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8695
2022-11-20 16:26:54,505 - mmcls - INFO - Epoch [28][300/391]	lr: 1.000e-01, eta: 1:42:17, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8497
2022-11-20 16:27:07,484 - mmcls - INFO - Epoch(val) [28][79]	train_accuracy: 75.5880, accuracy_top-1: 74.6600, accuracy_top-5: 96.3400
2022-11-20 16:27:20,661 - mmcls - INFO - Epoch [29][100/391]	lr: 1.000e-01, eta: 1:41:34, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8568
2022-11-20 16:27:31,686 - mmcls - INFO - Epoch [29][200/391]	lr: 1.000e-01, eta: 1:41:36, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7935
2022-11-20 16:27:42,728 - mmcls - INFO - Epoch [29][300/391]	lr: 1.000e-01, eta: 1:41:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.9196
2022-11-20 16:27:55,752 - mmcls - INFO - Epoch(val) [29][79]	train_accuracy: 75.6820, accuracy_top-1: 80.6700, accuracy_top-5: 98.6700
2022-11-20 16:28:08,981 - mmcls - INFO - Epoch [30][100/391]	lr: 1.000e-01, eta: 1:40:57, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.8581
2022-11-20 16:28:20,041 - mmcls - INFO - Epoch [30][200/391]	lr: 1.000e-01, eta: 1:40:59, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8161
2022-11-20 16:28:31,103 - mmcls - INFO - Epoch [30][300/391]	lr: 1.000e-01, eta: 1:41:01, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8205
2022-11-20 16:28:41,123 - mmcls - INFO - Saving checkpoint at 30 epochs
2022-11-20 16:28:44,193 - mmcls - INFO - Epoch(val) [30][79]	train_accuracy: 77.1160, accuracy_top-1: 83.1000, accuracy_top-5: 99.0700
2022-11-20 16:28:57,369 - mmcls - INFO - Epoch [31][100/391]	lr: 1.000e-01, eta: 1:40:20, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8074
2022-11-20 16:29:08,427 - mmcls - INFO - Epoch [31][200/391]	lr: 1.000e-01, eta: 1:40:22, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7910
2022-11-20 16:29:19,460 - mmcls - INFO - Epoch [31][300/391]	lr: 1.000e-01, eta: 1:40:24, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8293
2022-11-20 16:29:32,339 - mmcls - INFO - Epoch(val) [31][79]	train_accuracy: 77.7080, accuracy_top-1: 79.6400, accuracy_top-5: 98.8500
2022-11-20 16:29:45,514 - mmcls - INFO - Epoch [32][100/391]	lr: 1.000e-01, eta: 1:39:43, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8486
2022-11-20 16:29:56,551 - mmcls - INFO - Epoch [32][200/391]	lr: 1.000e-01, eta: 1:39:45, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8665
2022-11-20 16:30:07,604 - mmcls - INFO - Epoch [32][300/391]	lr: 1.000e-01, eta: 1:39:46, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7890
2022-11-20 16:30:20,635 - mmcls - INFO - Epoch(val) [32][79]	train_accuracy: 77.1420, accuracy_top-1: 79.7500, accuracy_top-5: 98.7000
2022-11-20 16:30:33,829 - mmcls - INFO - Epoch [33][100/391]	lr: 1.000e-01, eta: 1:39:07, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.7932
2022-11-20 16:30:44,879 - mmcls - INFO - Epoch [33][200/391]	lr: 1.000e-01, eta: 1:39:08, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7959
2022-11-20 16:30:55,966 - mmcls - INFO - Epoch [33][300/391]	lr: 1.000e-01, eta: 1:39:09, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8584
2022-11-20 16:31:08,999 - mmcls - INFO - Epoch(val) [33][79]	train_accuracy: 76.9880, accuracy_top-1: 81.3400, accuracy_top-5: 99.2200
2022-11-20 16:31:22,197 - mmcls - INFO - Epoch [34][100/391]	lr: 1.000e-01, eta: 1:38:31, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.8452
2022-11-20 16:31:33,234 - mmcls - INFO - Epoch [34][200/391]	lr: 1.000e-01, eta: 1:38:31, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8077
2022-11-20 16:31:44,271 - mmcls - INFO - Epoch [34][300/391]	lr: 1.000e-01, eta: 1:38:32, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7848
2022-11-20 16:31:57,266 - mmcls - INFO - Epoch(val) [34][79]	train_accuracy: 77.6280, accuracy_top-1: 81.7800, accuracy_top-5: 98.8200
2022-11-20 16:32:10,452 - mmcls - INFO - Epoch [35][100/391]	lr: 1.000e-01, eta: 1:37:54, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.7918
2022-11-20 16:32:21,493 - mmcls - INFO - Epoch [35][200/391]	lr: 1.000e-01, eta: 1:37:54, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.9003
2022-11-20 16:32:32,537 - mmcls - INFO - Epoch [35][300/391]	lr: 1.000e-01, eta: 1:37:55, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8933
2022-11-20 16:32:45,555 - mmcls - INFO - Epoch(val) [35][79]	train_accuracy: 76.9860, accuracy_top-1: 77.7800, accuracy_top-5: 98.6400
2022-11-20 16:32:58,751 - mmcls - INFO - Epoch [36][100/391]	lr: 1.000e-01, eta: 1:37:18, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.8499
2022-11-20 16:33:09,792 - mmcls - INFO - Epoch [36][200/391]	lr: 1.000e-01, eta: 1:37:18, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8350
2022-11-20 16:33:20,829 - mmcls - INFO - Epoch [36][300/391]	lr: 1.000e-01, eta: 1:37:18, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7713
2022-11-20 16:33:33,672 - mmcls - INFO - Epoch(val) [36][79]	train_accuracy: 77.4640, accuracy_top-1: 78.6500, accuracy_top-5: 98.5700
2022-11-20 16:33:46,831 - mmcls - INFO - Epoch [37][100/391]	lr: 1.000e-01, eta: 1:36:41, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8107
2022-11-20 16:33:57,941 - mmcls - INFO - Epoch [37][200/391]	lr: 1.000e-01, eta: 1:36:41, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8785
2022-11-20 16:34:09,048 - mmcls - INFO - Epoch [37][300/391]	lr: 1.000e-01, eta: 1:36:41, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7800
2022-11-20 16:34:22,104 - mmcls - INFO - Epoch(val) [37][79]	train_accuracy: 77.3400, accuracy_top-1: 82.2100, accuracy_top-5: 98.7600
2022-11-20 16:34:35,305 - mmcls - INFO - Epoch [38][100/391]	lr: 1.000e-01, eta: 1:36:05, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7686
2022-11-20 16:34:46,356 - mmcls - INFO - Epoch [38][200/391]	lr: 1.000e-01, eta: 1:36:05, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8266
2022-11-20 16:34:57,398 - mmcls - INFO - Epoch [38][300/391]	lr: 1.000e-01, eta: 1:36:04, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7709
2022-11-20 16:35:10,358 - mmcls - INFO - Epoch(val) [38][79]	train_accuracy: 77.5940, accuracy_top-1: 80.0300, accuracy_top-5: 98.8100
2022-11-20 16:35:23,529 - mmcls - INFO - Epoch [39][100/391]	lr: 1.000e-01, eta: 1:35:29, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7768
2022-11-20 16:35:34,554 - mmcls - INFO - Epoch [39][200/391]	lr: 1.000e-01, eta: 1:35:28, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7658
2022-11-20 16:35:45,621 - mmcls - INFO - Epoch [39][300/391]	lr: 1.000e-01, eta: 1:35:28, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7427
2022-11-20 16:35:58,521 - mmcls - INFO - Epoch(val) [39][79]	train_accuracy: 78.2140, accuracy_top-1: 81.6600, accuracy_top-5: 98.8100
2022-11-20 16:36:11,700 - mmcls - INFO - Epoch [40][100/391]	lr: 1.000e-01, eta: 1:34:53, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8507
2022-11-20 16:36:22,737 - mmcls - INFO - Epoch [40][200/391]	lr: 1.000e-01, eta: 1:34:52, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8101
2022-11-20 16:36:33,761 - mmcls - INFO - Epoch [40][300/391]	lr: 1.000e-01, eta: 1:34:51, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8431
2022-11-20 16:36:43,804 - mmcls - INFO - Saving checkpoint at 40 epochs
2022-11-20 16:36:46,991 - mmcls - INFO - Epoch(val) [40][79]	train_accuracy: 77.3740, accuracy_top-1: 77.8700, accuracy_top-5: 98.5400
2022-11-20 16:37:00,188 - mmcls - INFO - Epoch [41][100/391]	lr: 1.000e-01, eta: 1:34:17, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.8361
2022-11-20 16:37:11,257 - mmcls - INFO - Epoch [41][200/391]	lr: 1.000e-01, eta: 1:34:16, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8746
2022-11-20 16:37:22,299 - mmcls - INFO - Epoch [41][300/391]	lr: 1.000e-01, eta: 1:34:14, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7686
2022-11-20 16:37:35,113 - mmcls - INFO - Epoch(val) [41][79]	train_accuracy: 77.1780, accuracy_top-1: 79.9600, accuracy_top-5: 98.9500
2022-11-20 16:37:48,259 - mmcls - INFO - Epoch [42][100/391]	lr: 1.000e-01, eta: 1:33:41, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8574
2022-11-20 16:37:59,286 - mmcls - INFO - Epoch [42][200/391]	lr: 1.000e-01, eta: 1:33:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7449
2022-11-20 16:38:10,329 - mmcls - INFO - Epoch [42][300/391]	lr: 1.000e-01, eta: 1:33:37, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.9035
2022-11-20 16:38:23,271 - mmcls - INFO - Epoch(val) [42][79]	train_accuracy: 77.5800, accuracy_top-1: 81.8600, accuracy_top-5: 99.0800
2022-11-20 16:38:36,437 - mmcls - INFO - Epoch [43][100/391]	lr: 1.000e-01, eta: 1:33:04, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8860
2022-11-20 16:38:47,471 - mmcls - INFO - Epoch [43][200/391]	lr: 1.000e-01, eta: 1:33:03, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.9040
2022-11-20 16:38:58,516 - mmcls - INFO - Epoch [43][300/391]	lr: 1.000e-01, eta: 1:33:01, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8548
2022-11-20 16:39:11,498 - mmcls - INFO - Epoch(val) [43][79]	train_accuracy: 77.2760, accuracy_top-1: 81.1000, accuracy_top-5: 98.6700
2022-11-20 16:39:24,692 - mmcls - INFO - Epoch [44][100/391]	lr: 1.000e-01, eta: 1:32:28, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.8831
2022-11-20 16:39:35,753 - mmcls - INFO - Epoch [44][200/391]	lr: 1.000e-01, eta: 1:32:27, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8071
2022-11-20 16:39:46,818 - mmcls - INFO - Epoch [44][300/391]	lr: 1.000e-01, eta: 1:32:25, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7730
2022-11-20 16:39:59,685 - mmcls - INFO - Epoch(val) [44][79]	train_accuracy: 78.2080, accuracy_top-1: 74.8600, accuracy_top-5: 97.8600
2022-11-20 16:40:12,869 - mmcls - INFO - Epoch [45][100/391]	lr: 1.000e-01, eta: 1:31:53, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7771
2022-11-20 16:40:23,922 - mmcls - INFO - Epoch [45][200/391]	lr: 1.000e-01, eta: 1:31:50, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8028
2022-11-20 16:40:34,986 - mmcls - INFO - Epoch [45][300/391]	lr: 1.000e-01, eta: 1:31:48, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8458
2022-11-20 16:40:48,043 - mmcls - INFO - Epoch(val) [45][79]	train_accuracy: 78.6660, accuracy_top-1: 77.3200, accuracy_top-5: 98.0100
2022-11-20 16:41:01,200 - mmcls - INFO - Epoch [46][100/391]	lr: 1.000e-01, eta: 1:31:17, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8521
2022-11-20 16:41:12,220 - mmcls - INFO - Epoch [46][200/391]	lr: 1.000e-01, eta: 1:31:14, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7648
2022-11-20 16:41:23,302 - mmcls - INFO - Epoch [46][300/391]	lr: 1.000e-01, eta: 1:31:12, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7680
2022-11-20 16:41:36,321 - mmcls - INFO - Epoch(val) [46][79]	train_accuracy: 78.7920, accuracy_top-1: 83.4800, accuracy_top-5: 99.2600
2022-11-20 16:41:49,492 - mmcls - INFO - Epoch [47][100/391]	lr: 1.000e-01, eta: 1:30:41, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8346
2022-11-20 16:42:00,537 - mmcls - INFO - Epoch [47][200/391]	lr: 1.000e-01, eta: 1:30:38, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7862
2022-11-20 16:42:11,588 - mmcls - INFO - Epoch [47][300/391]	lr: 1.000e-01, eta: 1:30:36, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8688
2022-11-20 16:42:24,422 - mmcls - INFO - Epoch(val) [47][79]	train_accuracy: 78.1460, accuracy_top-1: 80.3600, accuracy_top-5: 98.7100
2022-11-20 16:42:37,550 - mmcls - INFO - Epoch [48][100/391]	lr: 1.000e-01, eta: 1:30:05, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8462
2022-11-20 16:42:48,567 - mmcls - INFO - Epoch [48][200/391]	lr: 1.000e-01, eta: 1:30:02, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8246
2022-11-20 16:42:59,591 - mmcls - INFO - Epoch [48][300/391]	lr: 1.000e-01, eta: 1:29:59, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8225
2022-11-20 16:43:12,594 - mmcls - INFO - Epoch(val) [48][79]	train_accuracy: 78.5880, accuracy_top-1: 82.6600, accuracy_top-5: 98.8600
2022-11-20 16:43:25,758 - mmcls - INFO - Epoch [49][100/391]	lr: 1.000e-01, eta: 1:29:29, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7419
2022-11-20 16:43:36,813 - mmcls - INFO - Epoch [49][200/391]	lr: 1.000e-01, eta: 1:29:26, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8274
2022-11-20 16:43:47,864 - mmcls - INFO - Epoch [49][300/391]	lr: 1.000e-01, eta: 1:29:23, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8194
2022-11-20 16:44:00,796 - mmcls - INFO - Epoch(val) [49][79]	train_accuracy: 79.4920, accuracy_top-1: 81.0400, accuracy_top-5: 98.6900
2022-11-20 16:44:13,934 - mmcls - INFO - Epoch [50][100/391]	lr: 1.000e-01, eta: 1:28:53, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7859
2022-11-20 16:44:24,944 - mmcls - INFO - Epoch [50][200/391]	lr: 1.000e-01, eta: 1:28:50, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8241
2022-11-20 16:44:35,959 - mmcls - INFO - Epoch [50][300/391]	lr: 1.000e-01, eta: 1:28:46, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8697
2022-11-20 16:44:45,938 - mmcls - INFO - Saving checkpoint at 50 epochs
2022-11-20 16:44:49,047 - mmcls - INFO - Epoch(val) [50][79]	train_accuracy: 78.1280, accuracy_top-1: 84.9500, accuracy_top-5: 99.1800
2022-11-20 16:45:02,229 - mmcls - INFO - Epoch [51][100/391]	lr: 1.000e-01, eta: 1:28:17, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8754
2022-11-20 16:45:13,236 - mmcls - INFO - Epoch [51][200/391]	lr: 1.000e-01, eta: 1:28:13, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8200
2022-11-20 16:45:24,267 - mmcls - INFO - Epoch [51][300/391]	lr: 1.000e-01, eta: 1:28:10, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8496
2022-11-20 16:45:37,249 - mmcls - INFO - Epoch(val) [51][79]	train_accuracy: 77.4020, accuracy_top-1: 77.9500, accuracy_top-5: 98.4600
2022-11-20 16:45:50,380 - mmcls - INFO - Epoch [52][100/391]	lr: 1.000e-01, eta: 1:27:41, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7723
2022-11-20 16:46:01,414 - mmcls - INFO - Epoch [52][200/391]	lr: 1.000e-01, eta: 1:27:37, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7990
2022-11-20 16:46:12,441 - mmcls - INFO - Epoch [52][300/391]	lr: 1.000e-01, eta: 1:27:34, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8357
2022-11-20 16:46:25,421 - mmcls - INFO - Epoch(val) [52][79]	train_accuracy: 78.5800, accuracy_top-1: 77.5400, accuracy_top-5: 97.6400
2022-11-20 16:46:38,580 - mmcls - INFO - Epoch [53][100/391]	lr: 1.000e-01, eta: 1:27:05, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7666
2022-11-20 16:46:49,603 - mmcls - INFO - Epoch [53][200/391]	lr: 1.000e-01, eta: 1:27:01, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8222
2022-11-20 16:47:00,633 - mmcls - INFO - Epoch [53][300/391]	lr: 1.000e-01, eta: 1:26:58, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7842
2022-11-20 16:47:13,480 - mmcls - INFO - Epoch(val) [53][79]	train_accuracy: 78.5580, accuracy_top-1: 83.0200, accuracy_top-5: 98.8800
2022-11-20 16:47:26,599 - mmcls - INFO - Epoch [54][100/391]	lr: 1.000e-01, eta: 1:26:29, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8789
2022-11-20 16:47:37,619 - mmcls - INFO - Epoch [54][200/391]	lr: 1.000e-01, eta: 1:26:25, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8763
2022-11-20 16:47:48,646 - mmcls - INFO - Epoch [54][300/391]	lr: 1.000e-01, eta: 1:26:21, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7752
2022-11-20 16:48:01,660 - mmcls - INFO - Epoch(val) [54][79]	train_accuracy: 77.4260, accuracy_top-1: 77.8400, accuracy_top-5: 98.3400
2022-11-20 16:48:14,815 - mmcls - INFO - Epoch [55][100/391]	lr: 1.000e-01, eta: 1:25:53, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8391
2022-11-20 16:48:25,821 - mmcls - INFO - Epoch [55][200/391]	lr: 1.000e-01, eta: 1:25:49, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8130
2022-11-20 16:48:36,858 - mmcls - INFO - Epoch [55][300/391]	lr: 1.000e-01, eta: 1:25:45, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8121
2022-11-20 16:48:49,897 - mmcls - INFO - Epoch(val) [55][79]	train_accuracy: 77.4740, accuracy_top-1: 85.4700, accuracy_top-5: 99.4500
2022-11-20 16:49:03,040 - mmcls - INFO - Epoch [56][100/391]	lr: 1.000e-01, eta: 1:25:17, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7485
2022-11-20 16:49:14,072 - mmcls - INFO - Epoch [56][200/391]	lr: 1.000e-01, eta: 1:25:13, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7812
2022-11-20 16:49:25,102 - mmcls - INFO - Epoch [56][300/391]	lr: 1.000e-01, eta: 1:25:09, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8085
2022-11-20 16:49:37,950 - mmcls - INFO - Epoch(val) [56][79]	train_accuracy: 78.6240, accuracy_top-1: 84.7300, accuracy_top-5: 99.1800
2022-11-20 16:49:51,096 - mmcls - INFO - Epoch [57][100/391]	lr: 1.000e-01, eta: 1:24:41, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8739
2022-11-20 16:50:02,131 - mmcls - INFO - Epoch [57][200/391]	lr: 1.000e-01, eta: 1:24:37, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7762
2022-11-20 16:50:13,168 - mmcls - INFO - Epoch [57][300/391]	lr: 1.000e-01, eta: 1:24:33, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7138
2022-11-20 16:50:26,148 - mmcls - INFO - Epoch(val) [57][79]	train_accuracy: 78.8640, accuracy_top-1: 74.2500, accuracy_top-5: 97.9100
2022-11-20 16:50:39,312 - mmcls - INFO - Epoch [58][100/391]	lr: 1.000e-01, eta: 1:24:05, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8543
2022-11-20 16:50:50,343 - mmcls - INFO - Epoch [58][200/391]	lr: 1.000e-01, eta: 1:24:01, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8762
2022-11-20 16:51:01,370 - mmcls - INFO - Epoch [58][300/391]	lr: 1.000e-01, eta: 1:23:57, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7741
2022-11-20 16:51:14,349 - mmcls - INFO - Epoch(val) [58][79]	train_accuracy: 78.0280, accuracy_top-1: 77.5900, accuracy_top-5: 98.1700
2022-11-20 16:51:27,488 - mmcls - INFO - Epoch [59][100/391]	lr: 1.000e-01, eta: 1:23:30, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7782
2022-11-20 16:51:38,534 - mmcls - INFO - Epoch [59][200/391]	lr: 1.000e-01, eta: 1:23:25, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8335
2022-11-20 16:51:49,581 - mmcls - INFO - Epoch [59][300/391]	lr: 1.000e-01, eta: 1:23:21, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7751
2022-11-20 16:52:02,456 - mmcls - INFO - Epoch(val) [59][79]	train_accuracy: 78.2620, accuracy_top-1: 84.0400, accuracy_top-5: 99.3200
2022-11-20 16:52:15,594 - mmcls - INFO - Epoch [60][100/391]	lr: 1.000e-01, eta: 1:22:54, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7849
2022-11-20 16:52:26,619 - mmcls - INFO - Epoch [60][200/391]	lr: 1.000e-01, eta: 1:22:49, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7827
2022-11-20 16:52:37,660 - mmcls - INFO - Epoch [60][300/391]	lr: 1.000e-01, eta: 1:22:45, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8103
2022-11-20 16:52:47,692 - mmcls - INFO - Saving checkpoint at 60 epochs
2022-11-20 16:52:50,862 - mmcls - INFO - Epoch(val) [60][79]	train_accuracy: 78.4640, accuracy_top-1: 85.4200, accuracy_top-5: 99.4000
2022-11-20 16:53:04,085 - mmcls - INFO - Epoch [61][100/391]	lr: 1.000e-01, eta: 1:22:18, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.7174
2022-11-20 16:53:15,172 - mmcls - INFO - Epoch [61][200/391]	lr: 1.000e-01, eta: 1:22:14, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8118
2022-11-20 16:53:26,238 - mmcls - INFO - Epoch [61][300/391]	lr: 1.000e-01, eta: 1:22:10, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8618
2022-11-20 16:53:39,095 - mmcls - INFO - Epoch(val) [61][79]	train_accuracy: 78.5120, accuracy_top-1: 82.8500, accuracy_top-5: 98.8600
2022-11-20 16:53:52,225 - mmcls - INFO - Epoch [62][100/391]	lr: 1.000e-01, eta: 1:21:43, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7310
2022-11-20 16:54:03,279 - mmcls - INFO - Epoch [62][200/391]	lr: 1.000e-01, eta: 1:21:38, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7178
2022-11-20 16:54:14,332 - mmcls - INFO - Epoch [62][300/391]	lr: 1.000e-01, eta: 1:21:34, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8355
2022-11-20 16:54:27,248 - mmcls - INFO - Epoch(val) [62][79]	train_accuracy: 79.6800, accuracy_top-1: 74.3700, accuracy_top-5: 98.7600
2022-11-20 16:54:40,386 - mmcls - INFO - Epoch [63][100/391]	lr: 1.000e-01, eta: 1:21:07, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8152
2022-11-20 16:54:51,424 - mmcls - INFO - Epoch [63][200/391]	lr: 1.000e-01, eta: 1:21:02, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7850
2022-11-20 16:55:02,454 - mmcls - INFO - Epoch [63][300/391]	lr: 1.000e-01, eta: 1:20:58, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8261
2022-11-20 16:55:15,587 - mmcls - INFO - Epoch(val) [63][79]	train_accuracy: 79.1940, accuracy_top-1: 81.1900, accuracy_top-5: 98.9400
2022-11-20 16:55:28,728 - mmcls - INFO - Epoch [64][100/391]	lr: 1.000e-01, eta: 1:20:31, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8641
2022-11-20 16:55:39,765 - mmcls - INFO - Epoch [64][200/391]	lr: 1.000e-01, eta: 1:20:27, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7391
2022-11-20 16:55:50,787 - mmcls - INFO - Epoch [64][300/391]	lr: 1.000e-01, eta: 1:20:22, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7226
2022-11-20 16:56:03,641 - mmcls - INFO - Epoch(val) [64][79]	train_accuracy: 78.5480, accuracy_top-1: 79.4800, accuracy_top-5: 98.6200
2022-11-20 16:56:16,772 - mmcls - INFO - Epoch [65][100/391]	lr: 1.000e-01, eta: 1:19:56, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7544
2022-11-20 16:56:27,771 - mmcls - INFO - Epoch [65][200/391]	lr: 1.000e-01, eta: 1:19:51, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7242
2022-11-20 16:56:38,804 - mmcls - INFO - Epoch [65][300/391]	lr: 1.000e-01, eta: 1:19:46, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7967
2022-11-20 16:56:51,691 - mmcls - INFO - Epoch(val) [65][79]	train_accuracy: 79.3300, accuracy_top-1: 83.9700, accuracy_top-5: 99.2100
2022-11-20 16:57:04,870 - mmcls - INFO - Epoch [66][100/391]	lr: 1.000e-01, eta: 1:19:20, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8588
2022-11-20 16:57:15,905 - mmcls - INFO - Epoch [66][200/391]	lr: 1.000e-01, eta: 1:19:15, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7686
2022-11-20 16:57:26,907 - mmcls - INFO - Epoch [66][300/391]	lr: 1.000e-01, eta: 1:19:10, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7636
2022-11-20 16:57:39,869 - mmcls - INFO - Epoch(val) [66][79]	train_accuracy: 78.7720, accuracy_top-1: 82.6400, accuracy_top-5: 99.1400
2022-11-20 16:57:53,033 - mmcls - INFO - Epoch [67][100/391]	lr: 1.000e-01, eta: 1:18:44, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8372
2022-11-20 16:58:04,058 - mmcls - INFO - Epoch [67][200/391]	lr: 1.000e-01, eta: 1:18:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8054
2022-11-20 16:58:15,102 - mmcls - INFO - Epoch [67][300/391]	lr: 1.000e-01, eta: 1:18:34, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8019
2022-11-20 16:58:27,944 - mmcls - INFO - Epoch(val) [67][79]	train_accuracy: 78.1140, accuracy_top-1: 84.7000, accuracy_top-5: 99.1900
2022-11-20 16:58:41,113 - mmcls - INFO - Epoch [68][100/391]	lr: 1.000e-01, eta: 1:18:09, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7886
2022-11-20 16:58:52,141 - mmcls - INFO - Epoch [68][200/391]	lr: 1.000e-01, eta: 1:18:04, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7694
2022-11-20 16:59:03,172 - mmcls - INFO - Epoch [68][300/391]	lr: 1.000e-01, eta: 1:17:58, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8632
2022-11-20 16:59:16,155 - mmcls - INFO - Epoch(val) [68][79]	train_accuracy: 78.4100, accuracy_top-1: 84.4400, accuracy_top-5: 98.7000
2022-11-20 16:59:29,271 - mmcls - INFO - Epoch [69][100/391]	lr: 1.000e-01, eta: 1:17:33, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8235
2022-11-20 16:59:40,289 - mmcls - INFO - Epoch [69][200/391]	lr: 1.000e-01, eta: 1:17:28, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8113
2022-11-20 16:59:51,314 - mmcls - INFO - Epoch [69][300/391]	lr: 1.000e-01, eta: 1:17:23, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7438
2022-11-20 17:00:04,417 - mmcls - INFO - Epoch(val) [69][79]	train_accuracy: 79.2200, accuracy_top-1: 78.7300, accuracy_top-5: 98.3300
2022-11-20 17:00:17,568 - mmcls - INFO - Epoch [70][100/391]	lr: 1.000e-01, eta: 1:16:57, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7361
2022-11-20 17:00:28,591 - mmcls - INFO - Epoch [70][200/391]	lr: 1.000e-01, eta: 1:16:52, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7389
2022-11-20 17:00:39,608 - mmcls - INFO - Epoch [70][300/391]	lr: 1.000e-01, eta: 1:16:47, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8049
2022-11-20 17:00:49,593 - mmcls - INFO - Saving checkpoint at 70 epochs
2022-11-20 17:00:52,640 - mmcls - INFO - Epoch(val) [70][79]	train_accuracy: 78.6520, accuracy_top-1: 82.4800, accuracy_top-5: 98.8400
2022-11-20 17:01:05,820 - mmcls - INFO - Epoch [71][100/391]	lr: 1.000e-01, eta: 1:16:22, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7806
2022-11-20 17:01:16,864 - mmcls - INFO - Epoch [71][200/391]	lr: 1.000e-01, eta: 1:16:17, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7820
2022-11-20 17:01:27,885 - mmcls - INFO - Epoch [71][300/391]	lr: 1.000e-01, eta: 1:16:11, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7235
2022-11-20 17:01:40,799 - mmcls - INFO - Epoch(val) [71][79]	train_accuracy: 78.6800, accuracy_top-1: 82.2000, accuracy_top-5: 98.7800
2022-11-20 17:01:53,945 - mmcls - INFO - Epoch [72][100/391]	lr: 1.000e-01, eta: 1:15:46, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8492
2022-11-20 17:02:04,970 - mmcls - INFO - Epoch [72][200/391]	lr: 1.000e-01, eta: 1:15:41, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7748
2022-11-20 17:02:16,008 - mmcls - INFO - Epoch [72][300/391]	lr: 1.000e-01, eta: 1:15:35, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7867
2022-11-20 17:02:29,062 - mmcls - INFO - Epoch(val) [72][79]	train_accuracy: 78.9780, accuracy_top-1: 80.0200, accuracy_top-5: 98.9200
2022-11-20 17:02:42,256 - mmcls - INFO - Epoch [73][100/391]	lr: 1.000e-01, eta: 1:15:11, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.7390
2022-11-20 17:02:53,337 - mmcls - INFO - Epoch [73][200/391]	lr: 1.000e-01, eta: 1:15:05, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7866
2022-11-20 17:03:04,420 - mmcls - INFO - Epoch [73][300/391]	lr: 1.000e-01, eta: 1:15:00, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7609
2022-11-20 17:03:17,323 - mmcls - INFO - Epoch(val) [73][79]	train_accuracy: 78.6920, accuracy_top-1: 78.7300, accuracy_top-5: 98.6600
2022-11-20 17:03:30,490 - mmcls - INFO - Epoch [74][100/391]	lr: 1.000e-01, eta: 1:14:35, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.6364
2022-11-20 17:03:41,542 - mmcls - INFO - Epoch [74][200/391]	lr: 1.000e-01, eta: 1:14:30, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8346
2022-11-20 17:03:52,575 - mmcls - INFO - Epoch [74][300/391]	lr: 1.000e-01, eta: 1:14:24, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7903
2022-11-20 17:04:05,509 - mmcls - INFO - Epoch(val) [74][79]	train_accuracy: 79.4240, accuracy_top-1: 80.2100, accuracy_top-5: 99.0600
2022-11-20 17:04:18,653 - mmcls - INFO - Epoch [75][100/391]	lr: 1.000e-01, eta: 1:14:00, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8049
2022-11-20 17:04:29,672 - mmcls - INFO - Epoch [75][200/391]	lr: 1.000e-01, eta: 1:13:54, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7665
2022-11-20 17:04:40,712 - mmcls - INFO - Epoch [75][300/391]	lr: 1.000e-01, eta: 1:13:49, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7693
2022-11-20 17:04:53,645 - mmcls - INFO - Epoch(val) [75][79]	train_accuracy: 78.9480, accuracy_top-1: 82.5600, accuracy_top-5: 98.8800
2022-11-20 17:05:06,816 - mmcls - INFO - Epoch [76][100/391]	lr: 1.000e-01, eta: 1:13:24, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7360
2022-11-20 17:05:17,878 - mmcls - INFO - Epoch [76][200/391]	lr: 1.000e-01, eta: 1:13:19, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7281
2022-11-20 17:05:28,931 - mmcls - INFO - Epoch [76][300/391]	lr: 1.000e-01, eta: 1:13:13, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8027
2022-11-20 17:05:41,765 - mmcls - INFO - Epoch(val) [76][79]	train_accuracy: 80.9100, accuracy_top-1: 82.6800, accuracy_top-5: 99.1400
2022-11-20 17:05:54,918 - mmcls - INFO - Epoch [77][100/391]	lr: 1.000e-01, eta: 1:12:49, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7733
2022-11-20 17:06:05,949 - mmcls - INFO - Epoch [77][200/391]	lr: 1.000e-01, eta: 1:12:43, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7686
2022-11-20 17:06:16,972 - mmcls - INFO - Epoch [77][300/391]	lr: 1.000e-01, eta: 1:12:37, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8187
2022-11-20 17:06:29,917 - mmcls - INFO - Epoch(val) [77][79]	train_accuracy: 78.8980, accuracy_top-1: 82.9700, accuracy_top-5: 98.9200
2022-11-20 17:06:43,062 - mmcls - INFO - Epoch [78][100/391]	lr: 1.000e-01, eta: 1:12:13, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7093
2022-11-20 17:06:54,088 - mmcls - INFO - Epoch [78][200/391]	lr: 1.000e-01, eta: 1:12:08, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6969
2022-11-20 17:07:05,112 - mmcls - INFO - Epoch [78][300/391]	lr: 1.000e-01, eta: 1:12:02, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7591
2022-11-20 17:07:18,122 - mmcls - INFO - Epoch(val) [78][79]	train_accuracy: 79.6240, accuracy_top-1: 80.9900, accuracy_top-5: 98.9400
2022-11-20 17:07:31,254 - mmcls - INFO - Epoch [79][100/391]	lr: 1.000e-01, eta: 1:11:38, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8168
2022-11-20 17:07:42,288 - mmcls - INFO - Epoch [79][200/391]	lr: 1.000e-01, eta: 1:11:32, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7412
2022-11-20 17:07:53,388 - mmcls - INFO - Epoch [79][300/391]	lr: 1.000e-01, eta: 1:11:26, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.8291
2022-11-20 17:08:06,242 - mmcls - INFO - Epoch(val) [79][79]	train_accuracy: 79.7600, accuracy_top-1: 83.4000, accuracy_top-5: 99.2800
2022-11-20 17:08:19,409 - mmcls - INFO - Epoch [80][100/391]	lr: 1.000e-01, eta: 1:11:03, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7312
2022-11-20 17:08:30,463 - mmcls - INFO - Epoch [80][200/391]	lr: 1.000e-01, eta: 1:10:57, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.7558
2022-11-20 17:08:41,506 - mmcls - INFO - Epoch [80][300/391]	lr: 1.000e-01, eta: 1:10:51, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6968
2022-11-20 17:08:51,515 - mmcls - INFO - Saving checkpoint at 80 epochs
2022-11-20 17:08:54,724 - mmcls - INFO - Epoch(val) [80][79]	train_accuracy: 81.2120, accuracy_top-1: 80.4800, accuracy_top-5: 98.9100
2022-11-20 17:09:07,886 - mmcls - INFO - Epoch [81][100/391]	lr: 1.000e-01, eta: 1:10:27, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7005
2022-11-20 17:09:18,912 - mmcls - INFO - Epoch [81][200/391]	lr: 1.000e-01, eta: 1:10:21, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7925
2022-11-20 17:09:29,935 - mmcls - INFO - Epoch [81][300/391]	lr: 1.000e-01, eta: 1:10:15, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7214
2022-11-20 17:09:42,703 - mmcls - INFO - Epoch(val) [81][79]	train_accuracy: 80.1040, accuracy_top-1: 85.8200, accuracy_top-5: 99.3600
2022-11-20 17:09:55,812 - mmcls - INFO - Epoch [82][100/391]	lr: 1.000e-01, eta: 1:09:52, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7308
2022-11-20 17:10:06,841 - mmcls - INFO - Epoch [82][200/391]	lr: 1.000e-01, eta: 1:09:45, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7889
2022-11-20 17:10:17,843 - mmcls - INFO - Epoch [82][300/391]	lr: 1.000e-01, eta: 1:09:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7411
2022-11-20 17:10:30,825 - mmcls - INFO - Epoch(val) [82][79]	train_accuracy: 79.8840, accuracy_top-1: 84.6900, accuracy_top-5: 99.3200
2022-11-20 17:10:43,953 - mmcls - INFO - Epoch [83][100/391]	lr: 1.000e-01, eta: 1:09:16, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7095
2022-11-20 17:10:54,968 - mmcls - INFO - Epoch [83][200/391]	lr: 1.000e-01, eta: 1:09:10, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7348
2022-11-20 17:11:06,011 - mmcls - INFO - Epoch [83][300/391]	lr: 1.000e-01, eta: 1:09:04, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8446
2022-11-20 17:11:18,926 - mmcls - INFO - Epoch(val) [83][79]	train_accuracy: 80.0920, accuracy_top-1: 82.5400, accuracy_top-5: 99.2700
2022-11-20 17:11:32,063 - mmcls - INFO - Epoch [84][100/391]	lr: 1.000e-01, eta: 1:08:40, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7737
2022-11-20 17:11:43,074 - mmcls - INFO - Epoch [84][200/391]	lr: 1.000e-01, eta: 1:08:34, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7575
2022-11-20 17:11:54,091 - mmcls - INFO - Epoch [84][300/391]	lr: 1.000e-01, eta: 1:08:28, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7373
2022-11-20 17:12:07,018 - mmcls - INFO - Epoch(val) [84][79]	train_accuracy: 79.9040, accuracy_top-1: 71.4100, accuracy_top-5: 97.1200
2022-11-20 17:12:20,137 - mmcls - INFO - Epoch [85][100/391]	lr: 1.000e-01, eta: 1:08:05, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8109
2022-11-20 17:12:31,141 - mmcls - INFO - Epoch [85][200/391]	lr: 1.000e-01, eta: 1:07:59, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7770
2022-11-20 17:12:42,143 - mmcls - INFO - Epoch [85][300/391]	lr: 1.000e-01, eta: 1:07:52, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7659
2022-11-20 17:12:55,125 - mmcls - INFO - Epoch(val) [85][79]	train_accuracy: 79.4940, accuracy_top-1: 82.3300, accuracy_top-5: 99.0100
2022-11-20 17:13:08,280 - mmcls - INFO - Epoch [86][100/391]	lr: 1.000e-01, eta: 1:07:29, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7431
2022-11-20 17:13:19,313 - mmcls - INFO - Epoch [86][200/391]	lr: 1.000e-01, eta: 1:07:23, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7351
2022-11-20 17:13:30,351 - mmcls - INFO - Epoch [86][300/391]	lr: 1.000e-01, eta: 1:07:17, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7110
2022-11-20 17:13:43,390 - mmcls - INFO - Epoch(val) [86][79]	train_accuracy: 79.6840, accuracy_top-1: 82.0000, accuracy_top-5: 98.8600
2022-11-20 17:13:56,522 - mmcls - INFO - Epoch [87][100/391]	lr: 1.000e-01, eta: 1:06:54, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7444
2022-11-20 17:14:07,558 - mmcls - INFO - Epoch [87][200/391]	lr: 1.000e-01, eta: 1:06:48, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8542
2022-11-20 17:14:18,571 - mmcls - INFO - Epoch [87][300/391]	lr: 1.000e-01, eta: 1:06:41, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7178
2022-11-20 17:14:31,406 - mmcls - INFO - Epoch(val) [87][79]	train_accuracy: 79.8700, accuracy_top-1: 84.3400, accuracy_top-5: 99.3800
2022-11-20 17:14:44,543 - mmcls - INFO - Epoch [88][100/391]	lr: 1.000e-01, eta: 1:06:18, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7722
2022-11-20 17:14:55,557 - mmcls - INFO - Epoch [88][200/391]	lr: 1.000e-01, eta: 1:06:12, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8088
2022-11-20 17:15:06,583 - mmcls - INFO - Epoch [88][300/391]	lr: 1.000e-01, eta: 1:06:05, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8533
2022-11-20 17:15:19,511 - mmcls - INFO - Epoch(val) [88][79]	train_accuracy: 78.1880, accuracy_top-1: 79.8000, accuracy_top-5: 98.9900
2022-11-20 17:15:32,646 - mmcls - INFO - Epoch [89][100/391]	lr: 1.000e-01, eta: 1:05:43, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7627
2022-11-20 17:15:43,654 - mmcls - INFO - Epoch [89][200/391]	lr: 1.000e-01, eta: 1:05:36, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8121
2022-11-20 17:15:54,695 - mmcls - INFO - Epoch [89][300/391]	lr: 1.000e-01, eta: 1:05:30, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7557
2022-11-20 17:16:07,565 - mmcls - INFO - Epoch(val) [89][79]	train_accuracy: 79.3080, accuracy_top-1: 80.8500, accuracy_top-5: 98.5800
2022-11-20 17:16:20,714 - mmcls - INFO - Epoch [90][100/391]	lr: 1.000e-01, eta: 1:05:07, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7850
2022-11-20 17:16:31,719 - mmcls - INFO - Epoch [90][200/391]	lr: 1.000e-01, eta: 1:05:01, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7488
2022-11-20 17:16:42,740 - mmcls - INFO - Epoch [90][300/391]	lr: 1.000e-01, eta: 1:04:54, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7615
2022-11-20 17:16:52,705 - mmcls - INFO - Saving checkpoint at 90 epochs
2022-11-20 17:16:55,721 - mmcls - INFO - Epoch(val) [90][79]	train_accuracy: 80.2800, accuracy_top-1: 79.8300, accuracy_top-5: 98.5100
2022-11-20 17:17:08,872 - mmcls - INFO - Epoch [91][100/391]	lr: 1.000e-01, eta: 1:04:32, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7273
2022-11-20 17:17:19,906 - mmcls - INFO - Epoch [91][200/391]	lr: 1.000e-01, eta: 1:04:25, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7307
2022-11-20 17:17:30,924 - mmcls - INFO - Epoch [91][300/391]	lr: 1.000e-01, eta: 1:04:19, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7400
2022-11-20 17:17:43,947 - mmcls - INFO - Epoch(val) [91][79]	train_accuracy: 79.7880, accuracy_top-1: 80.9600, accuracy_top-5: 98.5700
2022-11-20 17:17:57,119 - mmcls - INFO - Epoch [92][100/391]	lr: 1.000e-01, eta: 1:03:57, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7554
2022-11-20 17:18:08,128 - mmcls - INFO - Epoch [92][200/391]	lr: 1.000e-01, eta: 1:03:50, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7999
2022-11-20 17:18:19,162 - mmcls - INFO - Epoch [92][300/391]	lr: 1.000e-01, eta: 1:03:43, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.8085
2022-11-20 17:18:32,121 - mmcls - INFO - Epoch(val) [92][79]	train_accuracy: 79.2660, accuracy_top-1: 83.1300, accuracy_top-5: 99.1600
2022-11-20 17:18:45,245 - mmcls - INFO - Epoch [93][100/391]	lr: 1.000e-01, eta: 1:03:21, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7796
2022-11-20 17:18:56,264 - mmcls - INFO - Epoch [93][200/391]	lr: 1.000e-01, eta: 1:03:14, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7667
2022-11-20 17:19:07,309 - mmcls - INFO - Epoch [93][300/391]	lr: 1.000e-01, eta: 1:03:08, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7204
2022-11-20 17:19:20,173 - mmcls - INFO - Epoch(val) [93][79]	train_accuracy: 80.7480, accuracy_top-1: 79.0300, accuracy_top-5: 98.4900
2022-11-20 17:19:33,327 - mmcls - INFO - Epoch [94][100/391]	lr: 1.000e-01, eta: 1:02:46, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7637
2022-11-20 17:19:44,328 - mmcls - INFO - Epoch [94][200/391]	lr: 1.000e-01, eta: 1:02:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7597
2022-11-20 17:19:55,334 - mmcls - INFO - Epoch [94][300/391]	lr: 1.000e-01, eta: 1:02:32, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7416
2022-11-20 17:20:08,318 - mmcls - INFO - Epoch(val) [94][79]	train_accuracy: 80.2740, accuracy_top-1: 83.2700, accuracy_top-5: 99.0600
2022-11-20 17:20:21,444 - mmcls - INFO - Epoch [95][100/391]	lr: 1.000e-01, eta: 1:02:10, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7111
2022-11-20 17:20:32,453 - mmcls - INFO - Epoch [95][200/391]	lr: 1.000e-01, eta: 1:02:03, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7750
2022-11-20 17:20:43,472 - mmcls - INFO - Epoch [95][300/391]	lr: 1.000e-01, eta: 1:01:57, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7753
2022-11-20 17:20:56,534 - mmcls - INFO - Epoch(val) [95][79]	train_accuracy: 80.1860, accuracy_top-1: 80.5200, accuracy_top-5: 98.8100
2022-11-20 17:21:09,687 - mmcls - INFO - Epoch [96][100/391]	lr: 1.000e-01, eta: 1:01:35, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8457
2022-11-20 17:21:20,706 - mmcls - INFO - Epoch [96][200/391]	lr: 1.000e-01, eta: 1:01:28, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7094
2022-11-20 17:21:31,745 - mmcls - INFO - Epoch [96][300/391]	lr: 1.000e-01, eta: 1:01:21, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7759
2022-11-20 17:21:44,548 - mmcls - INFO - Epoch(val) [96][79]	train_accuracy: 79.0880, accuracy_top-1: 81.3300, accuracy_top-5: 99.0400
2022-11-20 17:21:57,673 - mmcls - INFO - Epoch [97][100/391]	lr: 1.000e-01, eta: 1:00:59, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7123
2022-11-20 17:22:08,675 - mmcls - INFO - Epoch [97][200/391]	lr: 1.000e-01, eta: 1:00:53, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6716
2022-11-20 17:22:19,716 - mmcls - INFO - Epoch [97][300/391]	lr: 1.000e-01, eta: 1:00:46, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7848
2022-11-20 17:22:32,701 - mmcls - INFO - Epoch(val) [97][79]	train_accuracy: 80.3560, accuracy_top-1: 84.0500, accuracy_top-5: 99.0200
2022-11-20 17:22:45,835 - mmcls - INFO - Epoch [98][100/391]	lr: 1.000e-01, eta: 1:00:24, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.6746
2022-11-20 17:22:56,844 - mmcls - INFO - Epoch [98][200/391]	lr: 1.000e-01, eta: 1:00:17, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7828
2022-11-20 17:23:07,875 - mmcls - INFO - Epoch [98][300/391]	lr: 1.000e-01, eta: 1:00:10, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6801
2022-11-20 17:23:20,853 - mmcls - INFO - Epoch(val) [98][79]	train_accuracy: 79.9200, accuracy_top-1: 82.8600, accuracy_top-5: 98.6000
2022-11-20 17:23:33,989 - mmcls - INFO - Epoch [99][100/391]	lr: 1.000e-01, eta: 0:59:49, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7321
2022-11-20 17:23:45,022 - mmcls - INFO - Epoch [99][200/391]	lr: 1.000e-01, eta: 0:59:42, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7472
2022-11-20 17:23:56,047 - mmcls - INFO - Epoch [99][300/391]	lr: 1.000e-01, eta: 0:59:35, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7251
2022-11-20 17:24:08,887 - mmcls - INFO - Epoch(val) [99][79]	train_accuracy: 80.9660, accuracy_top-1: 85.4900, accuracy_top-5: 99.3100
2022-11-20 17:24:22,011 - mmcls - INFO - Epoch [100][100/391]	lr: 1.000e-01, eta: 0:59:13, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.8442
2022-11-20 17:24:33,027 - mmcls - INFO - Epoch [100][200/391]	lr: 1.000e-01, eta: 0:59:06, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7440
2022-11-20 17:24:44,053 - mmcls - INFO - Epoch [100][300/391]	lr: 1.000e-01, eta: 0:58:59, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7908
2022-11-20 17:24:54,025 - mmcls - INFO - Saving checkpoint at 100 epochs
2022-11-20 17:24:57,262 - mmcls - INFO - Epoch(val) [100][79]	train_accuracy: 79.5800, accuracy_top-1: 82.6700, accuracy_top-5: 98.7600
2022-11-20 17:25:10,433 - mmcls - INFO - Epoch [101][100/391]	lr: 1.000e-02, eta: 0:58:38, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.7516
2022-11-20 17:25:21,457 - mmcls - INFO - Epoch [101][200/391]	lr: 1.000e-02, eta: 0:58:31, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.7168
2022-11-20 17:25:32,466 - mmcls - INFO - Epoch [101][300/391]	lr: 1.000e-02, eta: 0:58:24, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6394
2022-11-20 17:25:45,329 - mmcls - INFO - Epoch(val) [101][79]	train_accuracy: 83.0300, accuracy_top-1: 92.5100, accuracy_top-5: 99.7600
2022-11-20 17:25:58,476 - mmcls - INFO - Epoch [102][100/391]	lr: 1.000e-02, eta: 0:58:02, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.6631
2022-11-20 17:26:09,494 - mmcls - INFO - Epoch [102][200/391]	lr: 1.000e-02, eta: 0:57:55, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5188
2022-11-20 17:26:20,519 - mmcls - INFO - Epoch [102][300/391]	lr: 1.000e-02, eta: 0:57:48, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4786
2022-11-20 17:26:33,527 - mmcls - INFO - Epoch(val) [102][79]	train_accuracy: 85.9800, accuracy_top-1: 93.0500, accuracy_top-5: 99.8200
2022-11-20 17:26:46,673 - mmcls - INFO - Epoch [103][100/391]	lr: 1.000e-02, eta: 0:57:27, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.6075
2022-11-20 17:26:57,701 - mmcls - INFO - Epoch [103][200/391]	lr: 1.000e-02, eta: 0:57:20, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5964
2022-11-20 17:27:08,756 - mmcls - INFO - Epoch [103][300/391]	lr: 1.000e-02, eta: 0:57:13, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5201
2022-11-20 17:27:21,857 - mmcls - INFO - Epoch(val) [103][79]	train_accuracy: 87.1240, accuracy_top-1: 93.0400, accuracy_top-5: 99.8400
2022-11-20 17:27:35,007 - mmcls - INFO - Epoch [104][100/391]	lr: 1.000e-02, eta: 0:56:52, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5816
2022-11-20 17:27:46,025 - mmcls - INFO - Epoch [104][200/391]	lr: 1.000e-02, eta: 0:56:45, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6124
2022-11-20 17:27:57,028 - mmcls - INFO - Epoch [104][300/391]	lr: 1.000e-02, eta: 0:56:37, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5918
2022-11-20 17:28:09,854 - mmcls - INFO - Epoch(val) [104][79]	train_accuracy: 85.7940, accuracy_top-1: 93.4500, accuracy_top-5: 99.8300
2022-11-20 17:28:23,016 - mmcls - INFO - Epoch [105][100/391]	lr: 1.000e-02, eta: 0:56:16, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5946
2022-11-20 17:28:34,020 - mmcls - INFO - Epoch [105][200/391]	lr: 1.000e-02, eta: 0:56:09, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5676
2022-11-20 17:28:45,053 - mmcls - INFO - Epoch [105][300/391]	lr: 1.000e-02, eta: 0:56:02, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5727
2022-11-20 17:28:58,076 - mmcls - INFO - Epoch(val) [105][79]	train_accuracy: 85.9280, accuracy_top-1: 93.6600, accuracy_top-5: 99.8200
2022-11-20 17:29:11,206 - mmcls - INFO - Epoch [106][100/391]	lr: 1.000e-02, eta: 0:55:41, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5247
2022-11-20 17:29:22,234 - mmcls - INFO - Epoch [106][200/391]	lr: 1.000e-02, eta: 0:55:34, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4716
2022-11-20 17:29:33,254 - mmcls - INFO - Epoch [106][300/391]	lr: 1.000e-02, eta: 0:55:26, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5407
2022-11-20 17:29:46,214 - mmcls - INFO - Epoch(val) [106][79]	train_accuracy: 87.6100, accuracy_top-1: 93.8400, accuracy_top-5: 99.8600
2022-11-20 17:29:59,352 - mmcls - INFO - Epoch [107][100/391]	lr: 1.000e-02, eta: 0:55:06, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5224
2022-11-20 17:30:10,366 - mmcls - INFO - Epoch [107][200/391]	lr: 1.000e-02, eta: 0:54:58, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5198
2022-11-20 17:30:21,372 - mmcls - INFO - Epoch [107][300/391]	lr: 1.000e-02, eta: 0:54:51, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5495
2022-11-20 17:30:34,231 - mmcls - INFO - Epoch(val) [107][79]	train_accuracy: 87.8640, accuracy_top-1: 93.6400, accuracy_top-5: 99.8500
2022-11-20 17:30:47,365 - mmcls - INFO - Epoch [108][100/391]	lr: 1.000e-02, eta: 0:54:30, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4677
2022-11-20 17:30:58,408 - mmcls - INFO - Epoch [108][200/391]	lr: 1.000e-02, eta: 0:54:23, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5885
2022-11-20 17:31:09,418 - mmcls - INFO - Epoch [108][300/391]	lr: 1.000e-02, eta: 0:54:16, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5848
2022-11-20 17:31:22,394 - mmcls - INFO - Epoch(val) [108][79]	train_accuracy: 86.2140, accuracy_top-1: 93.7200, accuracy_top-5: 99.8200
2022-11-20 17:31:35,552 - mmcls - INFO - Epoch [109][100/391]	lr: 1.000e-02, eta: 0:53:55, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5569
2022-11-20 17:31:46,623 - mmcls - INFO - Epoch [109][200/391]	lr: 1.000e-02, eta: 0:53:47, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5320
2022-11-20 17:31:57,690 - mmcls - INFO - Epoch [109][300/391]	lr: 1.000e-02, eta: 0:53:40, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5399
2022-11-20 17:32:10,622 - mmcls - INFO - Epoch(val) [109][79]	train_accuracy: 87.8820, accuracy_top-1: 93.6300, accuracy_top-5: 99.8200
2022-11-20 17:32:23,748 - mmcls - INFO - Epoch [110][100/391]	lr: 1.000e-02, eta: 0:53:19, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4725
2022-11-20 17:32:34,760 - mmcls - INFO - Epoch [110][200/391]	lr: 1.000e-02, eta: 0:53:12, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4918
2022-11-20 17:32:45,796 - mmcls - INFO - Epoch [110][300/391]	lr: 1.000e-02, eta: 0:53:05, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5170
2022-11-20 17:32:55,802 - mmcls - INFO - Saving checkpoint at 110 epochs
2022-11-20 17:32:58,935 - mmcls - INFO - Epoch(val) [110][79]	train_accuracy: 89.1560, accuracy_top-1: 94.1300, accuracy_top-5: 99.8900
2022-11-20 17:33:12,068 - mmcls - INFO - Epoch [111][100/391]	lr: 1.000e-02, eta: 0:52:44, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4942
2022-11-20 17:33:23,087 - mmcls - INFO - Epoch [111][200/391]	lr: 1.000e-02, eta: 0:52:37, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4860
2022-11-20 17:33:34,117 - mmcls - INFO - Epoch [111][300/391]	lr: 1.000e-02, eta: 0:52:29, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5578
2022-11-20 17:33:47,158 - mmcls - INFO - Epoch(val) [111][79]	train_accuracy: 87.7900, accuracy_top-1: 93.8200, accuracy_top-5: 99.8600
2022-11-20 17:34:00,360 - mmcls - INFO - Epoch [112][100/391]	lr: 1.000e-02, eta: 0:52:09, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.5735
2022-11-20 17:34:11,424 - mmcls - INFO - Epoch [112][200/391]	lr: 1.000e-02, eta: 0:52:01, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5746
2022-11-20 17:34:22,482 - mmcls - INFO - Epoch [112][300/391]	lr: 1.000e-02, eta: 0:51:54, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.6083
2022-11-20 17:34:35,495 - mmcls - INFO - Epoch(val) [112][79]	train_accuracy: 86.9800, accuracy_top-1: 94.0900, accuracy_top-5: 99.8100
2022-11-20 17:34:48,643 - mmcls - INFO - Epoch [113][100/391]	lr: 1.000e-02, eta: 0:51:34, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4914
2022-11-20 17:34:59,673 - mmcls - INFO - Epoch [113][200/391]	lr: 1.000e-02, eta: 0:51:26, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5568
2022-11-20 17:35:10,706 - mmcls - INFO - Epoch [113][300/391]	lr: 1.000e-02, eta: 0:51:19, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4940
2022-11-20 17:35:23,533 - mmcls - INFO - Epoch(val) [113][79]	train_accuracy: 88.3300, accuracy_top-1: 94.1000, accuracy_top-5: 99.8600
2022-11-20 17:35:36,708 - mmcls - INFO - Epoch [114][100/391]	lr: 1.000e-02, eta: 0:50:58, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5683
2022-11-20 17:35:47,734 - mmcls - INFO - Epoch [114][200/391]	lr: 1.000e-02, eta: 0:50:51, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5342
2022-11-20 17:35:58,777 - mmcls - INFO - Epoch [114][300/391]	lr: 1.000e-02, eta: 0:50:43, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5304
2022-11-20 17:36:11,788 - mmcls - INFO - Epoch(val) [114][79]	train_accuracy: 87.5840, accuracy_top-1: 93.6500, accuracy_top-5: 99.8500
2022-11-20 17:36:24,957 - mmcls - INFO - Epoch [115][100/391]	lr: 1.000e-02, eta: 0:50:23, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5041
2022-11-20 17:36:36,014 - mmcls - INFO - Epoch [115][200/391]	lr: 1.000e-02, eta: 0:50:15, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4782
2022-11-20 17:36:47,048 - mmcls - INFO - Epoch [115][300/391]	lr: 1.000e-02, eta: 0:50:08, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5557
2022-11-20 17:37:00,049 - mmcls - INFO - Epoch(val) [115][79]	train_accuracy: 88.7420, accuracy_top-1: 94.0000, accuracy_top-5: 99.8900
2022-11-20 17:37:13,177 - mmcls - INFO - Epoch [116][100/391]	lr: 1.000e-02, eta: 0:49:48, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5179
2022-11-20 17:37:24,223 - mmcls - INFO - Epoch [116][200/391]	lr: 1.000e-02, eta: 0:49:40, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6113
2022-11-20 17:37:35,255 - mmcls - INFO - Epoch [116][300/391]	lr: 1.000e-02, eta: 0:49:33, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4912
2022-11-20 17:37:48,116 - mmcls - INFO - Epoch(val) [116][79]	train_accuracy: 87.1040, accuracy_top-1: 93.9900, accuracy_top-5: 99.8000
2022-11-20 17:38:01,274 - mmcls - INFO - Epoch [117][100/391]	lr: 1.000e-02, eta: 0:49:12, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5107
2022-11-20 17:38:12,306 - mmcls - INFO - Epoch [117][200/391]	lr: 1.000e-02, eta: 0:49:05, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5688
2022-11-20 17:38:23,360 - mmcls - INFO - Epoch [117][300/391]	lr: 1.000e-02, eta: 0:48:57, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4942
2022-11-20 17:38:36,518 - mmcls - INFO - Epoch(val) [117][79]	train_accuracy: 87.7800, accuracy_top-1: 93.7300, accuracy_top-5: 99.8500
2022-11-20 17:38:49,666 - mmcls - INFO - Epoch [118][100/391]	lr: 1.000e-02, eta: 0:48:37, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4944
2022-11-20 17:39:00,685 - mmcls - INFO - Epoch [118][200/391]	lr: 1.000e-02, eta: 0:48:29, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5949
2022-11-20 17:39:11,712 - mmcls - INFO - Epoch [118][300/391]	lr: 1.000e-02, eta: 0:48:22, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4838
2022-11-20 17:39:24,768 - mmcls - INFO - Epoch(val) [118][79]	train_accuracy: 87.4920, accuracy_top-1: 94.0000, accuracy_top-5: 99.8800
2022-11-20 17:39:37,884 - mmcls - INFO - Epoch [119][100/391]	lr: 1.000e-02, eta: 0:48:02, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5640
2022-11-20 17:39:48,912 - mmcls - INFO - Epoch [119][200/391]	lr: 1.000e-02, eta: 0:47:54, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5366
2022-11-20 17:39:59,949 - mmcls - INFO - Epoch [119][300/391]	lr: 1.000e-02, eta: 0:47:46, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5159
2022-11-20 17:40:12,767 - mmcls - INFO - Epoch(val) [119][79]	train_accuracy: 87.6500, accuracy_top-1: 94.2700, accuracy_top-5: 99.8600
2022-11-20 17:40:25,916 - mmcls - INFO - Epoch [120][100/391]	lr: 1.000e-02, eta: 0:47:26, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4885
2022-11-20 17:40:36,927 - mmcls - INFO - Epoch [120][200/391]	lr: 1.000e-02, eta: 0:47:19, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5575
2022-11-20 17:40:47,981 - mmcls - INFO - Epoch [120][300/391]	lr: 1.000e-02, eta: 0:47:11, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4273
2022-11-20 17:40:58,015 - mmcls - INFO - Saving checkpoint at 120 epochs
2022-11-20 17:41:01,264 - mmcls - INFO - Epoch(val) [120][79]	train_accuracy: 88.2340, accuracy_top-1: 93.9800, accuracy_top-5: 99.8200
2022-11-20 17:41:14,464 - mmcls - INFO - Epoch [121][100/391]	lr: 1.000e-02, eta: 0:46:51, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.4764
2022-11-20 17:41:25,514 - mmcls - INFO - Epoch [121][200/391]	lr: 1.000e-02, eta: 0:46:43, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4578
2022-11-20 17:41:36,555 - mmcls - INFO - Epoch [121][300/391]	lr: 1.000e-02, eta: 0:46:36, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4640
2022-11-20 17:41:49,438 - mmcls - INFO - Epoch(val) [121][79]	train_accuracy: 89.2460, accuracy_top-1: 94.1000, accuracy_top-5: 99.8600
2022-11-20 17:42:02,578 - mmcls - INFO - Epoch [122][100/391]	lr: 1.000e-02, eta: 0:46:16, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4360
2022-11-20 17:42:13,583 - mmcls - INFO - Epoch [122][200/391]	lr: 1.000e-02, eta: 0:46:08, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5402
2022-11-20 17:42:24,593 - mmcls - INFO - Epoch [122][300/391]	lr: 1.000e-02, eta: 0:46:00, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4280
2022-11-20 17:42:37,567 - mmcls - INFO - Epoch(val) [122][79]	train_accuracy: 90.0680, accuracy_top-1: 94.0300, accuracy_top-5: 99.8700
2022-11-20 17:42:50,707 - mmcls - INFO - Epoch [123][100/391]	lr: 1.000e-02, eta: 0:45:40, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5004
2022-11-20 17:43:01,762 - mmcls - INFO - Epoch [123][200/391]	lr: 1.000e-02, eta: 0:45:33, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5468
2022-11-20 17:43:12,807 - mmcls - INFO - Epoch [123][300/391]	lr: 1.000e-02, eta: 0:45:25, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4520
2022-11-20 17:43:25,862 - mmcls - INFO - Epoch(val) [123][79]	train_accuracy: 88.8340, accuracy_top-1: 94.0900, accuracy_top-5: 99.8000
2022-11-20 17:43:38,995 - mmcls - INFO - Epoch [124][100/391]	lr: 1.000e-02, eta: 0:45:05, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5462
2022-11-20 17:43:50,012 - mmcls - INFO - Epoch [124][200/391]	lr: 1.000e-02, eta: 0:44:57, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5653
2022-11-20 17:44:01,064 - mmcls - INFO - Epoch [124][300/391]	lr: 1.000e-02, eta: 0:44:50, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4472
2022-11-20 17:44:13,955 - mmcls - INFO - Epoch(val) [124][79]	train_accuracy: 88.1060, accuracy_top-1: 94.2800, accuracy_top-5: 99.8600
2022-11-20 17:44:27,131 - mmcls - INFO - Epoch [125][100/391]	lr: 1.000e-02, eta: 0:44:30, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5034
2022-11-20 17:44:38,204 - mmcls - INFO - Epoch [125][200/391]	lr: 1.000e-02, eta: 0:44:22, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5442
2022-11-20 17:44:49,269 - mmcls - INFO - Epoch [125][300/391]	lr: 1.000e-02, eta: 0:44:14, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5303
2022-11-20 17:45:02,299 - mmcls - INFO - Epoch(val) [125][79]	train_accuracy: 88.4080, accuracy_top-1: 94.0900, accuracy_top-5: 99.8300
2022-11-20 17:45:15,442 - mmcls - INFO - Epoch [126][100/391]	lr: 1.000e-02, eta: 0:43:55, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5323
2022-11-20 17:45:26,483 - mmcls - INFO - Epoch [126][200/391]	lr: 1.000e-02, eta: 0:43:47, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5976
2022-11-20 17:45:37,529 - mmcls - INFO - Epoch [126][300/391]	lr: 1.000e-02, eta: 0:43:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5268
2022-11-20 17:45:50,567 - mmcls - INFO - Epoch(val) [126][79]	train_accuracy: 88.0360, accuracy_top-1: 94.3600, accuracy_top-5: 99.8600
2022-11-20 17:46:03,706 - mmcls - INFO - Epoch [127][100/391]	lr: 1.000e-02, eta: 0:43:19, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5749
2022-11-20 17:46:14,720 - mmcls - INFO - Epoch [127][200/391]	lr: 1.000e-02, eta: 0:43:11, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5550
2022-11-20 17:46:25,741 - mmcls - INFO - Epoch [127][300/391]	lr: 1.000e-02, eta: 0:43:04, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6828
2022-11-20 17:46:38,687 - mmcls - INFO - Epoch(val) [127][79]	train_accuracy: 86.8140, accuracy_top-1: 94.3000, accuracy_top-5: 99.8700
2022-11-20 17:46:51,816 - mmcls - INFO - Epoch [128][100/391]	lr: 1.000e-02, eta: 0:42:44, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4932
2022-11-20 17:47:02,824 - mmcls - INFO - Epoch [128][200/391]	lr: 1.000e-02, eta: 0:42:36, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4690
2022-11-20 17:47:13,837 - mmcls - INFO - Epoch [128][300/391]	lr: 1.000e-02, eta: 0:42:28, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5643
2022-11-20 17:47:26,830 - mmcls - INFO - Epoch(val) [128][79]	train_accuracy: 89.1860, accuracy_top-1: 94.0800, accuracy_top-5: 99.8700
2022-11-20 17:47:39,953 - mmcls - INFO - Epoch [129][100/391]	lr: 1.000e-02, eta: 0:42:09, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5756
2022-11-20 17:47:50,958 - mmcls - INFO - Epoch [129][200/391]	lr: 1.000e-02, eta: 0:42:01, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4847
2022-11-20 17:48:01,979 - mmcls - INFO - Epoch [129][300/391]	lr: 1.000e-02, eta: 0:41:53, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5354
2022-11-20 17:48:14,974 - mmcls - INFO - Epoch(val) [129][79]	train_accuracy: 88.1480, accuracy_top-1: 94.2700, accuracy_top-5: 99.8500
2022-11-20 17:48:28,125 - mmcls - INFO - Epoch [130][100/391]	lr: 1.000e-02, eta: 0:41:33, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5074
2022-11-20 17:48:39,129 - mmcls - INFO - Epoch [130][200/391]	lr: 1.000e-02, eta: 0:41:25, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4476
2022-11-20 17:48:50,140 - mmcls - INFO - Epoch [130][300/391]	lr: 1.000e-02, eta: 0:41:17, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5520
2022-11-20 17:49:00,132 - mmcls - INFO - Saving checkpoint at 130 epochs
2022-11-20 17:49:03,166 - mmcls - INFO - Epoch(val) [130][79]	train_accuracy: 88.8000, accuracy_top-1: 93.7400, accuracy_top-5: 99.8100
2022-11-20 17:49:16,296 - mmcls - INFO - Epoch [131][100/391]	lr: 1.000e-02, eta: 0:40:58, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5151
2022-11-20 17:49:27,307 - mmcls - INFO - Epoch [131][200/391]	lr: 1.000e-02, eta: 0:40:50, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5150
2022-11-20 17:49:38,337 - mmcls - INFO - Epoch [131][300/391]	lr: 1.000e-02, eta: 0:40:42, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5405
2022-11-20 17:49:51,318 - mmcls - INFO - Epoch(val) [131][79]	train_accuracy: 88.5120, accuracy_top-1: 94.1700, accuracy_top-5: 99.8100
2022-11-20 17:50:04,461 - mmcls - INFO - Epoch [132][100/391]	lr: 1.000e-02, eta: 0:40:23, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.6032
2022-11-20 17:50:15,475 - mmcls - INFO - Epoch [132][200/391]	lr: 1.000e-02, eta: 0:40:15, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5582
2022-11-20 17:50:26,473 - mmcls - INFO - Epoch [132][300/391]	lr: 1.000e-02, eta: 0:40:07, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5258
2022-11-20 17:50:39,449 - mmcls - INFO - Epoch(val) [132][79]	train_accuracy: 87.3200, accuracy_top-1: 94.0200, accuracy_top-5: 99.8600
2022-11-20 17:50:52,611 - mmcls - INFO - Epoch [133][100/391]	lr: 1.000e-02, eta: 0:39:47, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5156
2022-11-20 17:51:03,622 - mmcls - INFO - Epoch [133][200/391]	lr: 1.000e-02, eta: 0:39:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4452
2022-11-20 17:51:14,641 - mmcls - INFO - Epoch [133][300/391]	lr: 1.000e-02, eta: 0:39:31, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4470
2022-11-20 17:51:27,521 - mmcls - INFO - Epoch(val) [133][79]	train_accuracy: 89.2000, accuracy_top-1: 94.3200, accuracy_top-5: 99.8600
2022-11-20 17:51:40,689 - mmcls - INFO - Epoch [134][100/391]	lr: 1.000e-02, eta: 0:39:12, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5251
2022-11-20 17:51:51,707 - mmcls - INFO - Epoch [134][200/391]	lr: 1.000e-02, eta: 0:39:04, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5559
2022-11-20 17:52:02,754 - mmcls - INFO - Epoch [134][300/391]	lr: 1.000e-02, eta: 0:38:56, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5089
2022-11-20 17:52:15,832 - mmcls - INFO - Epoch(val) [134][79]	train_accuracy: 88.2320, accuracy_top-1: 94.4400, accuracy_top-5: 99.9000
2022-11-20 17:52:28,975 - mmcls - INFO - Epoch [135][100/391]	lr: 1.000e-02, eta: 0:38:37, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.6102
2022-11-20 17:52:39,989 - mmcls - INFO - Epoch [135][200/391]	lr: 1.000e-02, eta: 0:38:29, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4964
2022-11-20 17:52:50,982 - mmcls - INFO - Epoch [135][300/391]	lr: 1.000e-02, eta: 0:38:21, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4706
2022-11-20 17:53:04,052 - mmcls - INFO - Epoch(val) [135][79]	train_accuracy: 86.9160, accuracy_top-1: 94.0500, accuracy_top-5: 99.8100
2022-11-20 17:53:17,175 - mmcls - INFO - Epoch [136][100/391]	lr: 1.000e-02, eta: 0:38:01, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5242
2022-11-20 17:53:28,209 - mmcls - INFO - Epoch [136][200/391]	lr: 1.000e-02, eta: 0:37:53, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5360
2022-11-20 17:53:39,232 - mmcls - INFO - Epoch [136][300/391]	lr: 1.000e-02, eta: 0:37:45, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4546
2022-11-20 17:53:52,092 - mmcls - INFO - Epoch(val) [136][79]	train_accuracy: 88.8460, accuracy_top-1: 94.3400, accuracy_top-5: 99.8300
2022-11-20 17:54:05,247 - mmcls - INFO - Epoch [137][100/391]	lr: 1.000e-02, eta: 0:37:26, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5519
2022-11-20 17:54:16,247 - mmcls - INFO - Epoch [137][200/391]	lr: 1.000e-02, eta: 0:37:18, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4699
2022-11-20 17:54:27,255 - mmcls - INFO - Epoch [137][300/391]	lr: 1.000e-02, eta: 0:37:10, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5104
2022-11-20 17:54:40,246 - mmcls - INFO - Epoch(val) [137][79]	train_accuracy: 88.5540, accuracy_top-1: 93.1800, accuracy_top-5: 99.8400
2022-11-20 17:54:53,385 - mmcls - INFO - Epoch [138][100/391]	lr: 1.000e-02, eta: 0:36:51, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5260
2022-11-20 17:55:04,405 - mmcls - INFO - Epoch [138][200/391]	lr: 1.000e-02, eta: 0:36:43, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.6101
2022-11-20 17:55:15,441 - mmcls - INFO - Epoch [138][300/391]	lr: 1.000e-02, eta: 0:36:35, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5233
2022-11-20 17:55:28,462 - mmcls - INFO - Epoch(val) [138][79]	train_accuracy: 88.1300, accuracy_top-1: 94.1900, accuracy_top-5: 99.8300
2022-11-20 17:55:41,603 - mmcls - INFO - Epoch [139][100/391]	lr: 1.000e-02, eta: 0:36:16, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4610
2022-11-20 17:55:52,617 - mmcls - INFO - Epoch [139][200/391]	lr: 1.000e-02, eta: 0:36:07, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4739
2022-11-20 17:56:03,631 - mmcls - INFO - Epoch [139][300/391]	lr: 1.000e-02, eta: 0:35:59, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4850
2022-11-20 17:56:16,499 - mmcls - INFO - Epoch(val) [139][79]	train_accuracy: 89.4700, accuracy_top-1: 94.0000, accuracy_top-5: 99.8900
2022-11-20 17:56:29,621 - mmcls - INFO - Epoch [140][100/391]	lr: 1.000e-02, eta: 0:35:40, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5583
2022-11-20 17:56:40,639 - mmcls - INFO - Epoch [140][200/391]	lr: 1.000e-02, eta: 0:35:32, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4872
2022-11-20 17:56:51,652 - mmcls - INFO - Epoch [140][300/391]	lr: 1.000e-02, eta: 0:35:24, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5913
2022-11-20 17:57:01,633 - mmcls - INFO - Saving checkpoint at 140 epochs
2022-11-20 17:57:04,899 - mmcls - INFO - Epoch(val) [140][79]	train_accuracy: 88.0440, accuracy_top-1: 94.1600, accuracy_top-5: 99.8400
2022-11-20 17:57:18,074 - mmcls - INFO - Epoch [141][100/391]	lr: 1.000e-02, eta: 0:35:05, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5102
2022-11-20 17:57:29,084 - mmcls - INFO - Epoch [141][200/391]	lr: 1.000e-02, eta: 0:34:57, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5302
2022-11-20 17:57:40,101 - mmcls - INFO - Epoch [141][300/391]	lr: 1.000e-02, eta: 0:34:49, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5198
2022-11-20 17:57:52,964 - mmcls - INFO - Epoch(val) [141][79]	train_accuracy: 89.3520, accuracy_top-1: 93.9600, accuracy_top-5: 99.8800
2022-11-20 17:58:06,118 - mmcls - INFO - Epoch [142][100/391]	lr: 1.000e-02, eta: 0:34:30, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5105
2022-11-20 17:58:17,123 - mmcls - INFO - Epoch [142][200/391]	lr: 1.000e-02, eta: 0:34:22, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5042
2022-11-20 17:58:28,135 - mmcls - INFO - Epoch [142][300/391]	lr: 1.000e-02, eta: 0:34:13, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4972
2022-11-20 17:58:41,092 - mmcls - INFO - Epoch(val) [142][79]	train_accuracy: 90.3060, accuracy_top-1: 94.3400, accuracy_top-5: 99.8200
2022-11-20 17:58:54,238 - mmcls - INFO - Epoch [143][100/391]	lr: 1.000e-02, eta: 0:33:54, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4926
2022-11-20 17:59:05,264 - mmcls - INFO - Epoch [143][200/391]	lr: 1.000e-02, eta: 0:33:46, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5073
2022-11-20 17:59:16,297 - mmcls - INFO - Epoch [143][300/391]	lr: 1.000e-02, eta: 0:33:38, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5079
2022-11-20 17:59:29,244 - mmcls - INFO - Epoch(val) [143][79]	train_accuracy: 89.3640, accuracy_top-1: 93.8700, accuracy_top-5: 99.8200
2022-11-20 17:59:42,359 - mmcls - INFO - Epoch [144][100/391]	lr: 1.000e-02, eta: 0:33:19, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4553
2022-11-20 17:59:53,364 - mmcls - INFO - Epoch [144][200/391]	lr: 1.000e-02, eta: 0:33:11, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4502
2022-11-20 18:00:04,391 - mmcls - INFO - Epoch [144][300/391]	lr: 1.000e-02, eta: 0:33:03, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5058
2022-11-20 18:00:17,204 - mmcls - INFO - Epoch(val) [144][79]	train_accuracy: 88.8240, accuracy_top-1: 93.7700, accuracy_top-5: 99.8100
2022-11-20 18:00:30,312 - mmcls - INFO - Epoch [145][100/391]	lr: 1.000e-02, eta: 0:32:44, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4029
2022-11-20 18:00:41,337 - mmcls - INFO - Epoch [145][200/391]	lr: 1.000e-02, eta: 0:32:36, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4334
2022-11-20 18:00:52,352 - mmcls - INFO - Epoch [145][300/391]	lr: 1.000e-02, eta: 0:32:27, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4508
2022-11-20 18:01:05,321 - mmcls - INFO - Epoch(val) [145][79]	train_accuracy: 90.4320, accuracy_top-1: 94.1100, accuracy_top-5: 99.8700
2022-11-20 18:01:18,449 - mmcls - INFO - Epoch [146][100/391]	lr: 1.000e-02, eta: 0:32:09, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5445
2022-11-20 18:01:29,446 - mmcls - INFO - Epoch [146][200/391]	lr: 1.000e-02, eta: 0:32:00, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4448
2022-11-20 18:01:40,482 - mmcls - INFO - Epoch [146][300/391]	lr: 1.000e-02, eta: 0:31:52, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4931
2022-11-20 18:01:53,436 - mmcls - INFO - Epoch(val) [146][79]	train_accuracy: 88.9760, accuracy_top-1: 93.6000, accuracy_top-5: 99.8300
2022-11-20 18:02:06,560 - mmcls - INFO - Epoch [147][100/391]	lr: 1.000e-02, eta: 0:31:33, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5425
2022-11-20 18:02:17,597 - mmcls - INFO - Epoch [147][200/391]	lr: 1.000e-02, eta: 0:31:25, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5369
2022-11-20 18:02:28,653 - mmcls - INFO - Epoch [147][300/391]	lr: 1.000e-02, eta: 0:31:17, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5461
2022-11-20 18:02:41,544 - mmcls - INFO - Epoch(val) [147][79]	train_accuracy: 87.4720, accuracy_top-1: 93.3700, accuracy_top-5: 99.8300
2022-11-20 18:02:54,709 - mmcls - INFO - Epoch [148][100/391]	lr: 1.000e-02, eta: 0:30:58, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4329
2022-11-20 18:03:05,766 - mmcls - INFO - Epoch [148][200/391]	lr: 1.000e-02, eta: 0:30:50, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5696
2022-11-20 18:03:16,818 - mmcls - INFO - Epoch [148][300/391]	lr: 1.000e-02, eta: 0:30:42, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5210
2022-11-20 18:03:29,753 - mmcls - INFO - Epoch(val) [148][79]	train_accuracy: 88.6520, accuracy_top-1: 94.1000, accuracy_top-5: 99.8300
2022-11-20 18:03:42,880 - mmcls - INFO - Epoch [149][100/391]	lr: 1.000e-02, eta: 0:30:23, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4856
2022-11-20 18:03:53,911 - mmcls - INFO - Epoch [149][200/391]	lr: 1.000e-02, eta: 0:30:15, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5546
2022-11-20 18:04:04,921 - mmcls - INFO - Epoch [149][300/391]	lr: 1.000e-02, eta: 0:30:06, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4446
2022-11-20 18:04:17,968 - mmcls - INFO - Epoch(val) [149][79]	train_accuracy: 88.0900, accuracy_top-1: 93.7300, accuracy_top-5: 99.8400
2022-11-20 18:04:31,122 - mmcls - INFO - Epoch [150][100/391]	lr: 1.000e-02, eta: 0:29:48, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4056
2022-11-20 18:04:42,143 - mmcls - INFO - Epoch [150][200/391]	lr: 1.000e-02, eta: 0:29:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4180
2022-11-20 18:04:53,168 - mmcls - INFO - Epoch [150][300/391]	lr: 1.000e-02, eta: 0:29:31, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5503
2022-11-20 18:05:03,149 - mmcls - INFO - Saving checkpoint at 150 epochs
2022-11-20 18:05:06,183 - mmcls - INFO - Epoch(val) [150][79]	train_accuracy: 89.9060, accuracy_top-1: 93.8500, accuracy_top-5: 99.8300
2022-11-20 18:05:19,315 - mmcls - INFO - Epoch [151][100/391]	lr: 1.000e-03, eta: 0:29:12, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4732
2022-11-20 18:05:30,322 - mmcls - INFO - Epoch [151][200/391]	lr: 1.000e-03, eta: 0:29:04, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4761
2022-11-20 18:05:41,337 - mmcls - INFO - Epoch [151][300/391]	lr: 1.000e-03, eta: 0:28:56, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4787
2022-11-20 18:05:54,269 - mmcls - INFO - Epoch(val) [151][79]	train_accuracy: 90.5880, accuracy_top-1: 94.6600, accuracy_top-5: 99.8700
2022-11-20 18:06:07,410 - mmcls - INFO - Epoch [152][100/391]	lr: 1.000e-03, eta: 0:28:37, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4925
2022-11-20 18:06:18,474 - mmcls - INFO - Epoch [152][200/391]	lr: 1.000e-03, eta: 0:28:29, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4990
2022-11-20 18:06:29,509 - mmcls - INFO - Epoch [152][300/391]	lr: 1.000e-03, eta: 0:28:20, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4544
2022-11-20 18:06:42,511 - mmcls - INFO - Epoch(val) [152][79]	train_accuracy: 89.1640, accuracy_top-1: 94.8800, accuracy_top-5: 99.8800
2022-11-20 18:06:55,669 - mmcls - INFO - Epoch [153][100/391]	lr: 1.000e-03, eta: 0:28:02, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4317
2022-11-20 18:07:06,740 - mmcls - INFO - Epoch [153][200/391]	lr: 1.000e-03, eta: 0:27:53, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5601
2022-11-20 18:07:17,783 - mmcls - INFO - Epoch [153][300/391]	lr: 1.000e-03, eta: 0:27:45, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4243
2022-11-20 18:07:30,632 - mmcls - INFO - Epoch(val) [153][79]	train_accuracy: 89.8260, accuracy_top-1: 94.9100, accuracy_top-5: 99.8600
2022-11-20 18:07:43,797 - mmcls - INFO - Epoch [154][100/391]	lr: 1.000e-03, eta: 0:27:27, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4440
2022-11-20 18:07:54,849 - mmcls - INFO - Epoch [154][200/391]	lr: 1.000e-03, eta: 0:27:18, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4199
2022-11-20 18:08:05,891 - mmcls - INFO - Epoch [154][300/391]	lr: 1.000e-03, eta: 0:27:10, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4694
2022-11-20 18:08:18,896 - mmcls - INFO - Epoch(val) [154][79]	train_accuracy: 89.7500, accuracy_top-1: 94.9500, accuracy_top-5: 99.8500
2022-11-20 18:08:32,038 - mmcls - INFO - Epoch [155][100/391]	lr: 1.000e-03, eta: 0:26:51, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5015
2022-11-20 18:08:43,073 - mmcls - INFO - Epoch [155][200/391]	lr: 1.000e-03, eta: 0:26:43, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5663
2022-11-20 18:08:54,147 - mmcls - INFO - Epoch [155][300/391]	lr: 1.000e-03, eta: 0:26:34, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5332
2022-11-20 18:09:07,236 - mmcls - INFO - Epoch(val) [155][79]	train_accuracy: 89.4800, accuracy_top-1: 94.9200, accuracy_top-5: 99.8700
2022-11-20 18:09:20,396 - mmcls - INFO - Epoch [156][100/391]	lr: 1.000e-03, eta: 0:26:16, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4765
2022-11-20 18:09:31,441 - mmcls - INFO - Epoch [156][200/391]	lr: 1.000e-03, eta: 0:26:08, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4043
2022-11-20 18:09:42,510 - mmcls - INFO - Epoch [156][300/391]	lr: 1.000e-03, eta: 0:25:59, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4558
2022-11-20 18:09:55,398 - mmcls - INFO - Epoch(val) [156][79]	train_accuracy: 90.5660, accuracy_top-1: 94.8200, accuracy_top-5: 99.8800
2022-11-20 18:10:08,550 - mmcls - INFO - Epoch [157][100/391]	lr: 1.000e-03, eta: 0:25:41, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4833
2022-11-20 18:10:19,592 - mmcls - INFO - Epoch [157][200/391]	lr: 1.000e-03, eta: 0:25:32, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4783
2022-11-20 18:10:30,639 - mmcls - INFO - Epoch [157][300/391]	lr: 1.000e-03, eta: 0:25:24, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4779
2022-11-20 18:10:43,603 - mmcls - INFO - Epoch(val) [157][79]	train_accuracy: 90.1300, accuracy_top-1: 94.8800, accuracy_top-5: 99.8900
2022-11-20 18:10:56,762 - mmcls - INFO - Epoch [158][100/391]	lr: 1.000e-03, eta: 0:25:06, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.3903
2022-11-20 18:11:07,804 - mmcls - INFO - Epoch [158][200/391]	lr: 1.000e-03, eta: 0:24:57, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5592
2022-11-20 18:11:18,829 - mmcls - INFO - Epoch [158][300/391]	lr: 1.000e-03, eta: 0:24:49, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4198
2022-11-20 18:11:31,732 - mmcls - INFO - Epoch(val) [158][79]	train_accuracy: 90.0520, accuracy_top-1: 94.8800, accuracy_top-5: 99.8700
2022-11-20 18:11:44,855 - mmcls - INFO - Epoch [159][100/391]	lr: 1.000e-03, eta: 0:24:30, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4901
2022-11-20 18:11:55,868 - mmcls - INFO - Epoch [159][200/391]	lr: 1.000e-03, eta: 0:24:22, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3990
2022-11-20 18:12:06,913 - mmcls - INFO - Epoch [159][300/391]	lr: 1.000e-03, eta: 0:24:13, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4479
2022-11-20 18:12:19,765 - mmcls - INFO - Epoch(val) [159][79]	train_accuracy: 91.2800, accuracy_top-1: 94.8900, accuracy_top-5: 99.8900
2022-11-20 18:12:32,930 - mmcls - INFO - Epoch [160][100/391]	lr: 1.000e-03, eta: 0:23:55, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4467
2022-11-20 18:12:43,962 - mmcls - INFO - Epoch [160][200/391]	lr: 1.000e-03, eta: 0:23:47, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5067
2022-11-20 18:12:54,991 - mmcls - INFO - Epoch [160][300/391]	lr: 1.000e-03, eta: 0:23:38, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5053
2022-11-20 18:13:04,965 - mmcls - INFO - Saving checkpoint at 160 epochs
2022-11-20 18:13:08,166 - mmcls - INFO - Epoch(val) [160][79]	train_accuracy: 89.3760, accuracy_top-1: 94.9800, accuracy_top-5: 99.8900
2022-11-20 18:13:21,304 - mmcls - INFO - Epoch [161][100/391]	lr: 1.000e-03, eta: 0:23:20, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4312
2022-11-20 18:13:32,298 - mmcls - INFO - Epoch [161][200/391]	lr: 1.000e-03, eta: 0:23:11, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4943
2022-11-20 18:13:43,319 - mmcls - INFO - Epoch [161][300/391]	lr: 1.000e-03, eta: 0:23:03, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4988
2022-11-20 18:13:56,124 - mmcls - INFO - Epoch(val) [161][79]	train_accuracy: 89.7100, accuracy_top-1: 95.0200, accuracy_top-5: 99.9000
2022-11-20 18:14:09,294 - mmcls - INFO - Epoch [162][100/391]	lr: 1.000e-03, eta: 0:22:45, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4786
2022-11-20 18:14:20,322 - mmcls - INFO - Epoch [162][200/391]	lr: 1.000e-03, eta: 0:22:36, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4259
2022-11-20 18:14:31,355 - mmcls - INFO - Epoch [162][300/391]	lr: 1.000e-03, eta: 0:22:28, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5396
2022-11-20 18:14:44,295 - mmcls - INFO - Epoch(val) [162][79]	train_accuracy: 89.8600, accuracy_top-1: 94.9700, accuracy_top-5: 99.8900
2022-11-20 18:14:57,441 - mmcls - INFO - Epoch [163][100/391]	lr: 1.000e-03, eta: 0:22:09, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4276
2022-11-20 18:15:08,465 - mmcls - INFO - Epoch [163][200/391]	lr: 1.000e-03, eta: 0:22:01, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4847
2022-11-20 18:15:19,481 - mmcls - INFO - Epoch [163][300/391]	lr: 1.000e-03, eta: 0:21:52, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3756
2022-11-20 18:15:32,458 - mmcls - INFO - Epoch(val) [163][79]	train_accuracy: 91.7720, accuracy_top-1: 95.0100, accuracy_top-5: 99.8500
2022-11-20 18:15:45,559 - mmcls - INFO - Epoch [164][100/391]	lr: 1.000e-03, eta: 0:21:34, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4508
2022-11-20 18:15:56,599 - mmcls - INFO - Epoch [164][200/391]	lr: 1.000e-03, eta: 0:21:26, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4775
2022-11-20 18:16:07,618 - mmcls - INFO - Epoch [164][300/391]	lr: 1.000e-03, eta: 0:21:17, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5207
2022-11-20 18:16:20,574 - mmcls - INFO - Epoch(val) [164][79]	train_accuracy: 90.4040, accuracy_top-1: 94.8700, accuracy_top-5: 99.8900
2022-11-20 18:16:33,702 - mmcls - INFO - Epoch [165][100/391]	lr: 1.000e-03, eta: 0:20:59, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4292
2022-11-20 18:16:44,727 - mmcls - INFO - Epoch [165][200/391]	lr: 1.000e-03, eta: 0:20:50, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4316
2022-11-20 18:16:55,761 - mmcls - INFO - Epoch [165][300/391]	lr: 1.000e-03, eta: 0:20:42, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3975
2022-11-20 18:17:08,725 - mmcls - INFO - Epoch(val) [165][79]	train_accuracy: 91.1060, accuracy_top-1: 94.8600, accuracy_top-5: 99.8800
2022-11-20 18:17:21,887 - mmcls - INFO - Epoch [166][100/391]	lr: 1.000e-03, eta: 0:20:24, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4108
2022-11-20 18:17:32,893 - mmcls - INFO - Epoch [166][200/391]	lr: 1.000e-03, eta: 0:20:15, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3977
2022-11-20 18:17:43,926 - mmcls - INFO - Epoch [166][300/391]	lr: 1.000e-03, eta: 0:20:06, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3946
2022-11-20 18:17:57,003 - mmcls - INFO - Epoch(val) [166][79]	train_accuracy: 91.3600, accuracy_top-1: 94.8400, accuracy_top-5: 99.9000
2022-11-20 18:18:10,145 - mmcls - INFO - Epoch [167][100/391]	lr: 1.000e-03, eta: 0:19:48, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.3701
2022-11-20 18:18:21,176 - mmcls - INFO - Epoch [167][200/391]	lr: 1.000e-03, eta: 0:19:40, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4718
2022-11-20 18:18:32,195 - mmcls - INFO - Epoch [167][300/391]	lr: 1.000e-03, eta: 0:19:31, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4316
2022-11-20 18:18:45,025 - mmcls - INFO - Epoch(val) [167][79]	train_accuracy: 90.9720, accuracy_top-1: 94.7800, accuracy_top-5: 99.8900
2022-11-20 18:18:58,153 - mmcls - INFO - Epoch [168][100/391]	lr: 1.000e-03, eta: 0:19:13, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.3489
2022-11-20 18:19:09,167 - mmcls - INFO - Epoch [168][200/391]	lr: 1.000e-03, eta: 0:19:04, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3525
2022-11-20 18:19:20,193 - mmcls - INFO - Epoch [168][300/391]	lr: 1.000e-03, eta: 0:18:56, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4731
2022-11-20 18:19:33,139 - mmcls - INFO - Epoch(val) [168][79]	train_accuracy: 92.3820, accuracy_top-1: 94.9000, accuracy_top-5: 99.8900
2022-11-20 18:19:46,247 - mmcls - INFO - Epoch [169][100/391]	lr: 1.000e-03, eta: 0:18:38, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5017
2022-11-20 18:19:57,246 - mmcls - INFO - Epoch [169][200/391]	lr: 1.000e-03, eta: 0:18:29, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5143
2022-11-20 18:20:08,261 - mmcls - INFO - Epoch [169][300/391]	lr: 1.000e-03, eta: 0:18:21, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4939
2022-11-20 18:20:21,231 - mmcls - INFO - Epoch(val) [169][79]	train_accuracy: 90.1160, accuracy_top-1: 94.8900, accuracy_top-5: 99.8700
2022-11-20 18:20:34,368 - mmcls - INFO - Epoch [170][100/391]	lr: 1.000e-03, eta: 0:18:03, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4569
2022-11-20 18:20:45,382 - mmcls - INFO - Epoch [170][200/391]	lr: 1.000e-03, eta: 0:17:54, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4579
2022-11-20 18:20:56,401 - mmcls - INFO - Epoch [170][300/391]	lr: 1.000e-03, eta: 0:17:45, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4561
2022-11-20 18:21:06,367 - mmcls - INFO - Saving checkpoint at 170 epochs
2022-11-20 18:21:09,561 - mmcls - INFO - Epoch(val) [170][79]	train_accuracy: 90.6020, accuracy_top-1: 94.9000, accuracy_top-5: 99.8700
2022-11-20 18:21:22,697 - mmcls - INFO - Epoch [171][100/391]	lr: 1.000e-03, eta: 0:17:27, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5032
2022-11-20 18:21:33,696 - mmcls - INFO - Epoch [171][200/391]	lr: 1.000e-03, eta: 0:17:19, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4169
2022-11-20 18:21:44,698 - mmcls - INFO - Epoch [171][300/391]	lr: 1.000e-03, eta: 0:17:10, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4530
2022-11-20 18:21:57,806 - mmcls - INFO - Epoch(val) [171][79]	train_accuracy: 90.7560, accuracy_top-1: 94.9100, accuracy_top-5: 99.8800
2022-11-20 18:22:11,038 - mmcls - INFO - Epoch [172][100/391]	lr: 1.000e-03, eta: 0:16:52, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.5490
2022-11-20 18:22:22,087 - mmcls - INFO - Epoch [172][200/391]	lr: 1.000e-03, eta: 0:16:43, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5155
2022-11-20 18:22:33,129 - mmcls - INFO - Epoch [172][300/391]	lr: 1.000e-03, eta: 0:16:35, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4089
2022-11-20 18:22:46,092 - mmcls - INFO - Epoch(val) [172][79]	train_accuracy: 90.4620, accuracy_top-1: 94.9200, accuracy_top-5: 99.9200
2022-11-20 18:22:59,241 - mmcls - INFO - Epoch [173][100/391]	lr: 1.000e-03, eta: 0:16:17, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4365
2022-11-20 18:23:10,276 - mmcls - INFO - Epoch [173][200/391]	lr: 1.000e-03, eta: 0:16:08, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4513
2022-11-20 18:23:21,311 - mmcls - INFO - Epoch [173][300/391]	lr: 1.000e-03, eta: 0:15:59, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3875
2022-11-20 18:23:34,172 - mmcls - INFO - Epoch(val) [173][79]	train_accuracy: 91.3040, accuracy_top-1: 95.0200, accuracy_top-5: 99.8600
2022-11-20 18:23:47,334 - mmcls - INFO - Epoch [174][100/391]	lr: 1.000e-03, eta: 0:15:42, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4915
2022-11-20 18:23:58,349 - mmcls - INFO - Epoch [174][200/391]	lr: 1.000e-03, eta: 0:15:33, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5120
2022-11-20 18:24:09,391 - mmcls - INFO - Epoch [174][300/391]	lr: 1.000e-03, eta: 0:15:24, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4045
2022-11-20 18:24:22,328 - mmcls - INFO - Epoch(val) [174][79]	train_accuracy: 89.7360, accuracy_top-1: 94.9200, accuracy_top-5: 99.8900
2022-11-20 18:24:35,469 - mmcls - INFO - Epoch [175][100/391]	lr: 1.000e-03, eta: 0:15:06, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4138
2022-11-20 18:24:46,465 - mmcls - INFO - Epoch [175][200/391]	lr: 1.000e-03, eta: 0:14:58, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4100
2022-11-20 18:24:57,496 - mmcls - INFO - Epoch [175][300/391]	lr: 1.000e-03, eta: 0:14:49, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4088
2022-11-20 18:25:10,509 - mmcls - INFO - Epoch(val) [175][79]	train_accuracy: 91.1320, accuracy_top-1: 94.9600, accuracy_top-5: 99.8800
2022-11-20 18:25:23,632 - mmcls - INFO - Epoch [176][100/391]	lr: 1.000e-03, eta: 0:14:31, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4541
2022-11-20 18:25:34,637 - mmcls - INFO - Epoch [176][200/391]	lr: 1.000e-03, eta: 0:14:22, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3692
2022-11-20 18:25:45,655 - mmcls - INFO - Epoch [176][300/391]	lr: 1.000e-03, eta: 0:14:14, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4583
2022-11-20 18:25:58,492 - mmcls - INFO - Epoch(val) [176][79]	train_accuracy: 90.4700, accuracy_top-1: 94.8500, accuracy_top-5: 99.8600
2022-11-20 18:26:11,644 - mmcls - INFO - Epoch [177][100/391]	lr: 1.000e-03, eta: 0:13:56, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.3924
2022-11-20 18:26:22,648 - mmcls - INFO - Epoch [177][200/391]	lr: 1.000e-03, eta: 0:13:47, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3836
2022-11-20 18:26:33,648 - mmcls - INFO - Epoch [177][300/391]	lr: 1.000e-03, eta: 0:13:38, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4520
2022-11-20 18:26:46,563 - mmcls - INFO - Epoch(val) [177][79]	train_accuracy: 91.3180, accuracy_top-1: 94.7800, accuracy_top-5: 99.8500
2022-11-20 18:26:59,781 - mmcls - INFO - Epoch [178][100/391]	lr: 1.000e-03, eta: 0:13:21, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.4331
2022-11-20 18:27:10,834 - mmcls - INFO - Epoch [178][200/391]	lr: 1.000e-03, eta: 0:13:12, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4030
2022-11-20 18:27:21,896 - mmcls - INFO - Epoch [178][300/391]	lr: 1.000e-03, eta: 0:13:03, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4704
2022-11-20 18:27:34,878 - mmcls - INFO - Epoch(val) [178][79]	train_accuracy: 90.1440, accuracy_top-1: 94.9900, accuracy_top-5: 99.8300
2022-11-20 18:27:48,023 - mmcls - INFO - Epoch [179][100/391]	lr: 1.000e-03, eta: 0:12:45, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4688
2022-11-20 18:27:59,036 - mmcls - INFO - Epoch [179][200/391]	lr: 1.000e-03, eta: 0:12:37, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5596
2022-11-20 18:28:10,062 - mmcls - INFO - Epoch [179][300/391]	lr: 1.000e-03, eta: 0:12:28, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4482
2022-11-20 18:28:22,866 - mmcls - INFO - Epoch(val) [179][79]	train_accuracy: 90.3220, accuracy_top-1: 94.8800, accuracy_top-5: 99.8400
2022-11-20 18:28:35,990 - mmcls - INFO - Epoch [180][100/391]	lr: 1.000e-03, eta: 0:12:10, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5064
2022-11-20 18:28:46,995 - mmcls - INFO - Epoch [180][200/391]	lr: 1.000e-03, eta: 0:12:01, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5738
2022-11-20 18:28:58,008 - mmcls - INFO - Epoch [180][300/391]	lr: 1.000e-03, eta: 0:11:53, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4114
2022-11-20 18:29:07,969 - mmcls - INFO - Saving checkpoint at 180 epochs
2022-11-20 18:29:11,106 - mmcls - INFO - Epoch(val) [180][79]	train_accuracy: 90.3460, accuracy_top-1: 94.8700, accuracy_top-5: 99.8600
2022-11-20 18:29:24,249 - mmcls - INFO - Epoch [181][100/391]	lr: 1.000e-04, eta: 0:11:35, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4433
2022-11-20 18:29:35,332 - mmcls - INFO - Epoch [181][200/391]	lr: 1.000e-04, eta: 0:11:26, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4768
2022-11-20 18:29:46,395 - mmcls - INFO - Epoch [181][300/391]	lr: 1.000e-04, eta: 0:11:17, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4604
2022-11-20 18:29:59,317 - mmcls - INFO - Epoch(val) [181][79]	train_accuracy: 89.6820, accuracy_top-1: 94.9200, accuracy_top-5: 99.8500
2022-11-20 18:30:12,487 - mmcls - INFO - Epoch [182][100/391]	lr: 1.000e-04, eta: 0:11:00, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4333
2022-11-20 18:30:23,525 - mmcls - INFO - Epoch [182][200/391]	lr: 1.000e-04, eta: 0:10:51, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3876
2022-11-20 18:30:34,572 - mmcls - INFO - Epoch [182][300/391]	lr: 1.000e-04, eta: 0:10:42, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4739
2022-11-20 18:30:47,509 - mmcls - INFO - Epoch(val) [182][79]	train_accuracy: 91.7260, accuracy_top-1: 94.8900, accuracy_top-5: 99.8600
2022-11-20 18:31:00,662 - mmcls - INFO - Epoch [183][100/391]	lr: 1.000e-04, eta: 0:10:25, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4683
2022-11-20 18:31:11,689 - mmcls - INFO - Epoch [183][200/391]	lr: 1.000e-04, eta: 0:10:16, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4619
2022-11-20 18:31:22,726 - mmcls - INFO - Epoch [183][300/391]	lr: 1.000e-04, eta: 0:10:07, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4633
2022-11-20 18:31:35,783 - mmcls - INFO - Epoch(val) [183][79]	train_accuracy: 90.8760, accuracy_top-1: 94.8600, accuracy_top-5: 99.8500
2022-11-20 18:31:48,977 - mmcls - INFO - Epoch [184][100/391]	lr: 1.000e-04, eta: 0:09:49, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.3702
2022-11-20 18:32:00,032 - mmcls - INFO - Epoch [184][200/391]	lr: 1.000e-04, eta: 0:09:40, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4598
2022-11-20 18:32:11,092 - mmcls - INFO - Epoch [184][300/391]	lr: 1.000e-04, eta: 0:09:32, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5101
2022-11-20 18:32:24,035 - mmcls - INFO - Epoch(val) [184][79]	train_accuracy: 90.5780, accuracy_top-1: 94.8900, accuracy_top-5: 99.8400
2022-11-20 18:32:37,174 - mmcls - INFO - Epoch [185][100/391]	lr: 1.000e-04, eta: 0:09:14, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4376
2022-11-20 18:32:48,193 - mmcls - INFO - Epoch [185][200/391]	lr: 1.000e-04, eta: 0:09:05, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4480
2022-11-20 18:32:59,227 - mmcls - INFO - Epoch [185][300/391]	lr: 1.000e-04, eta: 0:08:56, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4894
2022-11-20 18:33:12,271 - mmcls - INFO - Epoch(val) [185][79]	train_accuracy: 90.3800, accuracy_top-1: 94.8700, accuracy_top-5: 99.8500
2022-11-20 18:33:25,400 - mmcls - INFO - Epoch [186][100/391]	lr: 1.000e-04, eta: 0:08:39, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4686
2022-11-20 18:33:36,447 - mmcls - INFO - Epoch [186][200/391]	lr: 1.000e-04, eta: 0:08:30, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5389
2022-11-20 18:33:47,451 - mmcls - INFO - Epoch [186][300/391]	lr: 1.000e-04, eta: 0:08:21, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4560
2022-11-20 18:34:00,401 - mmcls - INFO - Epoch(val) [186][79]	train_accuracy: 90.6280, accuracy_top-1: 94.9100, accuracy_top-5: 99.8600
2022-11-20 18:34:13,538 - mmcls - INFO - Epoch [187][100/391]	lr: 1.000e-04, eta: 0:08:04, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.3934
2022-11-20 18:34:24,542 - mmcls - INFO - Epoch [187][200/391]	lr: 1.000e-04, eta: 0:07:55, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4793
2022-11-20 18:34:35,553 - mmcls - INFO - Epoch [187][300/391]	lr: 1.000e-04, eta: 0:07:46, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4773
2022-11-20 18:34:48,393 - mmcls - INFO - Epoch(val) [187][79]	train_accuracy: 90.6300, accuracy_top-1: 94.8800, accuracy_top-5: 99.8500
2022-11-20 18:35:01,559 - mmcls - INFO - Epoch [188][100/391]	lr: 1.000e-04, eta: 0:07:28, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5347
2022-11-20 18:35:12,570 - mmcls - INFO - Epoch [188][200/391]	lr: 1.000e-04, eta: 0:07:20, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5302
2022-11-20 18:35:23,579 - mmcls - INFO - Epoch [188][300/391]	lr: 1.000e-04, eta: 0:07:11, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5070
2022-11-20 18:35:36,622 - mmcls - INFO - Epoch(val) [188][79]	train_accuracy: 89.0680, accuracy_top-1: 94.8300, accuracy_top-5: 99.8700
2022-11-20 18:35:49,795 - mmcls - INFO - Epoch [189][100/391]	lr: 1.000e-04, eta: 0:06:53, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4660
2022-11-20 18:36:00,867 - mmcls - INFO - Epoch [189][200/391]	lr: 1.000e-04, eta: 0:06:44, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4867
2022-11-20 18:36:11,930 - mmcls - INFO - Epoch [189][300/391]	lr: 1.000e-04, eta: 0:06:35, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4757
2022-11-20 18:36:25,000 - mmcls - INFO - Epoch(val) [189][79]	train_accuracy: 90.3000, accuracy_top-1: 94.8800, accuracy_top-5: 99.8500
2022-11-20 18:36:38,177 - mmcls - INFO - Epoch [190][100/391]	lr: 1.000e-04, eta: 0:06:18, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4761
2022-11-20 18:36:49,242 - mmcls - INFO - Epoch [190][200/391]	lr: 1.000e-04, eta: 0:06:09, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4299
2022-11-20 18:37:00,309 - mmcls - INFO - Epoch [190][300/391]	lr: 1.000e-04, eta: 0:06:00, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5898
2022-11-20 18:37:10,310 - mmcls - INFO - Saving checkpoint at 190 epochs
2022-11-20 18:37:13,499 - mmcls - INFO - Epoch(val) [190][79]	train_accuracy: 90.5180, accuracy_top-1: 94.9100, accuracy_top-5: 99.8700
2022-11-20 18:37:26,674 - mmcls - INFO - Epoch [191][100/391]	lr: 1.000e-04, eta: 0:05:43, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4071
2022-11-20 18:37:37,728 - mmcls - INFO - Epoch [191][200/391]	lr: 1.000e-04, eta: 0:05:34, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.4520
2022-11-20 18:37:48,771 - mmcls - INFO - Epoch [191][300/391]	lr: 1.000e-04, eta: 0:05:25, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3892
2022-11-20 18:38:01,814 - mmcls - INFO - Epoch(val) [191][79]	train_accuracy: 91.5920, accuracy_top-1: 94.8800, accuracy_top-5: 99.8700
2022-11-20 18:38:14,978 - mmcls - INFO - Epoch [192][100/391]	lr: 1.000e-04, eta: 0:05:08, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4473
2022-11-20 18:38:26,015 - mmcls - INFO - Epoch [192][200/391]	lr: 1.000e-04, eta: 0:04:59, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5096
2022-11-20 18:38:37,062 - mmcls - INFO - Epoch [192][300/391]	lr: 1.000e-04, eta: 0:04:50, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5025
2022-11-20 18:38:50,105 - mmcls - INFO - Epoch(val) [192][79]	train_accuracy: 90.7060, accuracy_top-1: 94.8800, accuracy_top-5: 99.8500
2022-11-20 18:39:03,299 - mmcls - INFO - Epoch [193][100/391]	lr: 1.000e-04, eta: 0:04:32, time: 0.132, data_time: 0.021, memory: 1588, loss: 0.4151
2022-11-20 18:39:14,347 - mmcls - INFO - Epoch [193][200/391]	lr: 1.000e-04, eta: 0:04:23, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5027
2022-11-20 18:39:25,408 - mmcls - INFO - Epoch [193][300/391]	lr: 1.000e-04, eta: 0:04:14, time: 0.111, data_time: 0.001, memory: 1588, loss: 0.5514
2022-11-20 18:39:38,387 - mmcls - INFO - Epoch(val) [193][79]	train_accuracy: 90.5360, accuracy_top-1: 94.8700, accuracy_top-5: 99.8500
2022-11-20 18:39:51,542 - mmcls - INFO - Epoch [194][100/391]	lr: 1.000e-04, eta: 0:03:57, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4448
2022-11-20 18:40:02,548 - mmcls - INFO - Epoch [194][200/391]	lr: 1.000e-04, eta: 0:03:48, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4853
2022-11-20 18:40:13,561 - mmcls - INFO - Epoch [194][300/391]	lr: 1.000e-04, eta: 0:03:39, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4279
2022-11-20 18:40:26,601 - mmcls - INFO - Epoch(val) [194][79]	train_accuracy: 91.0960, accuracy_top-1: 94.8900, accuracy_top-5: 99.8500
2022-11-20 18:40:39,735 - mmcls - INFO - Epoch [195][100/391]	lr: 1.000e-04, eta: 0:03:22, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4999
2022-11-20 18:40:50,766 - mmcls - INFO - Epoch [195][200/391]	lr: 1.000e-04, eta: 0:03:13, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4878
2022-11-20 18:41:01,802 - mmcls - INFO - Epoch [195][300/391]	lr: 1.000e-04, eta: 0:03:04, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5153
2022-11-20 18:41:14,889 - mmcls - INFO - Epoch(val) [195][79]	train_accuracy: 88.4700, accuracy_top-1: 94.8900, accuracy_top-5: 99.8400
2022-11-20 18:41:28,066 - mmcls - INFO - Epoch [196][100/391]	lr: 1.000e-04, eta: 0:02:47, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4632
2022-11-20 18:41:39,089 - mmcls - INFO - Epoch [196][200/391]	lr: 1.000e-04, eta: 0:02:38, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4446
2022-11-20 18:41:50,136 - mmcls - INFO - Epoch [196][300/391]	lr: 1.000e-04, eta: 0:02:29, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4751
2022-11-20 18:42:03,095 - mmcls - INFO - Epoch(val) [196][79]	train_accuracy: 90.3940, accuracy_top-1: 94.8400, accuracy_top-5: 99.8500
2022-11-20 18:42:16,247 - mmcls - INFO - Epoch [197][100/391]	lr: 1.000e-04, eta: 0:02:11, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4613
2022-11-20 18:42:27,269 - mmcls - INFO - Epoch [197][200/391]	lr: 1.000e-04, eta: 0:02:02, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4237
2022-11-20 18:42:38,278 - mmcls - INFO - Epoch [197][300/391]	lr: 1.000e-04, eta: 0:01:53, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3703
2022-11-20 18:42:51,190 - mmcls - INFO - Epoch(val) [197][79]	train_accuracy: 92.3140, accuracy_top-1: 94.8700, accuracy_top-5: 99.8600
2022-11-20 18:43:04,328 - mmcls - INFO - Epoch [198][100/391]	lr: 1.000e-04, eta: 0:01:36, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5153
2022-11-20 18:43:15,329 - mmcls - INFO - Epoch [198][200/391]	lr: 1.000e-04, eta: 0:01:27, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4880
2022-11-20 18:43:26,334 - mmcls - INFO - Epoch [198][300/391]	lr: 1.000e-04, eta: 0:01:18, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3865
2022-11-20 18:43:39,297 - mmcls - INFO - Epoch(val) [198][79]	train_accuracy: 91.5440, accuracy_top-1: 94.8300, accuracy_top-5: 99.8700
2022-11-20 18:43:52,411 - mmcls - INFO - Epoch [199][100/391]	lr: 1.000e-04, eta: 0:01:01, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.4875
2022-11-20 18:44:03,416 - mmcls - INFO - Epoch [199][200/391]	lr: 1.000e-04, eta: 0:00:52, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.5348
2022-11-20 18:44:14,425 - mmcls - INFO - Epoch [199][300/391]	lr: 1.000e-04, eta: 0:00:43, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4502
2022-11-20 18:44:27,272 - mmcls - INFO - Epoch(val) [199][79]	train_accuracy: 89.9620, accuracy_top-1: 94.8700, accuracy_top-5: 99.8600
2022-11-20 18:44:40,407 - mmcls - INFO - Epoch [200][100/391]	lr: 1.000e-04, eta: 0:00:26, time: 0.131, data_time: 0.021, memory: 1588, loss: 0.5080
2022-11-20 18:44:51,418 - mmcls - INFO - Epoch [200][200/391]	lr: 1.000e-04, eta: 0:00:17, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.4923
2022-11-20 18:45:02,459 - mmcls - INFO - Epoch [200][300/391]	lr: 1.000e-04, eta: 0:00:08, time: 0.110, data_time: 0.001, memory: 1588, loss: 0.3965
2022-11-20 18:45:12,470 - mmcls - INFO - Saving checkpoint at 200 epochs
2022-11-20 18:45:15,727 - mmcls - INFO - Epoch(val) [200][79]	train_accuracy: 90.6880, accuracy_top-1: 94.8300, accuracy_top-5: 99.8600
