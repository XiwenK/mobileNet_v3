2022-11-21 00:07:25,902 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Oct 21 2022, 23:50:54) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3070 Ti Laptop GPU
CUDA_HOME: /usr/local/cuda-11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.105
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.13.0
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.0
OpenCV: 4.6.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.7
MMClassification: 0.24.1+4e5bf17
------------------------------------------------------------

2022-11-21 00:07:25,902 - mmcls - INFO - Distributed training: False
2022-11-21 00:07:25,951 - mmcls - INFO - Config:
model = dict(
    type='BSConvClassifier',
    backbone=dict(
        type='MobileNetV3Cifar', arch='large', conv_cfg=dict(type='BSConvS')),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='StackedLinearClsHeadWithPred',
        num_classes=100,
        in_channels=960,
        mid_channels=[1280],
        act_cfg=dict(type='HSwish'),
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),
        topk=(1, 5)),
    train_cfg=dict(augments=[
        dict(type='BatchCutMix', alpha=1.0, prob=0.5, num_classes=100)
    ]))
dataset_type = 'CIFAR100'
img_norm_cfg = dict(
    mean=[129.304, 124.07, 112.434], std=[68.17, 65.392, 70.418], to_rgb=False)
train_pipeline = [
    dict(type='RandomCrop', size=32, padding=4),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(
        type='Normalize',
        mean=[129.304, 124.07, 112.434],
        std=[68.17, 65.392, 70.418],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(
        type='Normalize',
        mean=[129.304, 124.07, 112.434],
        std=[68.17, 65.392, 70.418],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=128,
    workers_per_gpu=2,
    train=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(type='RandomCrop', size=32, padding=4),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True),
    test=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True))
optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[100, 150, 180])
runner = dict(type='EpochBasedRunner', max_epochs=200)
checkpoint_config = dict(interval=10, max_keep_ckpts=1)
log_config = dict(
    interval=100,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
work_dir = './work_dirs/5.cifar100_data_with_bsconv'
gpu_ids = [0]

2022-11-21 00:07:25,951 - mmcls - INFO - Set random seed to 541401438, deterministic: False
2022-11-21 00:07:26,029 - mmcls - INFO - initialize MobileNetV3Cifar with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d'], 'nonlinearity': 'leaky_relu'}, {'type': 'Normal', 'layer': ['Linear'], 'std': 0.01}, {'type': 'Constant', 'layer': ['BatchNorm2d'], 'val': 1}]
Name of parameter - Initialization information

backbone.layer0.conv.weight - torch.Size([16, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.depthwise_conv.conv.weight - torch.Size([16, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.depthwise_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.depthwise_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.linear_conv.conv.pw1.weight - torch.Size([4, 16, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.conv.pw2.weight - torch.Size([16, 4, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.conv.dw.weight - torch.Size([16, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.expand_conv.conv.weight - torch.Size([64, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.expand_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.expand_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.depthwise_conv.conv.weight - torch.Size([64, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.depthwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.depthwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.linear_conv.conv.pw1.weight - torch.Size([16, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.conv.pw2.weight - torch.Size([24, 16, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.conv.dw.weight - torch.Size([24, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.expand_conv.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.depthwise_conv.conv.weight - torch.Size([72, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.linear_conv.conv.pw1.weight - torch.Size([18, 72, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.conv.pw2.weight - torch.Size([24, 18, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.conv.dw.weight - torch.Size([24, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.expand_conv.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.depthwise_conv.conv.weight - torch.Size([72, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.se.conv1.conv.weight - torch.Size([24, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv1.conv.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.se.conv2.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv2.conv.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.linear_conv.conv.pw1.weight - torch.Size([18, 72, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.conv.pw2.weight - torch.Size([40, 18, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.linear_conv.conv.pw1.weight - torch.Size([30, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.conv.pw2.weight - torch.Size([40, 30, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.linear_conv.conv.pw1.weight - torch.Size([30, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.conv.pw2.weight - torch.Size([40, 30, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.depthwise_conv.conv.weight - torch.Size([240, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.linear_conv.conv.pw1.weight - torch.Size([60, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.conv.pw2.weight - torch.Size([80, 60, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.expand_conv.conv.weight - torch.Size([200, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.expand_conv.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.expand_conv.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.depthwise_conv.conv.weight - torch.Size([200, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.depthwise_conv.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.depthwise_conv.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.linear_conv.conv.pw1.weight - torch.Size([50, 200, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.conv.pw2.weight - torch.Size([80, 50, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.expand_conv.conv.weight - torch.Size([184, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.expand_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.expand_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.depthwise_conv.conv.weight - torch.Size([184, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.depthwise_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.depthwise_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.linear_conv.conv.pw1.weight - torch.Size([46, 184, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.conv.pw2.weight - torch.Size([80, 46, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.expand_conv.conv.weight - torch.Size([184, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.expand_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.expand_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.depthwise_conv.conv.weight - torch.Size([184, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.depthwise_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.depthwise_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.linear_conv.conv.pw1.weight - torch.Size([46, 184, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.conv.pw2.weight - torch.Size([80, 46, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.expand_conv.conv.weight - torch.Size([480, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.expand_conv.bn.weight - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.expand_conv.bn.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.depthwise_conv.conv.weight - torch.Size([480, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.depthwise_conv.bn.weight - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.depthwise_conv.bn.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.se.conv1.conv.weight - torch.Size([120, 480, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv1.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.se.conv2.conv.weight - torch.Size([480, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv2.conv.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.linear_conv.conv.pw1.weight - torch.Size([120, 480, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.conv.pw2.weight - torch.Size([112, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.conv.dw.weight - torch.Size([112, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.bn.weight - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.linear_conv.bn.bias - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.expand_conv.conv.weight - torch.Size([672, 112, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.expand_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.expand_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.depthwise_conv.conv.weight - torch.Size([672, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.depthwise_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.depthwise_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.se.conv1.conv.weight - torch.Size([168, 672, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.se.conv1.conv.bias - torch.Size([168]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.se.conv2.conv.weight - torch.Size([672, 168, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.se.conv2.conv.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.linear_conv.conv.pw1.weight - torch.Size([168, 672, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.conv.pw2.weight - torch.Size([112, 168, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.conv.dw.weight - torch.Size([112, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.bn.weight - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.linear_conv.bn.bias - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.expand_conv.conv.weight - torch.Size([672, 112, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.expand_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.expand_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.depthwise_conv.conv.weight - torch.Size([672, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.depthwise_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.depthwise_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.se.conv1.conv.weight - torch.Size([168, 672, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.se.conv1.conv.bias - torch.Size([168]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.se.conv2.conv.weight - torch.Size([672, 168, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.se.conv2.conv.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.linear_conv.conv.pw1.weight - torch.Size([168, 672, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.conv.pw2.weight - torch.Size([160, 168, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.expand_conv.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.expand_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.expand_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.depthwise_conv.conv.weight - torch.Size([960, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.depthwise_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.depthwise_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.se.conv1.conv.weight - torch.Size([240, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.se.conv1.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.se.conv2.conv.weight - torch.Size([960, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.se.conv2.conv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.linear_conv.conv.pw1.weight - torch.Size([240, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.conv.pw2.weight - torch.Size([160, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.expand_conv.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.expand_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.expand_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.depthwise_conv.conv.weight - torch.Size([960, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.depthwise_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.depthwise_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.se.conv1.conv.weight - torch.Size([240, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.se.conv1.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.se.conv2.conv.weight - torch.Size([960, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.se.conv2.conv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.linear_conv.conv.pw1.weight - torch.Size([240, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.conv.pw2.weight - torch.Size([160, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer16.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer16.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer16.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.0.fc.weight - torch.Size([1280, 960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.0.fc.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.1.fc.weight - torch.Size([100, 1280]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.1.fc.bias - torch.Size([100]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  
2022-11-21 00:07:27,615 - mmcls - INFO - Start running, host: aoyuli@LAY-LAPTOP, work_dir: /home/aoyuli/Project/mmdl/work_dirs/5.cifar100_data_with_bsconv
2022-11-21 00:07:27,615 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) TrainsetEvalHook                   
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) TrainsetEvalHook                   
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2022-11-21 00:07:27,616 - mmcls - INFO - workflow: [('train', 1)], max: 200 epochs
2022-11-21 00:07:27,616 - mmcls - INFO - Checkpoints will be saved to /home/aoyuli/Project/mmdl/work_dirs/5.cifar100_data_with_bsconv by HardDiskBackend.
2022-11-21 00:07:39,133 - mmcls - INFO - Epoch [1][100/391]	lr: 1.000e-01, eta: 2:29:12, time: 0.115, data_time: 0.022, memory: 1669, loss: 4.4661
2022-11-21 00:07:47,274 - mmcls - INFO - Epoch [1][200/391]	lr: 1.000e-01, eta: 2:07:25, time: 0.081, data_time: 0.001, memory: 1669, loss: 4.2408
2022-11-21 00:07:55,338 - mmcls - INFO - Epoch [1][300/391]	lr: 1.000e-01, eta: 1:59:44, time: 0.081, data_time: 0.001, memory: 1669, loss: 4.1109
2022-11-21 00:08:04,445 - mmcls - INFO - Epoch(val) [1][79]	train_accuracy: 5.6080, accuracy_top-1: 1.7900, accuracy_top-5: 7.1100
2022-11-21 00:08:14,883 - mmcls - INFO - Epoch [2][100/391]	lr: 1.000e-01, eta: 1:40:26, time: 0.104, data_time: 0.021, memory: 1669, loss: 3.9916
2022-11-21 00:08:23,434 - mmcls - INFO - Epoch [2][200/391]	lr: 1.000e-01, eta: 1:42:02, time: 0.085, data_time: 0.001, memory: 1669, loss: 3.8494
2022-11-21 00:08:32,079 - mmcls - INFO - Epoch [2][300/391]	lr: 1.000e-01, eta: 1:43:19, time: 0.086, data_time: 0.001, memory: 1669, loss: 3.7525
2022-11-21 00:08:41,888 - mmcls - INFO - Epoch(val) [2][79]	train_accuracy: 12.3820, accuracy_top-1: 12.9300, accuracy_top-5: 36.6400
2022-11-21 00:08:52,587 - mmcls - INFO - Epoch [3][100/391]	lr: 1.000e-01, eta: 1:36:20, time: 0.107, data_time: 0.021, memory: 1669, loss: 3.5630
2022-11-21 00:09:01,384 - mmcls - INFO - Epoch [3][200/391]	lr: 1.000e-01, eta: 1:37:56, time: 0.088, data_time: 0.001, memory: 1669, loss: 3.5097
2022-11-21 00:09:10,290 - mmcls - INFO - Epoch [3][300/391]	lr: 1.000e-01, eta: 1:39:21, time: 0.089, data_time: 0.001, memory: 1669, loss: 3.3762
2022-11-21 00:09:20,585 - mmcls - INFO - Epoch(val) [3][79]	train_accuracy: 18.9500, accuracy_top-1: 12.5400, accuracy_top-5: 35.7900
2022-11-21 00:09:31,677 - mmcls - INFO - Epoch [4][100/391]	lr: 1.000e-01, eta: 1:35:22, time: 0.111, data_time: 0.021, memory: 1669, loss: 3.1971
2022-11-21 00:09:40,837 - mmcls - INFO - Epoch [4][200/391]	lr: 1.000e-01, eta: 1:36:51, time: 0.092, data_time: 0.001, memory: 1669, loss: 3.2896
2022-11-21 00:09:50,091 - mmcls - INFO - Epoch [4][300/391]	lr: 1.000e-01, eta: 1:38:11, time: 0.093, data_time: 0.001, memory: 1669, loss: 3.1864
2022-11-21 00:10:00,415 - mmcls - INFO - Epoch(val) [4][79]	train_accuracy: 24.5600, accuracy_top-1: 31.1600, accuracy_top-5: 63.7800
2022-11-21 00:10:11,572 - mmcls - INFO - Epoch [5][100/391]	lr: 1.000e-01, eta: 1:35:14, time: 0.111, data_time: 0.021, memory: 1669, loss: 2.9561
2022-11-21 00:10:20,753 - mmcls - INFO - Epoch [5][200/391]	lr: 1.000e-01, eta: 1:36:21, time: 0.092, data_time: 0.001, memory: 1669, loss: 2.9080
2022-11-21 00:10:29,975 - mmcls - INFO - Epoch [5][300/391]	lr: 1.000e-01, eta: 1:37:21, time: 0.092, data_time: 0.001, memory: 1669, loss: 2.9603
2022-11-21 00:10:40,421 - mmcls - INFO - Epoch(val) [5][79]	train_accuracy: 30.4440, accuracy_top-1: 31.5400, accuracy_top-5: 65.2600
2022-11-21 00:10:51,583 - mmcls - INFO - Epoch [6][100/391]	lr: 1.000e-01, eta: 1:34:57, time: 0.111, data_time: 0.021, memory: 1669, loss: 2.8857
2022-11-21 00:11:00,758 - mmcls - INFO - Epoch [6][200/391]	lr: 1.000e-01, eta: 1:35:49, time: 0.092, data_time: 0.001, memory: 1669, loss: 2.7902
2022-11-21 00:11:09,830 - mmcls - INFO - Epoch [6][300/391]	lr: 1.000e-01, eta: 1:36:33, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.7739
2022-11-21 00:11:19,880 - mmcls - INFO - Epoch(val) [6][79]	train_accuracy: 33.2540, accuracy_top-1: 34.9900, accuracy_top-5: 67.0100
2022-11-21 00:11:30,708 - mmcls - INFO - Epoch [7][100/391]	lr: 1.000e-01, eta: 1:34:21, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.6965
2022-11-21 00:11:39,808 - mmcls - INFO - Epoch [7][200/391]	lr: 1.000e-01, eta: 1:35:02, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.7312
2022-11-21 00:11:48,689 - mmcls - INFO - Epoch [7][300/391]	lr: 1.000e-01, eta: 1:35:33, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.7012
2022-11-21 00:11:58,621 - mmcls - INFO - Epoch(val) [7][79]	train_accuracy: 36.1060, accuracy_top-1: 38.8200, accuracy_top-5: 71.2500
2022-11-21 00:12:09,562 - mmcls - INFO - Epoch [8][100/391]	lr: 1.000e-01, eta: 1:33:43, time: 0.109, data_time: 0.021, memory: 1669, loss: 2.6563
2022-11-21 00:12:18,620 - mmcls - INFO - Epoch [8][200/391]	lr: 1.000e-01, eta: 1:34:17, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.4821
2022-11-21 00:12:27,689 - mmcls - INFO - Epoch [8][300/391]	lr: 1.000e-01, eta: 1:34:48, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.6076
2022-11-21 00:12:37,695 - mmcls - INFO - Epoch(val) [8][79]	train_accuracy: 39.3860, accuracy_top-1: 43.6100, accuracy_top-5: 75.5900
2022-11-21 00:12:48,457 - mmcls - INFO - Epoch [9][100/391]	lr: 1.000e-01, eta: 1:33:07, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.3711
2022-11-21 00:12:57,405 - mmcls - INFO - Epoch [9][200/391]	lr: 1.000e-01, eta: 1:33:33, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.5920
2022-11-21 00:13:06,326 - mmcls - INFO - Epoch [9][300/391]	lr: 1.000e-01, eta: 1:33:56, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.5226
2022-11-21 00:13:16,390 - mmcls - INFO - Epoch(val) [9][79]	train_accuracy: 41.4180, accuracy_top-1: 42.3600, accuracy_top-5: 74.1600
2022-11-21 00:13:27,251 - mmcls - INFO - Epoch [10][100/391]	lr: 1.000e-01, eta: 1:32:28, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.3096
2022-11-21 00:13:36,238 - mmcls - INFO - Epoch [10][200/391]	lr: 1.000e-01, eta: 1:32:52, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.5853
2022-11-21 00:13:45,331 - mmcls - INFO - Epoch [10][300/391]	lr: 1.000e-01, eta: 1:33:16, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.5051
2022-11-21 00:13:53,470 - mmcls - INFO - Saving checkpoint at 10 epochs
2022-11-21 00:13:55,532 - mmcls - INFO - Epoch(val) [10][79]	train_accuracy: 42.2420, accuracy_top-1: 41.7500, accuracy_top-5: 73.6200
2022-11-21 00:14:06,435 - mmcls - INFO - Epoch [11][100/391]	lr: 1.000e-01, eta: 1:31:57, time: 0.109, data_time: 0.021, memory: 1669, loss: 2.3259
2022-11-21 00:14:15,518 - mmcls - INFO - Epoch [11][200/391]	lr: 1.000e-01, eta: 1:32:19, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.5138
2022-11-21 00:14:24,505 - mmcls - INFO - Epoch [11][300/391]	lr: 1.000e-01, eta: 1:32:38, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.4569
2022-11-21 00:14:34,612 - mmcls - INFO - Epoch(val) [11][79]	train_accuracy: 42.9900, accuracy_top-1: 49.1900, accuracy_top-5: 79.4900
2022-11-21 00:14:45,544 - mmcls - INFO - Epoch [12][100/391]	lr: 1.000e-01, eta: 1:31:26, time: 0.109, data_time: 0.021, memory: 1669, loss: 2.2492
2022-11-21 00:14:54,582 - mmcls - INFO - Epoch [12][200/391]	lr: 1.000e-01, eta: 1:31:45, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.5031
2022-11-21 00:15:03,532 - mmcls - INFO - Epoch [12][300/391]	lr: 1.000e-01, eta: 1:32:01, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.3354
2022-11-21 00:15:13,590 - mmcls - INFO - Epoch(val) [12][79]	train_accuracy: 45.3340, accuracy_top-1: 38.7400, accuracy_top-5: 69.8700
2022-11-21 00:15:24,340 - mmcls - INFO - Epoch [13][100/391]	lr: 1.000e-01, eta: 1:30:51, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.3779
2022-11-21 00:15:33,298 - mmcls - INFO - Epoch [13][200/391]	lr: 1.000e-01, eta: 1:31:07, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.3884
2022-11-21 00:15:42,081 - mmcls - INFO - Epoch [13][300/391]	lr: 1.000e-01, eta: 1:31:19, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.3560
2022-11-21 00:15:51,971 - mmcls - INFO - Epoch(val) [13][79]	train_accuracy: 45.1020, accuracy_top-1: 50.4800, accuracy_top-5: 80.0100
2022-11-21 00:16:02,711 - mmcls - INFO - Epoch [14][100/391]	lr: 1.000e-01, eta: 1:30:14, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.3830
2022-11-21 00:16:11,776 - mmcls - INFO - Epoch [14][200/391]	lr: 1.000e-01, eta: 1:30:29, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.3385
2022-11-21 00:16:20,789 - mmcls - INFO - Epoch [14][300/391]	lr: 1.000e-01, eta: 1:30:43, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.2335
2022-11-21 00:16:30,839 - mmcls - INFO - Epoch(val) [14][79]	train_accuracy: 46.6000, accuracy_top-1: 46.9200, accuracy_top-5: 76.7000
2022-11-21 00:16:41,577 - mmcls - INFO - Epoch [15][100/391]	lr: 1.000e-01, eta: 1:29:42, time: 0.107, data_time: 0.020, memory: 1669, loss: 2.2215
2022-11-21 00:16:50,498 - mmcls - INFO - Epoch [15][200/391]	lr: 1.000e-01, eta: 1:29:54, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.3144
2022-11-21 00:16:59,439 - mmcls - INFO - Epoch [15][300/391]	lr: 1.000e-01, eta: 1:30:06, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.3414
2022-11-21 00:17:09,510 - mmcls - INFO - Epoch(val) [15][79]	train_accuracy: 47.0460, accuracy_top-1: 44.5200, accuracy_top-5: 74.6300
2022-11-21 00:17:20,413 - mmcls - INFO - Epoch [16][100/391]	lr: 1.000e-01, eta: 1:29:10, time: 0.109, data_time: 0.021, memory: 1669, loss: 2.2875
2022-11-21 00:17:29,426 - mmcls - INFO - Epoch [16][200/391]	lr: 1.000e-01, eta: 1:29:22, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.1932
2022-11-21 00:17:38,362 - mmcls - INFO - Epoch [16][300/391]	lr: 1.000e-01, eta: 1:29:32, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.2062
2022-11-21 00:17:48,281 - mmcls - INFO - Epoch(val) [16][79]	train_accuracy: 48.2320, accuracy_top-1: 51.4600, accuracy_top-5: 81.5900
2022-11-21 00:17:58,911 - mmcls - INFO - Epoch [17][100/391]	lr: 1.000e-01, eta: 1:28:37, time: 0.106, data_time: 0.020, memory: 1669, loss: 2.0296
2022-11-21 00:18:07,969 - mmcls - INFO - Epoch [17][200/391]	lr: 1.000e-01, eta: 1:28:48, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.1850
2022-11-21 00:18:17,010 - mmcls - INFO - Epoch [17][300/391]	lr: 1.000e-01, eta: 1:28:58, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.1064
2022-11-21 00:18:27,103 - mmcls - INFO - Epoch(val) [17][79]	train_accuracy: 50.0280, accuracy_top-1: 49.0100, accuracy_top-5: 78.5100
2022-11-21 00:18:37,986 - mmcls - INFO - Epoch [18][100/391]	lr: 1.000e-01, eta: 1:28:08, time: 0.109, data_time: 0.021, memory: 1669, loss: 2.2034
2022-11-21 00:18:46,928 - mmcls - INFO - Epoch [18][200/391]	lr: 1.000e-01, eta: 1:28:16, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.1565
2022-11-21 00:18:55,957 - mmcls - INFO - Epoch [18][300/391]	lr: 1.000e-01, eta: 1:28:25, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.1541
2022-11-21 00:19:06,005 - mmcls - INFO - Epoch(val) [18][79]	train_accuracy: 49.2640, accuracy_top-1: 51.6400, accuracy_top-5: 80.6200
2022-11-21 00:19:16,820 - mmcls - INFO - Epoch [19][100/391]	lr: 1.000e-01, eta: 1:27:37, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.1577
2022-11-21 00:19:25,763 - mmcls - INFO - Epoch [19][200/391]	lr: 1.000e-01, eta: 1:27:45, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.1487
2022-11-21 00:19:34,980 - mmcls - INFO - Epoch [19][300/391]	lr: 1.000e-01, eta: 1:27:55, time: 0.092, data_time: 0.001, memory: 1669, loss: 2.1607
2022-11-21 00:19:45,384 - mmcls - INFO - Epoch(val) [19][79]	train_accuracy: 50.2320, accuracy_top-1: 46.9300, accuracy_top-5: 77.3100
2022-11-21 00:19:56,260 - mmcls - INFO - Epoch [20][100/391]	lr: 1.000e-01, eta: 1:27:09, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.2219
2022-11-21 00:20:05,293 - mmcls - INFO - Epoch [20][200/391]	lr: 1.000e-01, eta: 1:27:17, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.1531
2022-11-21 00:20:14,414 - mmcls - INFO - Epoch [20][300/391]	lr: 1.000e-01, eta: 1:27:25, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.0598
2022-11-21 00:20:22,768 - mmcls - INFO - Saving checkpoint at 20 epochs
2022-11-21 00:20:24,835 - mmcls - INFO - Epoch(val) [20][79]	train_accuracy: 50.4040, accuracy_top-1: 46.9900, accuracy_top-5: 77.0900
2022-11-21 00:20:35,852 - mmcls - INFO - Epoch [21][100/391]	lr: 1.000e-01, eta: 1:26:42, time: 0.110, data_time: 0.021, memory: 1669, loss: 2.1693
2022-11-21 00:20:44,960 - mmcls - INFO - Epoch [21][200/391]	lr: 1.000e-01, eta: 1:26:49, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.1385
2022-11-21 00:20:54,074 - mmcls - INFO - Epoch [21][300/391]	lr: 1.000e-01, eta: 1:26:57, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.2489
2022-11-21 00:21:04,265 - mmcls - INFO - Epoch(val) [21][79]	train_accuracy: 50.6480, accuracy_top-1: 53.3400, accuracy_top-5: 82.8600
2022-11-21 00:21:15,306 - mmcls - INFO - Epoch [22][100/391]	lr: 1.000e-01, eta: 1:26:15, time: 0.110, data_time: 0.021, memory: 1669, loss: 2.0557
2022-11-21 00:21:24,300 - mmcls - INFO - Epoch [22][200/391]	lr: 1.000e-01, eta: 1:26:21, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9956
2022-11-21 00:21:33,290 - mmcls - INFO - Epoch [22][300/391]	lr: 1.000e-01, eta: 1:26:27, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.1613
2022-11-21 00:21:43,337 - mmcls - INFO - Epoch(val) [22][79]	train_accuracy: 51.9720, accuracy_top-1: 45.4500, accuracy_top-5: 75.4100
2022-11-21 00:21:54,126 - mmcls - INFO - Epoch [23][100/391]	lr: 1.000e-01, eta: 1:25:45, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.0987
2022-11-21 00:22:03,058 - mmcls - INFO - Epoch [23][200/391]	lr: 1.000e-01, eta: 1:25:49, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.2018
2022-11-21 00:22:12,125 - mmcls - INFO - Epoch [23][300/391]	lr: 1.000e-01, eta: 1:25:55, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.2763
2022-11-21 00:22:22,224 - mmcls - INFO - Epoch(val) [23][79]	train_accuracy: 51.7400, accuracy_top-1: 50.1100, accuracy_top-5: 80.8500
2022-11-21 00:22:33,106 - mmcls - INFO - Epoch [24][100/391]	lr: 1.000e-01, eta: 1:25:15, time: 0.109, data_time: 0.021, memory: 1669, loss: 2.0815
2022-11-21 00:22:42,054 - mmcls - INFO - Epoch [24][200/391]	lr: 1.000e-01, eta: 1:25:19, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.1795
2022-11-21 00:22:51,021 - mmcls - INFO - Epoch [24][300/391]	lr: 1.000e-01, eta: 1:25:23, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0830
2022-11-21 00:23:01,108 - mmcls - INFO - Epoch(val) [24][79]	train_accuracy: 51.9120, accuracy_top-1: 44.3500, accuracy_top-5: 74.3000
2022-11-21 00:23:11,805 - mmcls - INFO - Epoch [25][100/391]	lr: 1.000e-01, eta: 1:24:43, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8721
2022-11-21 00:23:20,674 - mmcls - INFO - Epoch [25][200/391]	lr: 1.000e-01, eta: 1:24:47, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0974
2022-11-21 00:23:29,559 - mmcls - INFO - Epoch [25][300/391]	lr: 1.000e-01, eta: 1:24:50, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0830
2022-11-21 00:23:39,500 - mmcls - INFO - Epoch(val) [25][79]	train_accuracy: 52.9460, accuracy_top-1: 56.1300, accuracy_top-5: 84.4800
2022-11-21 00:23:50,195 - mmcls - INFO - Epoch [26][100/391]	lr: 1.000e-01, eta: 1:24:11, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.0678
2022-11-21 00:23:58,978 - mmcls - INFO - Epoch [26][200/391]	lr: 1.000e-01, eta: 1:24:13, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.2702
2022-11-21 00:24:07,954 - mmcls - INFO - Epoch [26][300/391]	lr: 1.000e-01, eta: 1:24:16, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9930
2022-11-21 00:24:18,036 - mmcls - INFO - Epoch(val) [26][79]	train_accuracy: 52.5000, accuracy_top-1: 51.5900, accuracy_top-5: 80.2600
2022-11-21 00:24:28,890 - mmcls - INFO - Epoch [27][100/391]	lr: 1.000e-01, eta: 1:23:40, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.0996
2022-11-21 00:24:37,815 - mmcls - INFO - Epoch [27][200/391]	lr: 1.000e-01, eta: 1:23:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.1810
2022-11-21 00:24:46,751 - mmcls - INFO - Epoch [27][300/391]	lr: 1.000e-01, eta: 1:23:45, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0560
2022-11-21 00:24:56,817 - mmcls - INFO - Epoch(val) [27][79]	train_accuracy: 52.4200, accuracy_top-1: 55.7800, accuracy_top-5: 83.3800
2022-11-21 00:25:07,747 - mmcls - INFO - Epoch [28][100/391]	lr: 1.000e-01, eta: 1:23:10, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.9810
2022-11-21 00:25:16,720 - mmcls - INFO - Epoch [28][200/391]	lr: 1.000e-01, eta: 1:23:13, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0490
2022-11-21 00:25:25,738 - mmcls - INFO - Epoch [28][300/391]	lr: 1.000e-01, eta: 1:23:15, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0834
2022-11-21 00:25:35,816 - mmcls - INFO - Epoch(val) [28][79]	train_accuracy: 53.2760, accuracy_top-1: 51.5400, accuracy_top-5: 79.2800
2022-11-21 00:25:46,562 - mmcls - INFO - Epoch [29][100/391]	lr: 1.000e-01, eta: 1:22:40, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9138
2022-11-21 00:25:55,415 - mmcls - INFO - Epoch [29][200/391]	lr: 1.000e-01, eta: 1:22:42, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0266
2022-11-21 00:26:04,301 - mmcls - INFO - Epoch [29][300/391]	lr: 1.000e-01, eta: 1:22:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0387
2022-11-21 00:26:14,346 - mmcls - INFO - Epoch(val) [29][79]	train_accuracy: 53.9560, accuracy_top-1: 54.3900, accuracy_top-5: 82.9400
2022-11-21 00:26:25,154 - mmcls - INFO - Epoch [30][100/391]	lr: 1.000e-01, eta: 1:22:09, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.0636
2022-11-21 00:26:34,150 - mmcls - INFO - Epoch [30][200/391]	lr: 1.000e-01, eta: 1:22:11, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9964
2022-11-21 00:26:43,107 - mmcls - INFO - Epoch [30][300/391]	lr: 1.000e-01, eta: 1:22:13, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0585
2022-11-21 00:26:51,271 - mmcls - INFO - Saving checkpoint at 30 epochs
2022-11-21 00:26:53,278 - mmcls - INFO - Epoch(val) [30][79]	train_accuracy: 54.3800, accuracy_top-1: 51.7900, accuracy_top-5: 79.7800
2022-11-21 00:27:04,136 - mmcls - INFO - Epoch [31][100/391]	lr: 1.000e-01, eta: 1:21:40, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.0214
2022-11-21 00:27:13,140 - mmcls - INFO - Epoch [31][200/391]	lr: 1.000e-01, eta: 1:21:41, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9271
2022-11-21 00:27:21,989 - mmcls - INFO - Epoch [31][300/391]	lr: 1.000e-01, eta: 1:21:42, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.0568
2022-11-21 00:27:31,976 - mmcls - INFO - Epoch(val) [31][79]	train_accuracy: 53.9140, accuracy_top-1: 56.7700, accuracy_top-5: 84.9400
2022-11-21 00:27:42,681 - mmcls - INFO - Epoch [32][100/391]	lr: 1.000e-01, eta: 1:21:09, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9464
2022-11-21 00:27:51,633 - mmcls - INFO - Epoch [32][200/391]	lr: 1.000e-01, eta: 1:21:10, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8723
2022-11-21 00:28:00,473 - mmcls - INFO - Epoch [32][300/391]	lr: 1.000e-01, eta: 1:21:10, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9150
2022-11-21 00:28:10,558 - mmcls - INFO - Epoch(val) [32][79]	train_accuracy: 55.4460, accuracy_top-1: 55.4800, accuracy_top-5: 83.3000
2022-11-21 00:28:21,529 - mmcls - INFO - Epoch [33][100/391]	lr: 1.000e-01, eta: 1:20:39, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.8935
2022-11-21 00:28:30,541 - mmcls - INFO - Epoch [33][200/391]	lr: 1.000e-01, eta: 1:20:40, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9216
2022-11-21 00:28:39,436 - mmcls - INFO - Epoch [33][300/391]	lr: 1.000e-01, eta: 1:20:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0233
2022-11-21 00:28:49,449 - mmcls - INFO - Epoch(val) [33][79]	train_accuracy: 55.5800, accuracy_top-1: 54.0900, accuracy_top-5: 83.5600
2022-11-21 00:29:00,282 - mmcls - INFO - Epoch [34][100/391]	lr: 1.000e-01, eta: 1:20:10, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.9849
2022-11-21 00:29:09,281 - mmcls - INFO - Epoch [34][200/391]	lr: 1.000e-01, eta: 1:20:11, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0518
2022-11-21 00:29:18,267 - mmcls - INFO - Epoch [34][300/391]	lr: 1.000e-01, eta: 1:20:11, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0405
2022-11-21 00:29:28,307 - mmcls - INFO - Epoch(val) [34][79]	train_accuracy: 54.6680, accuracy_top-1: 56.8900, accuracy_top-5: 85.5500
2022-11-21 00:29:38,982 - mmcls - INFO - Epoch [35][100/391]	lr: 1.000e-01, eta: 1:19:40, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.9809
2022-11-21 00:29:47,771 - mmcls - INFO - Epoch [35][200/391]	lr: 1.000e-01, eta: 1:19:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.0598
2022-11-21 00:29:56,581 - mmcls - INFO - Epoch [35][300/391]	lr: 1.000e-01, eta: 1:19:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9947
2022-11-21 00:30:06,613 - mmcls - INFO - Epoch(val) [35][79]	train_accuracy: 55.1920, accuracy_top-1: 49.9800, accuracy_top-5: 78.4100
2022-11-21 00:30:17,390 - mmcls - INFO - Epoch [36][100/391]	lr: 1.000e-01, eta: 1:19:09, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9600
2022-11-21 00:30:26,371 - mmcls - INFO - Epoch [36][200/391]	lr: 1.000e-01, eta: 1:19:09, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.1731
2022-11-21 00:30:35,448 - mmcls - INFO - Epoch [36][300/391]	lr: 1.000e-01, eta: 1:19:09, time: 0.091, data_time: 0.001, memory: 1669, loss: 2.0036
2022-11-21 00:30:45,475 - mmcls - INFO - Epoch(val) [36][79]	train_accuracy: 55.0940, accuracy_top-1: 51.8100, accuracy_top-5: 81.3200
2022-11-21 00:30:56,374 - mmcls - INFO - Epoch [37][100/391]	lr: 1.000e-01, eta: 1:18:40, time: 0.109, data_time: 0.021, memory: 1669, loss: 2.1220
2022-11-21 00:31:05,309 - mmcls - INFO - Epoch [37][200/391]	lr: 1.000e-01, eta: 1:18:40, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8053
2022-11-21 00:31:14,239 - mmcls - INFO - Epoch [37][300/391]	lr: 1.000e-01, eta: 1:18:39, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9963
2022-11-21 00:31:24,211 - mmcls - INFO - Epoch(val) [37][79]	train_accuracy: 55.3560, accuracy_top-1: 52.9400, accuracy_top-5: 81.8300
2022-11-21 00:31:35,031 - mmcls - INFO - Epoch [38][100/391]	lr: 1.000e-01, eta: 1:18:11, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.9141
2022-11-21 00:31:43,887 - mmcls - INFO - Epoch [38][200/391]	lr: 1.000e-01, eta: 1:18:10, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9886
2022-11-21 00:31:52,762 - mmcls - INFO - Epoch [38][300/391]	lr: 1.000e-01, eta: 1:18:09, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0338
2022-11-21 00:32:02,733 - mmcls - INFO - Epoch(val) [38][79]	train_accuracy: 54.8480, accuracy_top-1: 58.0800, accuracy_top-5: 86.0600
2022-11-21 00:32:13,604 - mmcls - INFO - Epoch [39][100/391]	lr: 1.000e-01, eta: 1:17:41, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8781
2022-11-21 00:32:22,621 - mmcls - INFO - Epoch [39][200/391]	lr: 1.000e-01, eta: 1:17:40, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9006
2022-11-21 00:32:31,602 - mmcls - INFO - Epoch [39][300/391]	lr: 1.000e-01, eta: 1:17:40, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9688
2022-11-21 00:32:41,568 - mmcls - INFO - Epoch(val) [39][79]	train_accuracy: 54.9800, accuracy_top-1: 50.4700, accuracy_top-5: 79.6000
2022-11-21 00:32:52,420 - mmcls - INFO - Epoch [40][100/391]	lr: 1.000e-01, eta: 1:17:12, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.0251
2022-11-21 00:33:01,327 - mmcls - INFO - Epoch [40][200/391]	lr: 1.000e-01, eta: 1:17:11, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0466
2022-11-21 00:33:10,323 - mmcls - INFO - Epoch [40][300/391]	lr: 1.000e-01, eta: 1:17:10, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9485
2022-11-21 00:33:18,485 - mmcls - INFO - Saving checkpoint at 40 epochs
2022-11-21 00:33:20,492 - mmcls - INFO - Epoch(val) [40][79]	train_accuracy: 55.2580, accuracy_top-1: 56.3000, accuracy_top-5: 83.4500
2022-11-21 00:33:31,297 - mmcls - INFO - Epoch [41][100/391]	lr: 1.000e-01, eta: 1:16:43, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8795
2022-11-21 00:33:40,223 - mmcls - INFO - Epoch [41][200/391]	lr: 1.000e-01, eta: 1:16:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0687
2022-11-21 00:33:48,976 - mmcls - INFO - Epoch [41][300/391]	lr: 1.000e-01, eta: 1:16:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9560
2022-11-21 00:33:58,878 - mmcls - INFO - Epoch(val) [41][79]	train_accuracy: 56.2220, accuracy_top-1: 55.6400, accuracy_top-5: 83.6900
2022-11-21 00:34:09,770 - mmcls - INFO - Epoch [42][100/391]	lr: 1.000e-01, eta: 1:16:13, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.9015
2022-11-21 00:34:18,770 - mmcls - INFO - Epoch [42][200/391]	lr: 1.000e-01, eta: 1:16:12, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0683
2022-11-21 00:34:27,768 - mmcls - INFO - Epoch [42][300/391]	lr: 1.000e-01, eta: 1:16:10, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7936
2022-11-21 00:34:37,800 - mmcls - INFO - Epoch(val) [42][79]	train_accuracy: 56.3820, accuracy_top-1: 51.6700, accuracy_top-5: 80.8900
2022-11-21 00:34:48,568 - mmcls - INFO - Epoch [43][100/391]	lr: 1.000e-01, eta: 1:15:44, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8306
2022-11-21 00:34:57,544 - mmcls - INFO - Epoch [43][200/391]	lr: 1.000e-01, eta: 1:15:42, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9010
2022-11-21 00:35:06,391 - mmcls - INFO - Epoch [43][300/391]	lr: 1.000e-01, eta: 1:15:40, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9619
2022-11-21 00:35:16,290 - mmcls - INFO - Epoch(val) [43][79]	train_accuracy: 57.3060, accuracy_top-1: 58.4400, accuracy_top-5: 85.4100
2022-11-21 00:35:27,065 - mmcls - INFO - Epoch [44][100/391]	lr: 1.000e-01, eta: 1:15:14, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9194
2022-11-21 00:35:35,915 - mmcls - INFO - Epoch [44][200/391]	lr: 1.000e-01, eta: 1:15:12, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0117
2022-11-21 00:35:44,710 - mmcls - INFO - Epoch [44][300/391]	lr: 1.000e-01, eta: 1:15:10, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9781
2022-11-21 00:35:54,610 - mmcls - INFO - Epoch(val) [44][79]	train_accuracy: 56.1580, accuracy_top-1: 53.7500, accuracy_top-5: 81.4900
2022-11-21 00:36:05,384 - mmcls - INFO - Epoch [45][100/391]	lr: 1.000e-01, eta: 1:14:44, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8581
2022-11-21 00:36:14,366 - mmcls - INFO - Epoch [45][200/391]	lr: 1.000e-01, eta: 1:14:42, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8672
2022-11-21 00:36:23,404 - mmcls - INFO - Epoch [45][300/391]	lr: 1.000e-01, eta: 1:14:40, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8633
2022-11-21 00:36:33,451 - mmcls - INFO - Epoch(val) [45][79]	train_accuracy: 57.2800, accuracy_top-1: 59.3600, accuracy_top-5: 86.5600
2022-11-21 00:36:44,158 - mmcls - INFO - Epoch [46][100/391]	lr: 1.000e-01, eta: 1:14:15, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9475
2022-11-21 00:36:53,025 - mmcls - INFO - Epoch [46][200/391]	lr: 1.000e-01, eta: 1:14:12, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7414
2022-11-21 00:37:01,993 - mmcls - INFO - Epoch [46][300/391]	lr: 1.000e-01, eta: 1:14:10, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8354
2022-11-21 00:37:12,011 - mmcls - INFO - Epoch(val) [46][79]	train_accuracy: 56.9900, accuracy_top-1: 54.5300, accuracy_top-5: 83.1500
2022-11-21 00:37:22,849 - mmcls - INFO - Epoch [47][100/391]	lr: 1.000e-01, eta: 1:13:45, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8867
2022-11-21 00:37:31,784 - mmcls - INFO - Epoch [47][200/391]	lr: 1.000e-01, eta: 1:13:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9519
2022-11-21 00:37:40,726 - mmcls - INFO - Epoch [47][300/391]	lr: 1.000e-01, eta: 1:13:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8863
2022-11-21 00:37:50,794 - mmcls - INFO - Epoch(val) [47][79]	train_accuracy: 57.7240, accuracy_top-1: 55.3500, accuracy_top-5: 82.6700
2022-11-21 00:38:01,714 - mmcls - INFO - Epoch [48][100/391]	lr: 1.000e-01, eta: 1:13:16, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.9283
2022-11-21 00:38:10,587 - mmcls - INFO - Epoch [48][200/391]	lr: 1.000e-01, eta: 1:13:14, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8420
2022-11-21 00:38:19,516 - mmcls - INFO - Epoch [48][300/391]	lr: 1.000e-01, eta: 1:13:12, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8452
2022-11-21 00:38:29,591 - mmcls - INFO - Epoch(val) [48][79]	train_accuracy: 56.9420, accuracy_top-1: 54.7200, accuracy_top-5: 82.2600
2022-11-21 00:38:40,421 - mmcls - INFO - Epoch [49][100/391]	lr: 1.000e-01, eta: 1:12:47, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.9226
2022-11-21 00:38:49,326 - mmcls - INFO - Epoch [49][200/391]	lr: 1.000e-01, eta: 1:12:45, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8568
2022-11-21 00:38:58,277 - mmcls - INFO - Epoch [49][300/391]	lr: 1.000e-01, eta: 1:12:42, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8940
2022-11-21 00:39:08,245 - mmcls - INFO - Epoch(val) [49][79]	train_accuracy: 58.1840, accuracy_top-1: 58.3200, accuracy_top-5: 86.4000
2022-11-21 00:39:18,880 - mmcls - INFO - Epoch [50][100/391]	lr: 1.000e-01, eta: 1:12:17, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.7607
2022-11-21 00:39:27,696 - mmcls - INFO - Epoch [50][200/391]	lr: 1.000e-01, eta: 1:12:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9323
2022-11-21 00:39:36,484 - mmcls - INFO - Epoch [50][300/391]	lr: 1.000e-01, eta: 1:12:11, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8292
2022-11-21 00:39:44,505 - mmcls - INFO - Saving checkpoint at 50 epochs
2022-11-21 00:39:46,491 - mmcls - INFO - Epoch(val) [50][79]	train_accuracy: 58.0720, accuracy_top-1: 59.5000, accuracy_top-5: 87.6900
2022-11-21 00:39:57,398 - mmcls - INFO - Epoch [51][100/391]	lr: 1.000e-01, eta: 1:11:48, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.9365
2022-11-21 00:40:06,365 - mmcls - INFO - Epoch [51][200/391]	lr: 1.000e-01, eta: 1:11:45, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8064
2022-11-21 00:40:15,307 - mmcls - INFO - Epoch [51][300/391]	lr: 1.000e-01, eta: 1:11:42, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9492
2022-11-21 00:40:25,375 - mmcls - INFO - Epoch(val) [51][79]	train_accuracy: 57.4200, accuracy_top-1: 50.7500, accuracy_top-5: 79.8500
2022-11-21 00:40:36,057 - mmcls - INFO - Epoch [52][100/391]	lr: 1.000e-01, eta: 1:11:18, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8131
2022-11-21 00:40:44,966 - mmcls - INFO - Epoch [52][200/391]	lr: 1.000e-01, eta: 1:11:15, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8830
2022-11-21 00:40:53,877 - mmcls - INFO - Epoch [52][300/391]	lr: 1.000e-01, eta: 1:11:12, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9098
2022-11-21 00:41:03,889 - mmcls - INFO - Epoch(val) [52][79]	train_accuracy: 58.0780, accuracy_top-1: 54.6300, accuracy_top-5: 83.6700
2022-11-21 00:41:14,678 - mmcls - INFO - Epoch [53][100/391]	lr: 1.000e-01, eta: 1:10:49, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7202
2022-11-21 00:41:23,550 - mmcls - INFO - Epoch [53][200/391]	lr: 1.000e-01, eta: 1:10:46, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6490
2022-11-21 00:41:32,416 - mmcls - INFO - Epoch [53][300/391]	lr: 1.000e-01, eta: 1:10:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9584
2022-11-21 00:41:42,396 - mmcls - INFO - Epoch(val) [53][79]	train_accuracy: 58.8680, accuracy_top-1: 57.0700, accuracy_top-5: 85.4900
2022-11-21 00:41:53,006 - mmcls - INFO - Epoch [54][100/391]	lr: 1.000e-01, eta: 1:10:19, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.6979
2022-11-21 00:42:01,705 - mmcls - INFO - Epoch [54][200/391]	lr: 1.000e-01, eta: 1:10:15, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.8632
2022-11-21 00:42:10,611 - mmcls - INFO - Epoch [54][300/391]	lr: 1.000e-01, eta: 1:10:12, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9754
2022-11-21 00:42:20,771 - mmcls - INFO - Epoch(val) [54][79]	train_accuracy: 58.6980, accuracy_top-1: 50.1100, accuracy_top-5: 79.9300
2022-11-21 00:42:31,605 - mmcls - INFO - Epoch [55][100/391]	lr: 1.000e-01, eta: 1:09:49, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8284
2022-11-21 00:42:40,499 - mmcls - INFO - Epoch [55][200/391]	lr: 1.000e-01, eta: 1:09:46, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7825
2022-11-21 00:42:49,495 - mmcls - INFO - Epoch [55][300/391]	lr: 1.000e-01, eta: 1:09:43, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0351
2022-11-21 00:42:59,476 - mmcls - INFO - Epoch(val) [55][79]	train_accuracy: 57.5240, accuracy_top-1: 61.5300, accuracy_top-5: 87.0500
2022-11-21 00:43:10,340 - mmcls - INFO - Epoch [56][100/391]	lr: 1.000e-01, eta: 1:09:20, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8301
2022-11-21 00:43:19,132 - mmcls - INFO - Epoch [56][200/391]	lr: 1.000e-01, eta: 1:09:17, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8248
2022-11-21 00:43:27,920 - mmcls - INFO - Epoch [56][300/391]	lr: 1.000e-01, eta: 1:09:13, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8632
2022-11-21 00:43:37,921 - mmcls - INFO - Epoch(val) [56][79]	train_accuracy: 58.9420, accuracy_top-1: 56.9100, accuracy_top-5: 84.4600
2022-11-21 00:43:48,595 - mmcls - INFO - Epoch [57][100/391]	lr: 1.000e-01, eta: 1:08:50, time: 0.106, data_time: 0.021, memory: 1669, loss: 2.0061
2022-11-21 00:43:57,340 - mmcls - INFO - Epoch [57][200/391]	lr: 1.000e-01, eta: 1:08:47, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.7319
2022-11-21 00:44:06,249 - mmcls - INFO - Epoch [57][300/391]	lr: 1.000e-01, eta: 1:08:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9260
2022-11-21 00:44:16,226 - mmcls - INFO - Epoch(val) [57][79]	train_accuracy: 57.5780, accuracy_top-1: 55.4100, accuracy_top-5: 83.2700
2022-11-21 00:44:27,149 - mmcls - INFO - Epoch [58][100/391]	lr: 1.000e-01, eta: 1:08:21, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.7766
2022-11-21 00:44:36,024 - mmcls - INFO - Epoch [58][200/391]	lr: 1.000e-01, eta: 1:08:18, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9114
2022-11-21 00:44:44,847 - mmcls - INFO - Epoch [58][300/391]	lr: 1.000e-01, eta: 1:08:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8679
2022-11-21 00:44:54,813 - mmcls - INFO - Epoch(val) [58][79]	train_accuracy: 59.0060, accuracy_top-1: 57.8500, accuracy_top-5: 85.5400
2022-11-21 00:45:05,636 - mmcls - INFO - Epoch [59][100/391]	lr: 1.000e-01, eta: 1:07:52, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7454
2022-11-21 00:45:14,488 - mmcls - INFO - Epoch [59][200/391]	lr: 1.000e-01, eta: 1:07:48, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7688
2022-11-21 00:45:23,458 - mmcls - INFO - Epoch [59][300/391]	lr: 1.000e-01, eta: 1:07:45, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9111
2022-11-21 00:45:33,394 - mmcls - INFO - Epoch(val) [59][79]	train_accuracy: 58.2820, accuracy_top-1: 51.2600, accuracy_top-5: 79.7000
2022-11-21 00:45:43,969 - mmcls - INFO - Epoch [60][100/391]	lr: 1.000e-01, eta: 1:07:22, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.8461
2022-11-21 00:45:52,725 - mmcls - INFO - Epoch [60][200/391]	lr: 1.000e-01, eta: 1:07:18, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8885
2022-11-21 00:46:01,473 - mmcls - INFO - Epoch [60][300/391]	lr: 1.000e-01, eta: 1:07:14, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.9232
2022-11-21 00:46:09,564 - mmcls - INFO - Saving checkpoint at 60 epochs
2022-11-21 00:46:11,588 - mmcls - INFO - Epoch(val) [60][79]	train_accuracy: 59.4740, accuracy_top-1: 45.4200, accuracy_top-5: 75.4900
2022-11-21 00:46:22,477 - mmcls - INFO - Epoch [61][100/391]	lr: 1.000e-01, eta: 1:06:53, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.9545
2022-11-21 00:46:31,332 - mmcls - INFO - Epoch [61][200/391]	lr: 1.000e-01, eta: 1:06:49, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6998
2022-11-21 00:46:40,162 - mmcls - INFO - Epoch [61][300/391]	lr: 1.000e-01, eta: 1:06:45, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7414
2022-11-21 00:46:50,190 - mmcls - INFO - Epoch(val) [61][79]	train_accuracy: 59.0580, accuracy_top-1: 54.9900, accuracy_top-5: 82.8300
2022-11-21 00:47:01,033 - mmcls - INFO - Epoch [62][100/391]	lr: 1.000e-01, eta: 1:06:23, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8911
2022-11-21 00:47:09,845 - mmcls - INFO - Epoch [62][200/391]	lr: 1.000e-01, eta: 1:06:19, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8515
2022-11-21 00:47:18,788 - mmcls - INFO - Epoch [62][300/391]	lr: 1.000e-01, eta: 1:06:16, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9472
2022-11-21 00:47:28,725 - mmcls - INFO - Epoch(val) [62][79]	train_accuracy: 57.3200, accuracy_top-1: 60.5700, accuracy_top-5: 86.6100
2022-11-21 00:47:39,493 - mmcls - INFO - Epoch [63][100/391]	lr: 1.000e-01, eta: 1:05:54, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7463
2022-11-21 00:47:48,306 - mmcls - INFO - Epoch [63][200/391]	lr: 1.000e-01, eta: 1:05:50, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8683
2022-11-21 00:47:57,128 - mmcls - INFO - Epoch [63][300/391]	lr: 1.000e-01, eta: 1:05:46, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7925
2022-11-21 00:48:07,219 - mmcls - INFO - Epoch(val) [63][79]	train_accuracy: 59.0720, accuracy_top-1: 58.1800, accuracy_top-5: 85.2300
2022-11-21 00:48:18,073 - mmcls - INFO - Epoch [64][100/391]	lr: 1.000e-01, eta: 1:05:25, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7885
2022-11-21 00:48:27,099 - mmcls - INFO - Epoch [64][200/391]	lr: 1.000e-01, eta: 1:05:21, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8019
2022-11-21 00:48:35,963 - mmcls - INFO - Epoch [64][300/391]	lr: 1.000e-01, eta: 1:05:17, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9934
2022-11-21 00:48:45,944 - mmcls - INFO - Epoch(val) [64][79]	train_accuracy: 57.6360, accuracy_top-1: 59.9300, accuracy_top-5: 85.8200
2022-11-21 00:48:56,677 - mmcls - INFO - Epoch [65][100/391]	lr: 1.000e-01, eta: 1:04:56, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7796
2022-11-21 00:49:05,660 - mmcls - INFO - Epoch [65][200/391]	lr: 1.000e-01, eta: 1:04:52, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7618
2022-11-21 00:49:14,636 - mmcls - INFO - Epoch [65][300/391]	lr: 1.000e-01, eta: 1:04:48, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.1465
2022-11-21 00:49:24,666 - mmcls - INFO - Epoch(val) [65][79]	train_accuracy: 58.5120, accuracy_top-1: 53.3700, accuracy_top-5: 80.6300
2022-11-21 00:49:35,418 - mmcls - INFO - Epoch [66][100/391]	lr: 1.000e-01, eta: 1:04:27, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8979
2022-11-21 00:49:44,179 - mmcls - INFO - Epoch [66][200/391]	lr: 1.000e-01, eta: 1:04:23, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7619
2022-11-21 00:49:53,003 - mmcls - INFO - Epoch [66][300/391]	lr: 1.000e-01, eta: 1:04:19, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9635
2022-11-21 00:50:02,883 - mmcls - INFO - Epoch(val) [66][79]	train_accuracy: 57.3740, accuracy_top-1: 57.9900, accuracy_top-5: 85.0600
2022-11-21 00:50:13,735 - mmcls - INFO - Epoch [67][100/391]	lr: 1.000e-01, eta: 1:03:58, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.6261
2022-11-21 00:50:22,715 - mmcls - INFO - Epoch [67][200/391]	lr: 1.000e-01, eta: 1:03:54, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.9207
2022-11-21 00:50:31,724 - mmcls - INFO - Epoch [67][300/391]	lr: 1.000e-01, eta: 1:03:50, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8096
2022-11-21 00:50:41,767 - mmcls - INFO - Epoch(val) [67][79]	train_accuracy: 59.7980, accuracy_top-1: 58.1100, accuracy_top-5: 85.8300
2022-11-21 00:50:52,600 - mmcls - INFO - Epoch [68][100/391]	lr: 1.000e-01, eta: 1:03:29, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8248
2022-11-21 00:51:01,529 - mmcls - INFO - Epoch [68][200/391]	lr: 1.000e-01, eta: 1:03:25, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7046
2022-11-21 00:51:10,524 - mmcls - INFO - Epoch [68][300/391]	lr: 1.000e-01, eta: 1:03:21, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8529
2022-11-21 00:51:20,546 - mmcls - INFO - Epoch(val) [68][79]	train_accuracy: 59.4460, accuracy_top-1: 55.9000, accuracy_top-5: 83.4400
2022-11-21 00:51:31,276 - mmcls - INFO - Epoch [69][100/391]	lr: 1.000e-01, eta: 1:03:01, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6887
2022-11-21 00:51:40,050 - mmcls - INFO - Epoch [69][200/391]	lr: 1.000e-01, eta: 1:02:56, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7090
2022-11-21 00:51:48,849 - mmcls - INFO - Epoch [69][300/391]	lr: 1.000e-01, eta: 1:02:51, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8483
2022-11-21 00:51:58,761 - mmcls - INFO - Epoch(val) [69][79]	train_accuracy: 60.0540, accuracy_top-1: 59.0500, accuracy_top-5: 85.8300
2022-11-21 00:52:09,642 - mmcls - INFO - Epoch [70][100/391]	lr: 1.000e-01, eta: 1:02:31, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.8230
2022-11-21 00:52:18,581 - mmcls - INFO - Epoch [70][200/391]	lr: 1.000e-01, eta: 1:02:27, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8314
2022-11-21 00:52:27,680 - mmcls - INFO - Epoch [70][300/391]	lr: 1.000e-01, eta: 1:02:23, time: 0.091, data_time: 0.001, memory: 1669, loss: 1.7930
2022-11-21 00:52:35,722 - mmcls - INFO - Saving checkpoint at 70 epochs
2022-11-21 00:52:37,728 - mmcls - INFO - Epoch(val) [70][79]	train_accuracy: 59.7420, accuracy_top-1: 59.3600, accuracy_top-5: 85.8600
2022-11-21 00:52:48,473 - mmcls - INFO - Epoch [71][100/391]	lr: 1.000e-01, eta: 1:02:03, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9776
2022-11-21 00:52:57,363 - mmcls - INFO - Epoch [71][200/391]	lr: 1.000e-01, eta: 1:01:58, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7613
2022-11-21 00:53:06,294 - mmcls - INFO - Epoch [71][300/391]	lr: 1.000e-01, eta: 1:01:54, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7905
2022-11-21 00:53:16,341 - mmcls - INFO - Epoch(val) [71][79]	train_accuracy: 59.5420, accuracy_top-1: 56.9600, accuracy_top-5: 83.4500
2022-11-21 00:53:27,172 - mmcls - INFO - Epoch [72][100/391]	lr: 1.000e-01, eta: 1:01:34, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8416
2022-11-21 00:53:35,897 - mmcls - INFO - Epoch [72][200/391]	lr: 1.000e-01, eta: 1:01:29, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.6918
2022-11-21 00:53:44,754 - mmcls - INFO - Epoch [72][300/391]	lr: 1.000e-01, eta: 1:01:24, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9441
2022-11-21 00:53:54,671 - mmcls - INFO - Epoch(val) [72][79]	train_accuracy: 58.4440, accuracy_top-1: 56.8800, accuracy_top-5: 84.5500
2022-11-21 00:54:05,429 - mmcls - INFO - Epoch [73][100/391]	lr: 1.000e-01, eta: 1:01:05, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8306
2022-11-21 00:54:14,424 - mmcls - INFO - Epoch [73][200/391]	lr: 1.000e-01, eta: 1:01:00, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8727
2022-11-21 00:54:23,398 - mmcls - INFO - Epoch [73][300/391]	lr: 1.000e-01, eta: 1:00:56, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7538
2022-11-21 00:54:33,420 - mmcls - INFO - Epoch(val) [73][79]	train_accuracy: 59.0900, accuracy_top-1: 49.8900, accuracy_top-5: 79.8800
2022-11-21 00:54:44,182 - mmcls - INFO - Epoch [74][100/391]	lr: 1.000e-01, eta: 1:00:36, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7750
2022-11-21 00:54:53,007 - mmcls - INFO - Epoch [74][200/391]	lr: 1.000e-01, eta: 1:00:31, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8747
2022-11-21 00:55:01,859 - mmcls - INFO - Epoch [74][300/391]	lr: 1.000e-01, eta: 1:00:26, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7313
2022-11-21 00:55:11,806 - mmcls - INFO - Epoch(val) [74][79]	train_accuracy: 59.4460, accuracy_top-1: 59.5900, accuracy_top-5: 85.3900
2022-11-21 00:55:22,478 - mmcls - INFO - Epoch [75][100/391]	lr: 1.000e-01, eta: 1:00:07, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.7099
2022-11-21 00:55:31,294 - mmcls - INFO - Epoch [75][200/391]	lr: 1.000e-01, eta: 1:00:02, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9348
2022-11-21 00:55:40,071 - mmcls - INFO - Epoch [75][300/391]	lr: 1.000e-01, eta: 0:59:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8411
2022-11-21 00:55:49,974 - mmcls - INFO - Epoch(val) [75][79]	train_accuracy: 59.1560, accuracy_top-1: 60.6100, accuracy_top-5: 86.2200
2022-11-21 00:56:00,734 - mmcls - INFO - Epoch [76][100/391]	lr: 1.000e-01, eta: 0:59:37, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9152
2022-11-21 00:56:09,711 - mmcls - INFO - Epoch [76][200/391]	lr: 1.000e-01, eta: 0:59:33, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7797
2022-11-21 00:56:18,632 - mmcls - INFO - Epoch [76][300/391]	lr: 1.000e-01, eta: 0:59:28, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7288
2022-11-21 00:56:28,641 - mmcls - INFO - Epoch(val) [76][79]	train_accuracy: 59.4280, accuracy_top-1: 57.2300, accuracy_top-5: 84.5200
2022-11-21 00:56:39,337 - mmcls - INFO - Epoch [77][100/391]	lr: 1.000e-01, eta: 0:59:08, time: 0.107, data_time: 0.020, memory: 1669, loss: 1.6407
2022-11-21 00:56:48,216 - mmcls - INFO - Epoch [77][200/391]	lr: 1.000e-01, eta: 0:59:04, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6669
2022-11-21 00:56:57,187 - mmcls - INFO - Epoch [77][300/391]	lr: 1.000e-01, eta: 0:58:59, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7969
2022-11-21 00:57:07,278 - mmcls - INFO - Epoch(val) [77][79]	train_accuracy: 60.9300, accuracy_top-1: 58.6700, accuracy_top-5: 84.7700
2022-11-21 00:57:18,111 - mmcls - INFO - Epoch [78][100/391]	lr: 1.000e-01, eta: 0:58:40, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.6841
2022-11-21 00:57:26,981 - mmcls - INFO - Epoch [78][200/391]	lr: 1.000e-01, eta: 0:58:35, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7352
2022-11-21 00:57:35,789 - mmcls - INFO - Epoch [78][300/391]	lr: 1.000e-01, eta: 0:58:30, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8010
2022-11-21 00:57:45,621 - mmcls - INFO - Epoch(val) [78][79]	train_accuracy: 61.1440, accuracy_top-1: 58.0300, accuracy_top-5: 85.1500
2022-11-21 00:57:56,273 - mmcls - INFO - Epoch [79][100/391]	lr: 1.000e-01, eta: 0:58:10, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.7769
2022-11-21 00:58:05,128 - mmcls - INFO - Epoch [79][200/391]	lr: 1.000e-01, eta: 0:58:05, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8029
2022-11-21 00:58:14,083 - mmcls - INFO - Epoch [79][300/391]	lr: 1.000e-01, eta: 0:58:01, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.0040
2022-11-21 00:58:24,092 - mmcls - INFO - Epoch(val) [79][79]	train_accuracy: 59.0080, accuracy_top-1: 57.6600, accuracy_top-5: 84.0900
2022-11-21 00:58:34,889 - mmcls - INFO - Epoch [80][100/391]	lr: 1.000e-01, eta: 0:57:42, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7339
2022-11-21 00:58:43,864 - mmcls - INFO - Epoch [80][200/391]	lr: 1.000e-01, eta: 0:57:37, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8365
2022-11-21 00:58:52,784 - mmcls - INFO - Epoch [80][300/391]	lr: 1.000e-01, eta: 0:57:32, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6973
2022-11-21 00:59:00,926 - mmcls - INFO - Saving checkpoint at 80 epochs
2022-11-21 00:59:02,923 - mmcls - INFO - Epoch(val) [80][79]	train_accuracy: 60.6260, accuracy_top-1: 58.2900, accuracy_top-5: 85.0100
2022-11-21 00:59:13,786 - mmcls - INFO - Epoch [81][100/391]	lr: 1.000e-01, eta: 0:57:13, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7903
2022-11-21 00:59:22,800 - mmcls - INFO - Epoch [81][200/391]	lr: 1.000e-01, eta: 0:57:08, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.6741
2022-11-21 00:59:31,610 - mmcls - INFO - Epoch [81][300/391]	lr: 1.000e-01, eta: 0:57:03, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7612
2022-11-21 00:59:41,672 - mmcls - INFO - Epoch(val) [81][79]	train_accuracy: 60.3720, accuracy_top-1: 55.5100, accuracy_top-5: 83.2800
2022-11-21 00:59:52,377 - mmcls - INFO - Epoch [82][100/391]	lr: 1.000e-01, eta: 0:56:44, time: 0.107, data_time: 0.020, memory: 1669, loss: 1.8452
2022-11-21 01:00:01,160 - mmcls - INFO - Epoch [82][200/391]	lr: 1.000e-01, eta: 0:56:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6531
2022-11-21 01:00:10,203 - mmcls - INFO - Epoch [82][300/391]	lr: 1.000e-01, eta: 0:56:34, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7686
2022-11-21 01:00:20,332 - mmcls - INFO - Epoch(val) [82][79]	train_accuracy: 60.6240, accuracy_top-1: 58.0800, accuracy_top-5: 84.8000
2022-11-21 01:00:31,181 - mmcls - INFO - Epoch [83][100/391]	lr: 1.000e-01, eta: 0:56:15, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.9207
2022-11-21 01:00:40,099 - mmcls - INFO - Epoch [83][200/391]	lr: 1.000e-01, eta: 0:56:10, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6961
2022-11-21 01:00:49,034 - mmcls - INFO - Epoch [83][300/391]	lr: 1.000e-01, eta: 0:56:05, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7806
2022-11-21 01:00:59,012 - mmcls - INFO - Epoch(val) [83][79]	train_accuracy: 58.9460, accuracy_top-1: 54.7500, accuracy_top-5: 82.6700
2022-11-21 01:01:09,897 - mmcls - INFO - Epoch [84][100/391]	lr: 1.000e-01, eta: 0:55:47, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.7510
2022-11-21 01:01:18,821 - mmcls - INFO - Epoch [84][200/391]	lr: 1.000e-01, eta: 0:55:42, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7389
2022-11-21 01:01:27,737 - mmcls - INFO - Epoch [84][300/391]	lr: 1.000e-01, eta: 0:55:36, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6751
2022-11-21 01:01:37,720 - mmcls - INFO - Epoch(val) [84][79]	train_accuracy: 61.3300, accuracy_top-1: 56.0200, accuracy_top-5: 81.7100
2022-11-21 01:01:48,435 - mmcls - INFO - Epoch [85][100/391]	lr: 1.000e-01, eta: 0:55:18, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7786
2022-11-21 01:01:57,204 - mmcls - INFO - Epoch [85][200/391]	lr: 1.000e-01, eta: 0:55:12, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8177
2022-11-21 01:02:06,118 - mmcls - INFO - Epoch [85][300/391]	lr: 1.000e-01, eta: 0:55:07, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7745
2022-11-21 01:02:16,128 - mmcls - INFO - Epoch(val) [85][79]	train_accuracy: 60.4440, accuracy_top-1: 56.7200, accuracy_top-5: 84.0500
2022-11-21 01:02:26,888 - mmcls - INFO - Epoch [86][100/391]	lr: 1.000e-01, eta: 0:54:49, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6729
2022-11-21 01:02:35,793 - mmcls - INFO - Epoch [86][200/391]	lr: 1.000e-01, eta: 0:54:44, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7848
2022-11-21 01:02:44,769 - mmcls - INFO - Epoch [86][300/391]	lr: 1.000e-01, eta: 0:54:38, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8705
2022-11-21 01:02:54,763 - mmcls - INFO - Epoch(val) [86][79]	train_accuracy: 60.6600, accuracy_top-1: 61.1200, accuracy_top-5: 87.3000
2022-11-21 01:03:05,506 - mmcls - INFO - Epoch [87][100/391]	lr: 1.000e-01, eta: 0:54:20, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8085
2022-11-21 01:03:14,383 - mmcls - INFO - Epoch [87][200/391]	lr: 1.000e-01, eta: 0:54:15, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8317
2022-11-21 01:03:23,208 - mmcls - INFO - Epoch [87][300/391]	lr: 1.000e-01, eta: 0:54:09, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7246
2022-11-21 01:03:33,135 - mmcls - INFO - Epoch(val) [87][79]	train_accuracy: 59.5500, accuracy_top-1: 58.4300, accuracy_top-5: 85.7000
2022-11-21 01:03:43,968 - mmcls - INFO - Epoch [88][100/391]	lr: 1.000e-01, eta: 0:53:51, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7110
2022-11-21 01:03:52,985 - mmcls - INFO - Epoch [88][200/391]	lr: 1.000e-01, eta: 0:53:46, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8109
2022-11-21 01:04:01,932 - mmcls - INFO - Epoch [88][300/391]	lr: 1.000e-01, eta: 0:53:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6095
2022-11-21 01:04:11,896 - mmcls - INFO - Epoch(val) [88][79]	train_accuracy: 62.0420, accuracy_top-1: 58.6700, accuracy_top-5: 86.2800
2022-11-21 01:04:22,737 - mmcls - INFO - Epoch [89][100/391]	lr: 1.000e-01, eta: 0:53:23, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.9238
2022-11-21 01:04:31,751 - mmcls - INFO - Epoch [89][200/391]	lr: 1.000e-01, eta: 0:53:17, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7860
2022-11-21 01:04:40,634 - mmcls - INFO - Epoch [89][300/391]	lr: 1.000e-01, eta: 0:53:12, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7199
2022-11-21 01:04:50,598 - mmcls - INFO - Epoch(val) [89][79]	train_accuracy: 60.1100, accuracy_top-1: 59.4700, accuracy_top-5: 86.9400
2022-11-21 01:05:01,355 - mmcls - INFO - Epoch [90][100/391]	lr: 1.000e-01, eta: 0:52:54, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7103
2022-11-21 01:05:10,259 - mmcls - INFO - Epoch [90][200/391]	lr: 1.000e-01, eta: 0:52:49, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7611
2022-11-21 01:05:19,168 - mmcls - INFO - Epoch [90][300/391]	lr: 1.000e-01, eta: 0:52:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8927
2022-11-21 01:05:27,233 - mmcls - INFO - Saving checkpoint at 90 epochs
2022-11-21 01:05:29,250 - mmcls - INFO - Epoch(val) [90][79]	train_accuracy: 61.1060, accuracy_top-1: 58.3900, accuracy_top-5: 84.8100
2022-11-21 01:05:39,939 - mmcls - INFO - Epoch [91][100/391]	lr: 1.000e-01, eta: 0:52:25, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6757
2022-11-21 01:05:48,731 - mmcls - INFO - Epoch [91][200/391]	lr: 1.000e-01, eta: 0:52:19, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7184
2022-11-21 01:05:57,561 - mmcls - INFO - Epoch [91][300/391]	lr: 1.000e-01, eta: 0:52:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7771
2022-11-21 01:06:07,588 - mmcls - INFO - Epoch(val) [91][79]	train_accuracy: 60.7100, accuracy_top-1: 52.5400, accuracy_top-5: 79.5000
2022-11-21 01:06:18,438 - mmcls - INFO - Epoch [92][100/391]	lr: 1.000e-01, eta: 0:51:56, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7157
2022-11-21 01:06:27,351 - mmcls - INFO - Epoch [92][200/391]	lr: 1.000e-01, eta: 0:51:51, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6618
2022-11-21 01:06:36,259 - mmcls - INFO - Epoch [92][300/391]	lr: 1.000e-01, eta: 0:51:45, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8189
2022-11-21 01:06:46,237 - mmcls - INFO - Epoch(val) [92][79]	train_accuracy: 60.7340, accuracy_top-1: 62.0400, accuracy_top-5: 87.4200
2022-11-21 01:06:57,010 - mmcls - INFO - Epoch [93][100/391]	lr: 1.000e-01, eta: 0:51:27, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6638
2022-11-21 01:07:05,941 - mmcls - INFO - Epoch [93][200/391]	lr: 1.000e-01, eta: 0:51:22, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6507
2022-11-21 01:07:14,816 - mmcls - INFO - Epoch [93][300/391]	lr: 1.000e-01, eta: 0:51:16, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9109
2022-11-21 01:07:24,776 - mmcls - INFO - Epoch(val) [93][79]	train_accuracy: 60.8000, accuracy_top-1: 60.5600, accuracy_top-5: 87.2300
2022-11-21 01:07:35,492 - mmcls - INFO - Epoch [94][100/391]	lr: 1.000e-01, eta: 0:50:58, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6916
2022-11-21 01:07:44,207 - mmcls - INFO - Epoch [94][200/391]	lr: 1.000e-01, eta: 0:50:53, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.7131
2022-11-21 01:07:53,041 - mmcls - INFO - Epoch [94][300/391]	lr: 1.000e-01, eta: 0:50:47, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8206
2022-11-21 01:08:02,960 - mmcls - INFO - Epoch(val) [94][79]	train_accuracy: 61.1400, accuracy_top-1: 57.8900, accuracy_top-5: 85.9700
2022-11-21 01:08:13,880 - mmcls - INFO - Epoch [95][100/391]	lr: 1.000e-01, eta: 0:50:30, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.8563
2022-11-21 01:08:22,937 - mmcls - INFO - Epoch [95][200/391]	lr: 1.000e-01, eta: 0:50:24, time: 0.091, data_time: 0.001, memory: 1669, loss: 1.6952
2022-11-21 01:08:31,959 - mmcls - INFO - Epoch [95][300/391]	lr: 1.000e-01, eta: 0:50:19, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7327
2022-11-21 01:08:41,828 - mmcls - INFO - Epoch(val) [95][79]	train_accuracy: 61.5620, accuracy_top-1: 59.2900, accuracy_top-5: 85.4100
2022-11-21 01:08:52,588 - mmcls - INFO - Epoch [96][100/391]	lr: 1.000e-01, eta: 0:50:01, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7147
2022-11-21 01:09:01,512 - mmcls - INFO - Epoch [96][200/391]	lr: 1.000e-01, eta: 0:49:55, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7582
2022-11-21 01:09:10,466 - mmcls - INFO - Epoch [96][300/391]	lr: 1.000e-01, eta: 0:49:50, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.8088
2022-11-21 01:09:20,487 - mmcls - INFO - Epoch(val) [96][79]	train_accuracy: 60.9560, accuracy_top-1: 53.8500, accuracy_top-5: 81.9900
2022-11-21 01:09:31,287 - mmcls - INFO - Epoch [97][100/391]	lr: 1.000e-01, eta: 0:49:32, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7226
2022-11-21 01:09:40,159 - mmcls - INFO - Epoch [97][200/391]	lr: 1.000e-01, eta: 0:49:27, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6864
2022-11-21 01:09:49,101 - mmcls - INFO - Epoch [97][300/391]	lr: 1.000e-01, eta: 0:49:21, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6472
2022-11-21 01:09:59,119 - mmcls - INFO - Epoch(val) [97][79]	train_accuracy: 62.5860, accuracy_top-1: 58.8200, accuracy_top-5: 84.9400
2022-11-21 01:10:09,999 - mmcls - INFO - Epoch [98][100/391]	lr: 1.000e-01, eta: 0:49:04, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.8983
2022-11-21 01:10:19,041 - mmcls - INFO - Epoch [98][200/391]	lr: 1.000e-01, eta: 0:48:58, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7319
2022-11-21 01:10:28,005 - mmcls - INFO - Epoch [98][300/391]	lr: 1.000e-01, eta: 0:48:53, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7906
2022-11-21 01:10:38,018 - mmcls - INFO - Epoch(val) [98][79]	train_accuracy: 59.9920, accuracy_top-1: 57.3800, accuracy_top-5: 84.7900
2022-11-21 01:10:48,747 - mmcls - INFO - Epoch [99][100/391]	lr: 1.000e-01, eta: 0:48:35, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7791
2022-11-21 01:10:57,689 - mmcls - INFO - Epoch [99][200/391]	lr: 1.000e-01, eta: 0:48:29, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7634
2022-11-21 01:11:06,634 - mmcls - INFO - Epoch [99][300/391]	lr: 1.000e-01, eta: 0:48:24, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9452
2022-11-21 01:11:16,607 - mmcls - INFO - Epoch(val) [99][79]	train_accuracy: 60.4560, accuracy_top-1: 60.3400, accuracy_top-5: 86.2300
2022-11-21 01:11:27,374 - mmcls - INFO - Epoch [100][100/391]	lr: 1.000e-01, eta: 0:48:06, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6545
2022-11-21 01:11:36,155 - mmcls - INFO - Epoch [100][200/391]	lr: 1.000e-01, eta: 0:48:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7276
2022-11-21 01:11:45,026 - mmcls - INFO - Epoch [100][300/391]	lr: 1.000e-01, eta: 0:47:55, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7679
2022-11-21 01:11:53,011 - mmcls - INFO - Saving checkpoint at 100 epochs
2022-11-21 01:11:55,006 - mmcls - INFO - Epoch(val) [100][79]	train_accuracy: 61.9900, accuracy_top-1: 61.2900, accuracy_top-5: 87.5100
2022-11-21 01:12:05,764 - mmcls - INFO - Epoch [101][100/391]	lr: 1.000e-02, eta: 0:47:38, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.5636
2022-11-21 01:12:14,773 - mmcls - INFO - Epoch [101][200/391]	lr: 1.000e-02, eta: 0:47:32, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.4427
2022-11-21 01:12:23,778 - mmcls - INFO - Epoch [101][300/391]	lr: 1.000e-02, eta: 0:47:26, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.2115
2022-11-21 01:12:33,814 - mmcls - INFO - Epoch(val) [101][79]	train_accuracy: 71.4140, accuracy_top-1: 75.6600, accuracy_top-5: 94.5000
2022-11-21 01:12:44,501 - mmcls - INFO - Epoch [102][100/391]	lr: 1.000e-02, eta: 0:47:09, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.5485
2022-11-21 01:12:53,304 - mmcls - INFO - Epoch [102][200/391]	lr: 1.000e-02, eta: 0:47:03, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2564
2022-11-21 01:13:02,251 - mmcls - INFO - Epoch [102][300/391]	lr: 1.000e-02, eta: 0:46:57, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2204
2022-11-21 01:13:12,246 - mmcls - INFO - Epoch(val) [102][79]	train_accuracy: 74.1440, accuracy_top-1: 76.4800, accuracy_top-5: 94.9000
2022-11-21 01:13:23,064 - mmcls - INFO - Epoch [103][100/391]	lr: 1.000e-02, eta: 0:46:40, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.4664
2022-11-21 01:13:31,959 - mmcls - INFO - Epoch [103][200/391]	lr: 1.000e-02, eta: 0:46:34, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2240
2022-11-21 01:13:40,866 - mmcls - INFO - Epoch [103][300/391]	lr: 1.000e-02, eta: 0:46:28, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3068
2022-11-21 01:13:50,807 - mmcls - INFO - Epoch(val) [103][79]	train_accuracy: 74.6860, accuracy_top-1: 76.5600, accuracy_top-5: 94.9700
2022-11-21 01:14:01,474 - mmcls - INFO - Epoch [104][100/391]	lr: 1.000e-02, eta: 0:46:11, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1758
2022-11-21 01:14:10,442 - mmcls - INFO - Epoch [104][200/391]	lr: 1.000e-02, eta: 0:46:05, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.2374
2022-11-21 01:14:19,423 - mmcls - INFO - Epoch [104][300/391]	lr: 1.000e-02, eta: 0:46:00, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.2292
2022-11-21 01:14:29,437 - mmcls - INFO - Epoch(val) [104][79]	train_accuracy: 75.5560, accuracy_top-1: 76.9700, accuracy_top-5: 95.1000
2022-11-21 01:14:40,215 - mmcls - INFO - Epoch [105][100/391]	lr: 1.000e-02, eta: 0:45:43, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.2523
2022-11-21 01:14:49,129 - mmcls - INFO - Epoch [105][200/391]	lr: 1.000e-02, eta: 0:45:37, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2158
2022-11-21 01:14:58,058 - mmcls - INFO - Epoch [105][300/391]	lr: 1.000e-02, eta: 0:45:31, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3271
2022-11-21 01:15:08,129 - mmcls - INFO - Epoch(val) [105][79]	train_accuracy: 75.4080, accuracy_top-1: 76.8300, accuracy_top-5: 95.2400
2022-11-21 01:15:18,953 - mmcls - INFO - Epoch [106][100/391]	lr: 1.000e-02, eta: 0:45:14, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.2796
2022-11-21 01:15:27,887 - mmcls - INFO - Epoch [106][200/391]	lr: 1.000e-02, eta: 0:45:08, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2101
2022-11-21 01:15:36,674 - mmcls - INFO - Epoch [106][300/391]	lr: 1.000e-02, eta: 0:45:02, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4012
2022-11-21 01:15:46,486 - mmcls - INFO - Epoch(val) [106][79]	train_accuracy: 76.0480, accuracy_top-1: 77.1800, accuracy_top-5: 95.0500
2022-11-21 01:15:57,059 - mmcls - INFO - Epoch [107][100/391]	lr: 1.000e-02, eta: 0:44:45, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.0887
2022-11-21 01:16:05,945 - mmcls - INFO - Epoch [107][200/391]	lr: 1.000e-02, eta: 0:44:39, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1746
2022-11-21 01:16:14,943 - mmcls - INFO - Epoch [107][300/391]	lr: 1.000e-02, eta: 0:44:33, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.2278
2022-11-21 01:16:24,916 - mmcls - INFO - Epoch(val) [107][79]	train_accuracy: 78.8380, accuracy_top-1: 77.5400, accuracy_top-5: 95.3100
2022-11-21 01:16:35,684 - mmcls - INFO - Epoch [108][100/391]	lr: 1.000e-02, eta: 0:44:16, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.1520
2022-11-21 01:16:44,468 - mmcls - INFO - Epoch [108][200/391]	lr: 1.000e-02, eta: 0:44:10, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1430
2022-11-21 01:16:53,386 - mmcls - INFO - Epoch [108][300/391]	lr: 1.000e-02, eta: 0:44:04, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3958
2022-11-21 01:17:03,333 - mmcls - INFO - Epoch(val) [108][79]	train_accuracy: 77.2080, accuracy_top-1: 77.8000, accuracy_top-5: 95.2000
2022-11-21 01:17:14,057 - mmcls - INFO - Epoch [109][100/391]	lr: 1.000e-02, eta: 0:43:47, time: 0.107, data_time: 0.020, memory: 1669, loss: 1.2252
2022-11-21 01:17:22,937 - mmcls - INFO - Epoch [109][200/391]	lr: 1.000e-02, eta: 0:43:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1532
2022-11-21 01:17:31,835 - mmcls - INFO - Epoch [109][300/391]	lr: 1.000e-02, eta: 0:43:35, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1924
2022-11-21 01:17:41,730 - mmcls - INFO - Epoch(val) [109][79]	train_accuracy: 78.2160, accuracy_top-1: 77.7400, accuracy_top-5: 95.1300
2022-11-21 01:17:52,398 - mmcls - INFO - Epoch [110][100/391]	lr: 1.000e-02, eta: 0:43:19, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1331
2022-11-21 01:18:01,190 - mmcls - INFO - Epoch [110][200/391]	lr: 1.000e-02, eta: 0:43:13, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0937
2022-11-21 01:18:10,111 - mmcls - INFO - Epoch [110][300/391]	lr: 1.000e-02, eta: 0:43:06, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1651
2022-11-21 01:18:18,195 - mmcls - INFO - Saving checkpoint at 110 epochs
2022-11-21 01:18:20,211 - mmcls - INFO - Epoch(val) [110][79]	train_accuracy: 78.5620, accuracy_top-1: 77.7900, accuracy_top-5: 95.1400
2022-11-21 01:18:31,043 - mmcls - INFO - Epoch [111][100/391]	lr: 1.000e-02, eta: 0:42:50, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.1066
2022-11-21 01:18:39,928 - mmcls - INFO - Epoch [111][200/391]	lr: 1.000e-02, eta: 0:42:44, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1506
2022-11-21 01:18:48,968 - mmcls - INFO - Epoch [111][300/391]	lr: 1.000e-02, eta: 0:42:38, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.1927
2022-11-21 01:18:59,076 - mmcls - INFO - Epoch(val) [111][79]	train_accuracy: 79.2320, accuracy_top-1: 77.6200, accuracy_top-5: 95.3600
2022-11-21 01:19:09,865 - mmcls - INFO - Epoch [112][100/391]	lr: 1.000e-02, eta: 0:42:21, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.2693
2022-11-21 01:19:18,730 - mmcls - INFO - Epoch [112][200/391]	lr: 1.000e-02, eta: 0:42:15, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1840
2022-11-21 01:19:27,648 - mmcls - INFO - Epoch [112][300/391]	lr: 1.000e-02, eta: 0:42:09, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1524
2022-11-21 01:19:37,587 - mmcls - INFO - Epoch(val) [112][79]	train_accuracy: 77.5480, accuracy_top-1: 77.5200, accuracy_top-5: 95.1400
2022-11-21 01:19:48,277 - mmcls - INFO - Epoch [113][100/391]	lr: 1.000e-02, eta: 0:41:52, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0272
2022-11-21 01:19:57,142 - mmcls - INFO - Epoch [113][200/391]	lr: 1.000e-02, eta: 0:41:46, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1873
2022-11-21 01:20:06,091 - mmcls - INFO - Epoch [113][300/391]	lr: 1.000e-02, eta: 0:41:40, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.3387
2022-11-21 01:20:16,196 - mmcls - INFO - Epoch(val) [113][79]	train_accuracy: 78.1860, accuracy_top-1: 77.8000, accuracy_top-5: 95.4000
2022-11-21 01:20:27,047 - mmcls - INFO - Epoch [114][100/391]	lr: 1.000e-02, eta: 0:41:24, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.1620
2022-11-21 01:20:36,115 - mmcls - INFO - Epoch [114][200/391]	lr: 1.000e-02, eta: 0:41:18, time: 0.091, data_time: 0.001, memory: 1669, loss: 1.1702
2022-11-21 01:20:44,988 - mmcls - INFO - Epoch [114][300/391]	lr: 1.000e-02, eta: 0:41:12, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2768
2022-11-21 01:20:54,966 - mmcls - INFO - Epoch(val) [114][79]	train_accuracy: 78.2860, accuracy_top-1: 77.3400, accuracy_top-5: 94.9800
2022-11-21 01:21:05,762 - mmcls - INFO - Epoch [115][100/391]	lr: 1.000e-02, eta: 0:40:55, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0659
2022-11-21 01:21:14,672 - mmcls - INFO - Epoch [115][200/391]	lr: 1.000e-02, eta: 0:40:49, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2457
2022-11-21 01:21:23,512 - mmcls - INFO - Epoch [115][300/391]	lr: 1.000e-02, eta: 0:40:43, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2101
2022-11-21 01:21:33,440 - mmcls - INFO - Epoch(val) [115][79]	train_accuracy: 78.1460, accuracy_top-1: 77.5000, accuracy_top-5: 95.0000
2022-11-21 01:21:44,026 - mmcls - INFO - Epoch [116][100/391]	lr: 1.000e-02, eta: 0:40:26, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0838
2022-11-21 01:21:52,824 - mmcls - INFO - Epoch [116][200/391]	lr: 1.000e-02, eta: 0:40:20, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4140
2022-11-21 01:22:01,627 - mmcls - INFO - Epoch [116][300/391]	lr: 1.000e-02, eta: 0:40:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2237
2022-11-21 01:22:11,673 - mmcls - INFO - Epoch(val) [116][79]	train_accuracy: 77.6000, accuracy_top-1: 77.7100, accuracy_top-5: 95.2700
2022-11-21 01:22:22,470 - mmcls - INFO - Epoch [117][100/391]	lr: 1.000e-02, eta: 0:39:58, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0337
2022-11-21 01:22:31,392 - mmcls - INFO - Epoch [117][200/391]	lr: 1.000e-02, eta: 0:39:51, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9831
2022-11-21 01:22:40,240 - mmcls - INFO - Epoch [117][300/391]	lr: 1.000e-02, eta: 0:39:45, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0342
2022-11-21 01:22:50,212 - mmcls - INFO - Epoch(val) [117][79]	train_accuracy: 81.5200, accuracy_top-1: 77.9900, accuracy_top-5: 95.2800
2022-11-21 01:23:01,028 - mmcls - INFO - Epoch [118][100/391]	lr: 1.000e-02, eta: 0:39:29, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9475
2022-11-21 01:23:09,894 - mmcls - INFO - Epoch [118][200/391]	lr: 1.000e-02, eta: 0:39:23, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0023
2022-11-21 01:23:18,703 - mmcls - INFO - Epoch [118][300/391]	lr: 1.000e-02, eta: 0:39:16, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2053
2022-11-21 01:23:28,596 - mmcls - INFO - Epoch(val) [118][79]	train_accuracy: 81.3960, accuracy_top-1: 78.0500, accuracy_top-5: 95.2300
2022-11-21 01:23:39,202 - mmcls - INFO - Epoch [119][100/391]	lr: 1.000e-02, eta: 0:39:00, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1098
2022-11-21 01:23:47,979 - mmcls - INFO - Epoch [119][200/391]	lr: 1.000e-02, eta: 0:38:54, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1985
2022-11-21 01:23:56,770 - mmcls - INFO - Epoch [119][300/391]	lr: 1.000e-02, eta: 0:38:47, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1465
2022-11-21 01:24:06,739 - mmcls - INFO - Epoch(val) [119][79]	train_accuracy: 79.7680, accuracy_top-1: 77.5300, accuracy_top-5: 94.9500
2022-11-21 01:24:17,585 - mmcls - INFO - Epoch [120][100/391]	lr: 1.000e-02, eta: 0:38:31, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.1544
2022-11-21 01:24:26,554 - mmcls - INFO - Epoch [120][200/391]	lr: 1.000e-02, eta: 0:38:25, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.0904
2022-11-21 01:24:35,390 - mmcls - INFO - Epoch [120][300/391]	lr: 1.000e-02, eta: 0:38:19, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1267
2022-11-21 01:24:43,513 - mmcls - INFO - Saving checkpoint at 120 epochs
2022-11-21 01:24:45,522 - mmcls - INFO - Epoch(val) [120][79]	train_accuracy: 80.1480, accuracy_top-1: 77.9700, accuracy_top-5: 95.1700
2022-11-21 01:24:56,314 - mmcls - INFO - Epoch [121][100/391]	lr: 1.000e-02, eta: 0:38:02, time: 0.108, data_time: 0.020, memory: 1669, loss: 0.9430
2022-11-21 01:25:05,182 - mmcls - INFO - Epoch [121][200/391]	lr: 1.000e-02, eta: 0:37:56, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3339
2022-11-21 01:25:14,082 - mmcls - INFO - Epoch [121][300/391]	lr: 1.000e-02, eta: 0:37:50, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9587
2022-11-21 01:25:24,041 - mmcls - INFO - Epoch(val) [121][79]	train_accuracy: 80.8560, accuracy_top-1: 78.4000, accuracy_top-5: 95.0800
2022-11-21 01:25:34,778 - mmcls - INFO - Epoch [122][100/391]	lr: 1.000e-02, eta: 0:37:34, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.2571
2022-11-21 01:25:43,583 - mmcls - INFO - Epoch [122][200/391]	lr: 1.000e-02, eta: 0:37:27, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1224
2022-11-21 01:25:52,361 - mmcls - INFO - Epoch [122][300/391]	lr: 1.000e-02, eta: 0:37:21, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1519
2022-11-21 01:26:02,306 - mmcls - INFO - Epoch(val) [122][79]	train_accuracy: 80.0220, accuracy_top-1: 78.3200, accuracy_top-5: 95.0300
2022-11-21 01:26:13,104 - mmcls - INFO - Epoch [123][100/391]	lr: 1.000e-02, eta: 0:37:05, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.1853
2022-11-21 01:26:22,026 - mmcls - INFO - Epoch [123][200/391]	lr: 1.000e-02, eta: 0:36:59, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1006
2022-11-21 01:26:30,948 - mmcls - INFO - Epoch [123][300/391]	lr: 1.000e-02, eta: 0:36:52, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0638
2022-11-21 01:26:40,986 - mmcls - INFO - Epoch(val) [123][79]	train_accuracy: 78.6560, accuracy_top-1: 77.7500, accuracy_top-5: 94.9700
2022-11-21 01:26:51,793 - mmcls - INFO - Epoch [124][100/391]	lr: 1.000e-02, eta: 0:36:36, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.1198
2022-11-21 01:27:00,772 - mmcls - INFO - Epoch [124][200/391]	lr: 1.000e-02, eta: 0:36:30, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.0665
2022-11-21 01:27:09,698 - mmcls - INFO - Epoch [124][300/391]	lr: 1.000e-02, eta: 0:36:24, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1714
2022-11-21 01:27:19,661 - mmcls - INFO - Epoch(val) [124][79]	train_accuracy: 79.6360, accuracy_top-1: 77.8500, accuracy_top-5: 95.0300
2022-11-21 01:27:30,371 - mmcls - INFO - Epoch [125][100/391]	lr: 1.000e-02, eta: 0:36:08, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0809
2022-11-21 01:27:39,151 - mmcls - INFO - Epoch [125][200/391]	lr: 1.000e-02, eta: 0:36:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3408
2022-11-21 01:27:47,947 - mmcls - INFO - Epoch [125][300/391]	lr: 1.000e-02, eta: 0:35:55, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9545
2022-11-21 01:27:57,791 - mmcls - INFO - Epoch(val) [125][79]	train_accuracy: 80.1220, accuracy_top-1: 77.9800, accuracy_top-5: 95.2200
2022-11-21 01:28:08,617 - mmcls - INFO - Epoch [126][100/391]	lr: 1.000e-02, eta: 0:35:39, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0717
2022-11-21 01:28:17,603 - mmcls - INFO - Epoch [126][200/391]	lr: 1.000e-02, eta: 0:35:33, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.0417
2022-11-21 01:28:26,409 - mmcls - INFO - Epoch [126][300/391]	lr: 1.000e-02, eta: 0:35:26, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0451
2022-11-21 01:28:36,379 - mmcls - INFO - Epoch(val) [126][79]	train_accuracy: 80.4400, accuracy_top-1: 77.7900, accuracy_top-5: 95.0700
2022-11-21 01:28:47,100 - mmcls - INFO - Epoch [127][100/391]	lr: 1.000e-02, eta: 0:35:10, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.2113
2022-11-21 01:28:55,868 - mmcls - INFO - Epoch [127][200/391]	lr: 1.000e-02, eta: 0:35:04, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1054
2022-11-21 01:29:04,711 - mmcls - INFO - Epoch [127][300/391]	lr: 1.000e-02, eta: 0:34:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0363
2022-11-21 01:29:14,648 - mmcls - INFO - Epoch(val) [127][79]	train_accuracy: 81.1160, accuracy_top-1: 78.1100, accuracy_top-5: 95.1600
2022-11-21 01:29:25,381 - mmcls - INFO - Epoch [128][100/391]	lr: 1.000e-02, eta: 0:34:41, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.8379
2022-11-21 01:29:34,192 - mmcls - INFO - Epoch [128][200/391]	lr: 1.000e-02, eta: 0:34:35, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8967
2022-11-21 01:29:42,904 - mmcls - INFO - Epoch [128][300/391]	lr: 1.000e-02, eta: 0:34:28, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.1390
2022-11-21 01:29:52,681 - mmcls - INFO - Epoch(val) [128][79]	train_accuracy: 82.7900, accuracy_top-1: 78.2700, accuracy_top-5: 95.1300
2022-11-21 01:30:03,268 - mmcls - INFO - Epoch [129][100/391]	lr: 1.000e-02, eta: 0:34:12, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0881
2022-11-21 01:30:12,189 - mmcls - INFO - Epoch [129][200/391]	lr: 1.000e-02, eta: 0:34:06, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9997
2022-11-21 01:30:21,100 - mmcls - INFO - Epoch [129][300/391]	lr: 1.000e-02, eta: 0:34:00, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1372
2022-11-21 01:30:30,999 - mmcls - INFO - Epoch(val) [129][79]	train_accuracy: 81.0920, accuracy_top-1: 77.6200, accuracy_top-5: 95.0100
2022-11-21 01:30:41,965 - mmcls - INFO - Epoch [130][100/391]	lr: 1.000e-02, eta: 0:33:44, time: 0.109, data_time: 0.021, memory: 1669, loss: 1.1085
2022-11-21 01:30:50,881 - mmcls - INFO - Epoch [130][200/391]	lr: 1.000e-02, eta: 0:33:37, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1053
2022-11-21 01:30:59,745 - mmcls - INFO - Epoch [130][300/391]	lr: 1.000e-02, eta: 0:33:31, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0816
2022-11-21 01:31:07,778 - mmcls - INFO - Saving checkpoint at 130 epochs
2022-11-21 01:31:09,774 - mmcls - INFO - Epoch(val) [130][79]	train_accuracy: 79.7000, accuracy_top-1: 78.6200, accuracy_top-5: 95.1200
2022-11-21 01:31:20,517 - mmcls - INFO - Epoch [131][100/391]	lr: 1.000e-02, eta: 0:33:15, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9349
2022-11-21 01:31:29,294 - mmcls - INFO - Epoch [131][200/391]	lr: 1.000e-02, eta: 0:33:09, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1010
2022-11-21 01:31:38,218 - mmcls - INFO - Epoch [131][300/391]	lr: 1.000e-02, eta: 0:33:02, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2476
2022-11-21 01:31:48,231 - mmcls - INFO - Epoch(val) [131][79]	train_accuracy: 80.6760, accuracy_top-1: 78.0100, accuracy_top-5: 94.9400
2022-11-21 01:31:58,831 - mmcls - INFO - Epoch [132][100/391]	lr: 1.000e-02, eta: 0:32:46, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.9638
2022-11-21 01:32:07,739 - mmcls - INFO - Epoch [132][200/391]	lr: 1.000e-02, eta: 0:32:40, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1439
2022-11-21 01:32:16,698 - mmcls - INFO - Epoch [132][300/391]	lr: 1.000e-02, eta: 0:32:33, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.0715
2022-11-21 01:32:26,704 - mmcls - INFO - Epoch(val) [132][79]	train_accuracy: 81.1580, accuracy_top-1: 77.5500, accuracy_top-5: 95.0200
2022-11-21 01:32:37,423 - mmcls - INFO - Epoch [133][100/391]	lr: 1.000e-02, eta: 0:32:18, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0242
2022-11-21 01:32:46,283 - mmcls - INFO - Epoch [133][200/391]	lr: 1.000e-02, eta: 0:32:11, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9271
2022-11-21 01:32:55,111 - mmcls - INFO - Epoch [133][300/391]	lr: 1.000e-02, eta: 0:32:05, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9894
2022-11-21 01:33:05,082 - mmcls - INFO - Epoch(val) [133][79]	train_accuracy: 81.9300, accuracy_top-1: 77.8200, accuracy_top-5: 94.7800
2022-11-21 01:33:15,953 - mmcls - INFO - Epoch [134][100/391]	lr: 1.000e-02, eta: 0:31:49, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9870
2022-11-21 01:33:24,829 - mmcls - INFO - Epoch [134][200/391]	lr: 1.000e-02, eta: 0:31:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9438
2022-11-21 01:33:33,689 - mmcls - INFO - Epoch [134][300/391]	lr: 1.000e-02, eta: 0:31:36, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0456
2022-11-21 01:33:43,634 - mmcls - INFO - Epoch(val) [134][79]	train_accuracy: 82.1060, accuracy_top-1: 77.6900, accuracy_top-5: 95.0000
2022-11-21 01:33:54,250 - mmcls - INFO - Epoch [135][100/391]	lr: 1.000e-02, eta: 0:31:20, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1787
2022-11-21 01:34:02,957 - mmcls - INFO - Epoch [135][200/391]	lr: 1.000e-02, eta: 0:31:14, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0503
2022-11-21 01:34:11,805 - mmcls - INFO - Epoch [135][300/391]	lr: 1.000e-02, eta: 0:31:07, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0067
2022-11-21 01:34:21,782 - mmcls - INFO - Epoch(val) [135][79]	train_accuracy: 80.3980, accuracy_top-1: 78.3300, accuracy_top-5: 95.2100
2022-11-21 01:34:32,398 - mmcls - INFO - Epoch [136][100/391]	lr: 1.000e-02, eta: 0:30:52, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.2612
2022-11-21 01:34:41,285 - mmcls - INFO - Epoch [136][200/391]	lr: 1.000e-02, eta: 0:30:45, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0255
2022-11-21 01:34:50,125 - mmcls - INFO - Epoch [136][300/391]	lr: 1.000e-02, eta: 0:30:38, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1347
2022-11-21 01:35:00,127 - mmcls - INFO - Epoch(val) [136][79]	train_accuracy: 79.4020, accuracy_top-1: 77.7400, accuracy_top-5: 95.4300
2022-11-21 01:35:10,861 - mmcls - INFO - Epoch [137][100/391]	lr: 1.000e-02, eta: 0:30:23, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.1114
2022-11-21 01:35:19,605 - mmcls - INFO - Epoch [137][200/391]	lr: 1.000e-02, eta: 0:30:16, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0090
2022-11-21 01:35:28,473 - mmcls - INFO - Epoch [137][300/391]	lr: 1.000e-02, eta: 0:30:10, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1184
2022-11-21 01:35:38,276 - mmcls - INFO - Epoch(val) [137][79]	train_accuracy: 81.1600, accuracy_top-1: 77.6300, accuracy_top-5: 95.0300
2022-11-21 01:35:48,923 - mmcls - INFO - Epoch [138][100/391]	lr: 1.000e-02, eta: 0:29:54, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.9726
2022-11-21 01:35:57,724 - mmcls - INFO - Epoch [138][200/391]	lr: 1.000e-02, eta: 0:29:47, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9865
2022-11-21 01:36:06,600 - mmcls - INFO - Epoch [138][300/391]	lr: 1.000e-02, eta: 0:29:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1061
2022-11-21 01:36:16,645 - mmcls - INFO - Epoch(val) [138][79]	train_accuracy: 82.2980, accuracy_top-1: 77.7200, accuracy_top-5: 95.0100
2022-11-21 01:36:27,498 - mmcls - INFO - Epoch [139][100/391]	lr: 1.000e-02, eta: 0:29:25, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.2887
2022-11-21 01:36:36,336 - mmcls - INFO - Epoch [139][200/391]	lr: 1.000e-02, eta: 0:29:19, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0722
2022-11-21 01:36:45,217 - mmcls - INFO - Epoch [139][300/391]	lr: 1.000e-02, eta: 0:29:12, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0615
2022-11-21 01:36:55,208 - mmcls - INFO - Epoch(val) [139][79]	train_accuracy: 80.8520, accuracy_top-1: 77.4700, accuracy_top-5: 95.2200
2022-11-21 01:37:05,985 - mmcls - INFO - Epoch [140][100/391]	lr: 1.000e-02, eta: 0:28:57, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0966
2022-11-21 01:37:14,885 - mmcls - INFO - Epoch [140][200/391]	lr: 1.000e-02, eta: 0:28:50, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1111
2022-11-21 01:37:23,773 - mmcls - INFO - Epoch [140][300/391]	lr: 1.000e-02, eta: 0:28:44, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0247
2022-11-21 01:37:31,798 - mmcls - INFO - Saving checkpoint at 140 epochs
2022-11-21 01:37:33,827 - mmcls - INFO - Epoch(val) [140][79]	train_accuracy: 80.9280, accuracy_top-1: 78.0200, accuracy_top-5: 95.1100
2022-11-21 01:37:44,453 - mmcls - INFO - Epoch [141][100/391]	lr: 1.000e-02, eta: 0:28:28, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.2240
2022-11-21 01:37:53,157 - mmcls - INFO - Epoch [141][200/391]	lr: 1.000e-02, eta: 0:28:21, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.8730
2022-11-21 01:38:01,885 - mmcls - INFO - Epoch [141][300/391]	lr: 1.000e-02, eta: 0:28:15, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2079
2022-11-21 01:38:11,872 - mmcls - INFO - Epoch(val) [141][79]	train_accuracy: 81.5180, accuracy_top-1: 78.2600, accuracy_top-5: 95.3400
2022-11-21 01:38:22,661 - mmcls - INFO - Epoch [142][100/391]	lr: 1.000e-02, eta: 0:27:59, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9913
2022-11-21 01:38:31,584 - mmcls - INFO - Epoch [142][200/391]	lr: 1.000e-02, eta: 0:27:53, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0682
2022-11-21 01:38:40,392 - mmcls - INFO - Epoch [142][300/391]	lr: 1.000e-02, eta: 0:27:46, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9691
2022-11-21 01:38:50,352 - mmcls - INFO - Epoch(val) [142][79]	train_accuracy: 82.0440, accuracy_top-1: 77.8300, accuracy_top-5: 94.9500
2022-11-21 01:39:01,166 - mmcls - INFO - Epoch [143][100/391]	lr: 1.000e-02, eta: 0:27:31, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.1119
2022-11-21 01:39:09,950 - mmcls - INFO - Epoch [143][200/391]	lr: 1.000e-02, eta: 0:27:24, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0523
2022-11-21 01:39:18,700 - mmcls - INFO - Epoch [143][300/391]	lr: 1.000e-02, eta: 0:27:17, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9965
2022-11-21 01:39:28,628 - mmcls - INFO - Epoch(val) [143][79]	train_accuracy: 81.2340, accuracy_top-1: 76.9500, accuracy_top-5: 94.7800
2022-11-21 01:39:39,263 - mmcls - INFO - Epoch [144][100/391]	lr: 1.000e-02, eta: 0:27:02, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0892
2022-11-21 01:39:48,069 - mmcls - INFO - Epoch [144][200/391]	lr: 1.000e-02, eta: 0:26:55, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0686
2022-11-21 01:39:56,726 - mmcls - INFO - Epoch [144][300/391]	lr: 1.000e-02, eta: 0:26:48, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0493
2022-11-21 01:40:06,675 - mmcls - INFO - Epoch(val) [144][79]	train_accuracy: 81.6100, accuracy_top-1: 77.8600, accuracy_top-5: 94.7900
2022-11-21 01:40:17,272 - mmcls - INFO - Epoch [145][100/391]	lr: 1.000e-02, eta: 0:26:33, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.9238
2022-11-21 01:40:26,060 - mmcls - INFO - Epoch [145][200/391]	lr: 1.000e-02, eta: 0:26:26, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2193
2022-11-21 01:40:34,931 - mmcls - INFO - Epoch [145][300/391]	lr: 1.000e-02, eta: 0:26:20, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9977
2022-11-21 01:40:44,892 - mmcls - INFO - Epoch(val) [145][79]	train_accuracy: 81.9100, accuracy_top-1: 77.7800, accuracy_top-5: 95.3100
2022-11-21 01:40:55,662 - mmcls - INFO - Epoch [146][100/391]	lr: 1.000e-02, eta: 0:26:04, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9782
2022-11-21 01:41:04,544 - mmcls - INFO - Epoch [146][200/391]	lr: 1.000e-02, eta: 0:25:58, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2003
2022-11-21 01:41:13,379 - mmcls - INFO - Epoch [146][300/391]	lr: 1.000e-02, eta: 0:25:51, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1764
2022-11-21 01:41:23,319 - mmcls - INFO - Epoch(val) [146][79]	train_accuracy: 81.4100, accuracy_top-1: 77.8000, accuracy_top-5: 95.0300
2022-11-21 01:41:34,087 - mmcls - INFO - Epoch [147][100/391]	lr: 1.000e-02, eta: 0:25:36, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9867
2022-11-21 01:41:42,966 - mmcls - INFO - Epoch [147][200/391]	lr: 1.000e-02, eta: 0:25:29, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1281
2022-11-21 01:41:51,778 - mmcls - INFO - Epoch [147][300/391]	lr: 1.000e-02, eta: 0:25:22, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0849
2022-11-21 01:42:01,689 - mmcls - INFO - Epoch(val) [147][79]	train_accuracy: 81.4420, accuracy_top-1: 77.5800, accuracy_top-5: 94.7200
2022-11-21 01:42:12,472 - mmcls - INFO - Epoch [148][100/391]	lr: 1.000e-02, eta: 0:25:07, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0078
2022-11-21 01:42:21,241 - mmcls - INFO - Epoch [148][200/391]	lr: 1.000e-02, eta: 0:25:00, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2276
2022-11-21 01:42:30,133 - mmcls - INFO - Epoch [148][300/391]	lr: 1.000e-02, eta: 0:24:54, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9376
2022-11-21 01:42:40,124 - mmcls - INFO - Epoch(val) [148][79]	train_accuracy: 81.6240, accuracy_top-1: 77.5900, accuracy_top-5: 94.9500
2022-11-21 01:42:50,933 - mmcls - INFO - Epoch [149][100/391]	lr: 1.000e-02, eta: 0:24:39, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.8582
2022-11-21 01:42:59,767 - mmcls - INFO - Epoch [149][200/391]	lr: 1.000e-02, eta: 0:24:32, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9738
2022-11-21 01:43:08,698 - mmcls - INFO - Epoch [149][300/391]	lr: 1.000e-02, eta: 0:24:25, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1150
2022-11-21 01:43:18,560 - mmcls - INFO - Epoch(val) [149][79]	train_accuracy: 83.6920, accuracy_top-1: 77.4200, accuracy_top-5: 94.9600
2022-11-21 01:43:29,210 - mmcls - INFO - Epoch [150][100/391]	lr: 1.000e-02, eta: 0:24:10, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.8113
2022-11-21 01:43:37,898 - mmcls - INFO - Epoch [150][200/391]	lr: 1.000e-02, eta: 0:24:03, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.1567
2022-11-21 01:43:46,560 - mmcls - INFO - Epoch [150][300/391]	lr: 1.000e-02, eta: 0:23:56, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9765
2022-11-21 01:43:54,534 - mmcls - INFO - Saving checkpoint at 150 epochs
2022-11-21 01:43:56,570 - mmcls - INFO - Epoch(val) [150][79]	train_accuracy: 82.7120, accuracy_top-1: 77.6300, accuracy_top-5: 94.8200
2022-11-21 01:44:07,349 - mmcls - INFO - Epoch [151][100/391]	lr: 1.000e-03, eta: 0:23:41, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9275
2022-11-21 01:44:16,287 - mmcls - INFO - Epoch [151][200/391]	lr: 1.000e-03, eta: 0:23:34, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.7986
2022-11-21 01:44:25,258 - mmcls - INFO - Epoch [151][300/391]	lr: 1.000e-03, eta: 0:23:28, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.0687
2022-11-21 01:44:35,144 - mmcls - INFO - Epoch(val) [151][79]	train_accuracy: 85.0140, accuracy_top-1: 79.1100, accuracy_top-5: 95.5300
2022-11-21 01:44:45,852 - mmcls - INFO - Epoch [152][100/391]	lr: 1.000e-03, eta: 0:23:13, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.1744
2022-11-21 01:44:54,693 - mmcls - INFO - Epoch [152][200/391]	lr: 1.000e-03, eta: 0:23:06, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0114
2022-11-21 01:45:03,518 - mmcls - INFO - Epoch [152][300/391]	lr: 1.000e-03, eta: 0:22:59, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1930
2022-11-21 01:45:13,542 - mmcls - INFO - Epoch(val) [152][79]	train_accuracy: 82.2180, accuracy_top-1: 79.1600, accuracy_top-5: 95.4300
2022-11-21 01:45:24,293 - mmcls - INFO - Epoch [153][100/391]	lr: 1.000e-03, eta: 0:22:44, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.7962
2022-11-21 01:45:33,079 - mmcls - INFO - Epoch [153][200/391]	lr: 1.000e-03, eta: 0:22:37, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1651
2022-11-21 01:45:41,859 - mmcls - INFO - Epoch [153][300/391]	lr: 1.000e-03, eta: 0:22:30, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0732
2022-11-21 01:45:51,731 - mmcls - INFO - Epoch(val) [153][79]	train_accuracy: 83.0360, accuracy_top-1: 79.1600, accuracy_top-5: 95.4800
2022-11-21 01:46:02,364 - mmcls - INFO - Epoch [154][100/391]	lr: 1.000e-03, eta: 0:22:15, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.7712
2022-11-21 01:46:11,204 - mmcls - INFO - Epoch [154][200/391]	lr: 1.000e-03, eta: 0:22:08, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0009
2022-11-21 01:46:20,041 - mmcls - INFO - Epoch [154][300/391]	lr: 1.000e-03, eta: 0:22:02, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7440
2022-11-21 01:46:29,970 - mmcls - INFO - Epoch(val) [154][79]	train_accuracy: 85.7500, accuracy_top-1: 79.3800, accuracy_top-5: 95.5000
2022-11-21 01:46:40,702 - mmcls - INFO - Epoch [155][100/391]	lr: 1.000e-03, eta: 0:21:47, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9287
2022-11-21 01:46:49,621 - mmcls - INFO - Epoch [155][200/391]	lr: 1.000e-03, eta: 0:21:40, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9389
2022-11-21 01:46:58,503 - mmcls - INFO - Epoch [155][300/391]	lr: 1.000e-03, eta: 0:21:33, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1081
2022-11-21 01:47:08,386 - mmcls - INFO - Epoch(val) [155][79]	train_accuracy: 83.6960, accuracy_top-1: 79.2300, accuracy_top-5: 95.4800
2022-11-21 01:47:19,114 - mmcls - INFO - Epoch [156][100/391]	lr: 1.000e-03, eta: 0:21:18, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0064
2022-11-21 01:47:27,843 - mmcls - INFO - Epoch [156][200/391]	lr: 1.000e-03, eta: 0:21:11, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9868
2022-11-21 01:47:36,590 - mmcls - INFO - Epoch [156][300/391]	lr: 1.000e-03, eta: 0:21:04, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0855
2022-11-21 01:47:46,477 - mmcls - INFO - Epoch(val) [156][79]	train_accuracy: 83.2180, accuracy_top-1: 79.3300, accuracy_top-5: 95.5100
2022-11-21 01:47:57,095 - mmcls - INFO - Epoch [157][100/391]	lr: 1.000e-03, eta: 0:20:49, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.2117
2022-11-21 01:48:06,019 - mmcls - INFO - Epoch [157][200/391]	lr: 1.000e-03, eta: 0:20:42, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0522
2022-11-21 01:48:14,887 - mmcls - INFO - Epoch [157][300/391]	lr: 1.000e-03, eta: 0:20:36, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8854
2022-11-21 01:48:24,874 - mmcls - INFO - Epoch(val) [157][79]	train_accuracy: 82.2740, accuracy_top-1: 79.2500, accuracy_top-5: 95.5300
2022-11-21 01:48:35,614 - mmcls - INFO - Epoch [158][100/391]	lr: 1.000e-03, eta: 0:20:21, time: 0.107, data_time: 0.020, memory: 1669, loss: 0.9890
2022-11-21 01:48:44,401 - mmcls - INFO - Epoch [158][200/391]	lr: 1.000e-03, eta: 0:20:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1132
2022-11-21 01:48:53,281 - mmcls - INFO - Epoch [158][300/391]	lr: 1.000e-03, eta: 0:20:07, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1706
2022-11-21 01:49:03,221 - mmcls - INFO - Epoch(val) [158][79]	train_accuracy: 82.6560, accuracy_top-1: 79.1700, accuracy_top-5: 95.5400
2022-11-21 01:49:14,072 - mmcls - INFO - Epoch [159][100/391]	lr: 1.000e-03, eta: 0:19:52, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0817
2022-11-21 01:49:22,900 - mmcls - INFO - Epoch [159][200/391]	lr: 1.000e-03, eta: 0:19:45, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8866
2022-11-21 01:49:31,843 - mmcls - INFO - Epoch [159][300/391]	lr: 1.000e-03, eta: 0:19:38, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9888
2022-11-21 01:49:41,752 - mmcls - INFO - Epoch(val) [159][79]	train_accuracy: 84.3620, accuracy_top-1: 79.1900, accuracy_top-5: 95.3400
2022-11-21 01:49:52,307 - mmcls - INFO - Epoch [160][100/391]	lr: 1.000e-03, eta: 0:19:23, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.1688
2022-11-21 01:50:00,957 - mmcls - INFO - Epoch [160][200/391]	lr: 1.000e-03, eta: 0:19:16, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9738
2022-11-21 01:50:09,813 - mmcls - INFO - Epoch [160][300/391]	lr: 1.000e-03, eta: 0:19:10, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9397
2022-11-21 01:50:17,772 - mmcls - INFO - Saving checkpoint at 160 epochs
2022-11-21 01:50:19,770 - mmcls - INFO - Epoch(val) [160][79]	train_accuracy: 83.3400, accuracy_top-1: 79.5200, accuracy_top-5: 95.4200
2022-11-21 01:50:30,541 - mmcls - INFO - Epoch [161][100/391]	lr: 1.000e-03, eta: 0:18:55, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.8539
2022-11-21 01:50:39,352 - mmcls - INFO - Epoch [161][200/391]	lr: 1.000e-03, eta: 0:18:48, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7947
2022-11-21 01:50:48,191 - mmcls - INFO - Epoch [161][300/391]	lr: 1.000e-03, eta: 0:18:41, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9136
2022-11-21 01:50:58,114 - mmcls - INFO - Epoch(val) [161][79]	train_accuracy: 86.2940, accuracy_top-1: 79.2600, accuracy_top-5: 95.3300
2022-11-21 01:51:08,893 - mmcls - INFO - Epoch [162][100/391]	lr: 1.000e-03, eta: 0:18:26, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0318
2022-11-21 01:51:17,655 - mmcls - INFO - Epoch [162][200/391]	lr: 1.000e-03, eta: 0:18:19, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0774
2022-11-21 01:51:26,433 - mmcls - INFO - Epoch [162][300/391]	lr: 1.000e-03, eta: 0:18:12, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0040
2022-11-21 01:51:36,226 - mmcls - INFO - Epoch(val) [162][79]	train_accuracy: 81.9980, accuracy_top-1: 79.2200, accuracy_top-5: 95.3700
2022-11-21 01:51:46,751 - mmcls - INFO - Epoch [163][100/391]	lr: 1.000e-03, eta: 0:17:58, time: 0.105, data_time: 0.021, memory: 1669, loss: 0.9022
2022-11-21 01:51:55,309 - mmcls - INFO - Epoch [163][200/391]	lr: 1.000e-03, eta: 0:17:50, time: 0.086, data_time: 0.001, memory: 1669, loss: 0.9163
2022-11-21 01:52:04,049 - mmcls - INFO - Epoch [163][300/391]	lr: 1.000e-03, eta: 0:17:44, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9330
2022-11-21 01:52:13,991 - mmcls - INFO - Epoch(val) [163][79]	train_accuracy: 84.0760, accuracy_top-1: 79.3800, accuracy_top-5: 95.5100
2022-11-21 01:52:24,829 - mmcls - INFO - Epoch [164][100/391]	lr: 1.000e-03, eta: 0:17:29, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9947
2022-11-21 01:52:33,669 - mmcls - INFO - Epoch [164][200/391]	lr: 1.000e-03, eta: 0:17:22, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0098
2022-11-21 01:52:42,428 - mmcls - INFO - Epoch [164][300/391]	lr: 1.000e-03, eta: 0:17:15, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0613
2022-11-21 01:52:52,309 - mmcls - INFO - Epoch(val) [164][79]	train_accuracy: 82.5800, accuracy_top-1: 79.1500, accuracy_top-5: 95.4200
2022-11-21 01:53:03,155 - mmcls - INFO - Epoch [165][100/391]	lr: 1.000e-03, eta: 0:17:00, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9149
2022-11-21 01:53:11,870 - mmcls - INFO - Epoch [165][200/391]	lr: 1.000e-03, eta: 0:16:53, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.8291
2022-11-21 01:53:20,767 - mmcls - INFO - Epoch [165][300/391]	lr: 1.000e-03, eta: 0:16:46, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0107
2022-11-21 01:53:30,629 - mmcls - INFO - Epoch(val) [165][79]	train_accuracy: 83.8300, accuracy_top-1: 79.1200, accuracy_top-5: 95.4600
2022-11-21 01:53:41,222 - mmcls - INFO - Epoch [166][100/391]	lr: 1.000e-03, eta: 0:16:32, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.9484
2022-11-21 01:53:49,871 - mmcls - INFO - Epoch [166][200/391]	lr: 1.000e-03, eta: 0:16:25, time: 0.086, data_time: 0.001, memory: 1669, loss: 0.9266
2022-11-21 01:53:58,528 - mmcls - INFO - Epoch [166][300/391]	lr: 1.000e-03, eta: 0:16:18, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9358
2022-11-21 01:54:08,438 - mmcls - INFO - Epoch(val) [166][79]	train_accuracy: 85.5400, accuracy_top-1: 79.1800, accuracy_top-5: 95.5300
2022-11-21 01:54:19,202 - mmcls - INFO - Epoch [167][100/391]	lr: 1.000e-03, eta: 0:16:03, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9642
2022-11-21 01:54:28,118 - mmcls - INFO - Epoch [167][200/391]	lr: 1.000e-03, eta: 0:15:56, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8079
2022-11-21 01:54:36,965 - mmcls - INFO - Epoch [167][300/391]	lr: 1.000e-03, eta: 0:15:49, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0441
2022-11-21 01:54:46,942 - mmcls - INFO - Epoch(val) [167][79]	train_accuracy: 84.2220, accuracy_top-1: 79.1500, accuracy_top-5: 95.5000
2022-11-21 01:54:57,711 - mmcls - INFO - Epoch [168][100/391]	lr: 1.000e-03, eta: 0:15:34, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0431
2022-11-21 01:55:06,556 - mmcls - INFO - Epoch [168][200/391]	lr: 1.000e-03, eta: 0:15:27, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7869
2022-11-21 01:55:15,417 - mmcls - INFO - Epoch [168][300/391]	lr: 1.000e-03, eta: 0:15:20, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8756
2022-11-21 01:55:25,322 - mmcls - INFO - Epoch(val) [168][79]	train_accuracy: 85.5980, accuracy_top-1: 79.2300, accuracy_top-5: 95.4500
2022-11-21 01:55:35,943 - mmcls - INFO - Epoch [169][100/391]	lr: 1.000e-03, eta: 0:15:06, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0807
2022-11-21 01:55:44,692 - mmcls - INFO - Epoch [169][200/391]	lr: 1.000e-03, eta: 0:14:59, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0738
2022-11-21 01:55:53,401 - mmcls - INFO - Epoch [169][300/391]	lr: 1.000e-03, eta: 0:14:52, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.8776
2022-11-21 01:56:03,204 - mmcls - INFO - Epoch(val) [169][79]	train_accuracy: 84.1660, accuracy_top-1: 79.2600, accuracy_top-5: 95.5200
2022-11-21 01:56:14,055 - mmcls - INFO - Epoch [170][100/391]	lr: 1.000e-03, eta: 0:14:37, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.8483
2022-11-21 01:56:22,979 - mmcls - INFO - Epoch [170][200/391]	lr: 1.000e-03, eta: 0:14:30, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0802
2022-11-21 01:56:31,869 - mmcls - INFO - Epoch [170][300/391]	lr: 1.000e-03, eta: 0:14:23, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8838
2022-11-21 01:56:39,769 - mmcls - INFO - Saving checkpoint at 170 epochs
2022-11-21 01:56:41,757 - mmcls - INFO - Epoch(val) [170][79]	train_accuracy: 84.0080, accuracy_top-1: 79.3500, accuracy_top-5: 95.3400
2022-11-21 01:56:52,416 - mmcls - INFO - Epoch [171][100/391]	lr: 1.000e-03, eta: 0:14:09, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.9567
2022-11-21 01:57:01,203 - mmcls - INFO - Epoch [171][200/391]	lr: 1.000e-03, eta: 0:14:02, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7667
2022-11-21 01:57:10,058 - mmcls - INFO - Epoch [171][300/391]	lr: 1.000e-03, eta: 0:13:55, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0895
2022-11-21 01:57:19,979 - mmcls - INFO - Epoch(val) [171][79]	train_accuracy: 85.0920, accuracy_top-1: 79.3200, accuracy_top-5: 95.5200
2022-11-21 01:57:30,630 - mmcls - INFO - Epoch [172][100/391]	lr: 1.000e-03, eta: 0:13:40, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0702
2022-11-21 01:57:39,522 - mmcls - INFO - Epoch [172][200/391]	lr: 1.000e-03, eta: 0:13:33, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9586
2022-11-21 01:57:48,342 - mmcls - INFO - Epoch [172][300/391]	lr: 1.000e-03, eta: 0:13:26, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9832
2022-11-21 01:57:58,302 - mmcls - INFO - Epoch(val) [172][79]	train_accuracy: 83.6780, accuracy_top-1: 79.3100, accuracy_top-5: 95.4500
2022-11-21 01:58:09,082 - mmcls - INFO - Epoch [173][100/391]	lr: 1.000e-03, eta: 0:13:11, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9629
2022-11-21 01:58:17,845 - mmcls - INFO - Epoch [173][200/391]	lr: 1.000e-03, eta: 0:13:04, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8861
2022-11-21 01:58:26,705 - mmcls - INFO - Epoch [173][300/391]	lr: 1.000e-03, eta: 0:12:57, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8737
2022-11-21 01:58:36,642 - mmcls - INFO - Epoch(val) [173][79]	train_accuracy: 85.3140, accuracy_top-1: 79.4300, accuracy_top-5: 95.3800
2022-11-21 01:58:47,461 - mmcls - INFO - Epoch [174][100/391]	lr: 1.000e-03, eta: 0:12:43, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9032
2022-11-21 01:58:56,309 - mmcls - INFO - Epoch [174][200/391]	lr: 1.000e-03, eta: 0:12:36, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9932
2022-11-21 01:59:05,096 - mmcls - INFO - Epoch [174][300/391]	lr: 1.000e-03, eta: 0:12:29, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8936
2022-11-21 01:59:15,008 - mmcls - INFO - Epoch(val) [174][79]	train_accuracy: 84.5540, accuracy_top-1: 79.1600, accuracy_top-5: 95.5000
2022-11-21 01:59:25,668 - mmcls - INFO - Epoch [175][100/391]	lr: 1.000e-03, eta: 0:12:14, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0660
2022-11-21 01:59:34,411 - mmcls - INFO - Epoch [175][200/391]	lr: 1.000e-03, eta: 0:12:07, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.7754
2022-11-21 01:59:43,184 - mmcls - INFO - Epoch [175][300/391]	lr: 1.000e-03, eta: 0:12:00, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0867
2022-11-21 01:59:53,045 - mmcls - INFO - Epoch(val) [175][79]	train_accuracy: 83.9040, accuracy_top-1: 79.1600, accuracy_top-5: 95.3700
2022-11-21 02:00:03,770 - mmcls - INFO - Epoch [176][100/391]	lr: 1.000e-03, eta: 0:11:46, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9655
2022-11-21 02:00:12,610 - mmcls - INFO - Epoch [176][200/391]	lr: 1.000e-03, eta: 0:11:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7667
2022-11-21 02:00:21,648 - mmcls - INFO - Epoch [176][300/391]	lr: 1.000e-03, eta: 0:11:32, time: 0.090, data_time: 0.001, memory: 1669, loss: 0.9672
2022-11-21 02:00:31,694 - mmcls - INFO - Epoch(val) [176][79]	train_accuracy: 85.5320, accuracy_top-1: 79.3200, accuracy_top-5: 95.3900
2022-11-21 02:00:42,334 - mmcls - INFO - Epoch [177][100/391]	lr: 1.000e-03, eta: 0:11:17, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.8812
2022-11-21 02:00:51,093 - mmcls - INFO - Epoch [177][200/391]	lr: 1.000e-03, eta: 0:11:10, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9382
2022-11-21 02:00:59,932 - mmcls - INFO - Epoch [177][300/391]	lr: 1.000e-03, eta: 0:11:03, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9068
2022-11-21 02:01:09,996 - mmcls - INFO - Epoch(val) [177][79]	train_accuracy: 85.1320, accuracy_top-1: 79.1300, accuracy_top-5: 95.3500
2022-11-21 02:01:20,789 - mmcls - INFO - Epoch [178][100/391]	lr: 1.000e-03, eta: 0:10:49, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0562
2022-11-21 02:01:29,578 - mmcls - INFO - Epoch [178][200/391]	lr: 1.000e-03, eta: 0:10:42, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9195
2022-11-21 02:01:38,323 - mmcls - INFO - Epoch [178][300/391]	lr: 1.000e-03, eta: 0:10:34, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0076
2022-11-21 02:01:48,271 - mmcls - INFO - Epoch(val) [178][79]	train_accuracy: 83.7060, accuracy_top-1: 79.1600, accuracy_top-5: 95.2800
2022-11-21 02:01:59,073 - mmcls - INFO - Epoch [179][100/391]	lr: 1.000e-03, eta: 0:10:20, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.8372
2022-11-21 02:02:07,986 - mmcls - INFO - Epoch [179][200/391]	lr: 1.000e-03, eta: 0:10:13, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0686
2022-11-21 02:02:16,874 - mmcls - INFO - Epoch [179][300/391]	lr: 1.000e-03, eta: 0:10:06, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0875
2022-11-21 02:02:26,832 - mmcls - INFO - Epoch(val) [179][79]	train_accuracy: 83.9100, accuracy_top-1: 79.3400, accuracy_top-5: 95.2700
2022-11-21 02:02:37,636 - mmcls - INFO - Epoch [180][100/391]	lr: 1.000e-03, eta: 0:09:52, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0889
2022-11-21 02:02:46,427 - mmcls - INFO - Epoch [180][200/391]	lr: 1.000e-03, eta: 0:09:44, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0225
2022-11-21 02:02:55,324 - mmcls - INFO - Epoch [180][300/391]	lr: 1.000e-03, eta: 0:09:37, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9213
2022-11-21 02:03:03,377 - mmcls - INFO - Saving checkpoint at 180 epochs
2022-11-21 02:03:05,385 - mmcls - INFO - Epoch(val) [180][79]	train_accuracy: 83.1340, accuracy_top-1: 79.3600, accuracy_top-5: 95.3200
2022-11-21 02:03:16,135 - mmcls - INFO - Epoch [181][100/391]	lr: 1.000e-04, eta: 0:09:23, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9648
2022-11-21 02:03:24,904 - mmcls - INFO - Epoch [181][200/391]	lr: 1.000e-04, eta: 0:09:16, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9614
2022-11-21 02:03:33,728 - mmcls - INFO - Epoch [181][300/391]	lr: 1.000e-04, eta: 0:09:09, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9098
2022-11-21 02:03:43,715 - mmcls - INFO - Epoch(val) [181][79]	train_accuracy: 83.6460, accuracy_top-1: 79.1700, accuracy_top-5: 95.3700
2022-11-21 02:03:54,293 - mmcls - INFO - Epoch [182][100/391]	lr: 1.000e-04, eta: 0:08:54, time: 0.105, data_time: 0.021, memory: 1669, loss: 0.7804
2022-11-21 02:04:03,072 - mmcls - INFO - Epoch [182][200/391]	lr: 1.000e-04, eta: 0:08:47, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0683
2022-11-21 02:04:12,021 - mmcls - INFO - Epoch [182][300/391]	lr: 1.000e-04, eta: 0:08:40, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9320
2022-11-21 02:04:21,973 - mmcls - INFO - Epoch(val) [182][79]	train_accuracy: 85.4100, accuracy_top-1: 79.3000, accuracy_top-5: 95.4600
2022-11-21 02:04:32,751 - mmcls - INFO - Epoch [183][100/391]	lr: 1.000e-04, eta: 0:08:26, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.8983
2022-11-21 02:04:41,559 - mmcls - INFO - Epoch [183][200/391]	lr: 1.000e-04, eta: 0:08:19, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0763
2022-11-21 02:04:50,333 - mmcls - INFO - Epoch [183][300/391]	lr: 1.000e-04, eta: 0:08:12, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1237
2022-11-21 02:05:00,343 - mmcls - INFO - Epoch(val) [183][79]	train_accuracy: 82.1420, accuracy_top-1: 79.1800, accuracy_top-5: 95.4200
2022-11-21 02:05:11,174 - mmcls - INFO - Epoch [184][100/391]	lr: 1.000e-04, eta: 0:07:57, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9738
2022-11-21 02:05:20,024 - mmcls - INFO - Epoch [184][200/391]	lr: 1.000e-04, eta: 0:07:50, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9440
2022-11-21 02:05:28,912 - mmcls - INFO - Epoch [184][300/391]	lr: 1.000e-04, eta: 0:07:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8904
2022-11-21 02:05:38,860 - mmcls - INFO - Epoch(val) [184][79]	train_accuracy: 85.7040, accuracy_top-1: 79.2900, accuracy_top-5: 95.4800
2022-11-21 02:05:49,445 - mmcls - INFO - Epoch [185][100/391]	lr: 1.000e-04, eta: 0:07:29, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1614
2022-11-21 02:05:58,247 - mmcls - INFO - Epoch [185][200/391]	lr: 1.000e-04, eta: 0:07:22, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0832
2022-11-21 02:06:07,111 - mmcls - INFO - Epoch [185][300/391]	lr: 1.000e-04, eta: 0:07:14, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8817
2022-11-21 02:06:17,073 - mmcls - INFO - Epoch(val) [185][79]	train_accuracy: 83.8540, accuracy_top-1: 79.4400, accuracy_top-5: 95.4700
2022-11-21 02:06:27,886 - mmcls - INFO - Epoch [186][100/391]	lr: 1.000e-04, eta: 0:07:00, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.8971
2022-11-21 02:06:36,691 - mmcls - INFO - Epoch [186][200/391]	lr: 1.000e-04, eta: 0:06:53, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8930
2022-11-21 02:06:45,619 - mmcls - INFO - Epoch [186][300/391]	lr: 1.000e-04, eta: 0:06:46, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0454
2022-11-21 02:06:55,652 - mmcls - INFO - Epoch(val) [186][79]	train_accuracy: 85.0840, accuracy_top-1: 79.2800, accuracy_top-5: 95.4800
2022-11-21 02:07:06,521 - mmcls - INFO - Epoch [187][100/391]	lr: 1.000e-04, eta: 0:06:32, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.0998
2022-11-21 02:07:15,247 - mmcls - INFO - Epoch [187][200/391]	lr: 1.000e-04, eta: 0:06:24, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9527
2022-11-21 02:07:24,026 - mmcls - INFO - Epoch [187][300/391]	lr: 1.000e-04, eta: 0:06:17, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8971
2022-11-21 02:07:33,828 - mmcls - INFO - Epoch(val) [187][79]	train_accuracy: 84.8460, accuracy_top-1: 79.3600, accuracy_top-5: 95.4200
2022-11-21 02:07:44,554 - mmcls - INFO - Epoch [188][100/391]	lr: 1.000e-04, eta: 0:06:03, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9658
2022-11-21 02:07:53,352 - mmcls - INFO - Epoch [188][200/391]	lr: 1.000e-04, eta: 0:05:56, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1356
2022-11-21 02:08:02,185 - mmcls - INFO - Epoch [188][300/391]	lr: 1.000e-04, eta: 0:05:49, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0037
2022-11-21 02:08:12,183 - mmcls - INFO - Epoch(val) [188][79]	train_accuracy: 83.8240, accuracy_top-1: 79.2800, accuracy_top-5: 95.3900
2022-11-21 02:08:23,011 - mmcls - INFO - Epoch [189][100/391]	lr: 1.000e-04, eta: 0:05:35, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9037
2022-11-21 02:08:31,883 - mmcls - INFO - Epoch [189][200/391]	lr: 1.000e-04, eta: 0:05:27, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9116
2022-11-21 02:08:40,594 - mmcls - INFO - Epoch [189][300/391]	lr: 1.000e-04, eta: 0:05:20, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.8559
2022-11-21 02:08:50,517 - mmcls - INFO - Epoch(val) [189][79]	train_accuracy: 86.6380, accuracy_top-1: 79.3200, accuracy_top-5: 95.4300
2022-11-21 02:09:01,184 - mmcls - INFO - Epoch [190][100/391]	lr: 1.000e-04, eta: 0:05:06, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0117
2022-11-21 02:09:10,044 - mmcls - INFO - Epoch [190][200/391]	lr: 1.000e-04, eta: 0:04:59, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0558
2022-11-21 02:09:18,875 - mmcls - INFO - Epoch [190][300/391]	lr: 1.000e-04, eta: 0:04:52, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0029
2022-11-21 02:09:26,896 - mmcls - INFO - Saving checkpoint at 190 epochs
2022-11-21 02:09:28,927 - mmcls - INFO - Epoch(val) [190][79]	train_accuracy: 85.1280, accuracy_top-1: 79.3200, accuracy_top-5: 95.4100
2022-11-21 02:09:39,688 - mmcls - INFO - Epoch [191][100/391]	lr: 1.000e-04, eta: 0:04:37, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0562
2022-11-21 02:09:49,272 - mmcls - INFO - Epoch [191][200/391]	lr: 1.000e-04, eta: 0:04:30, time: 0.096, data_time: 0.001, memory: 1669, loss: 1.0344
2022-11-21 02:09:58,813 - mmcls - INFO - Epoch [191][300/391]	lr: 1.000e-04, eta: 0:04:23, time: 0.095, data_time: 0.001, memory: 1669, loss: 1.1927
2022-11-21 02:10:08,889 - mmcls - INFO - Epoch(val) [191][79]	train_accuracy: 83.3940, accuracy_top-1: 79.2400, accuracy_top-5: 95.4100
2022-11-21 02:10:19,598 - mmcls - INFO - Epoch [192][100/391]	lr: 1.000e-04, eta: 0:04:09, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9745
2022-11-21 02:10:28,532 - mmcls - INFO - Epoch [192][200/391]	lr: 1.000e-04, eta: 0:04:02, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9180
2022-11-21 02:10:37,343 - mmcls - INFO - Epoch [192][300/391]	lr: 1.000e-04, eta: 0:03:55, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8299
2022-11-21 02:10:47,395 - mmcls - INFO - Epoch(val) [192][79]	train_accuracy: 84.3620, accuracy_top-1: 79.3500, accuracy_top-5: 95.4100
2022-11-21 02:10:58,463 - mmcls - INFO - Epoch [193][100/391]	lr: 1.000e-04, eta: 0:03:40, time: 0.110, data_time: 0.021, memory: 1669, loss: 0.9484
2022-11-21 02:11:07,651 - mmcls - INFO - Epoch [193][200/391]	lr: 1.000e-04, eta: 0:03:33, time: 0.092, data_time: 0.001, memory: 1669, loss: 0.9670
2022-11-21 02:11:16,599 - mmcls - INFO - Epoch [193][300/391]	lr: 1.000e-04, eta: 0:03:26, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8268
2022-11-21 02:11:26,619 - mmcls - INFO - Epoch(val) [193][79]	train_accuracy: 85.2060, accuracy_top-1: 79.2900, accuracy_top-5: 95.4000
2022-11-21 02:11:37,364 - mmcls - INFO - Epoch [194][100/391]	lr: 1.000e-04, eta: 0:03:12, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9315
2022-11-21 02:11:46,263 - mmcls - INFO - Epoch [194][200/391]	lr: 1.000e-04, eta: 0:03:05, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9538
2022-11-21 02:11:55,196 - mmcls - INFO - Epoch [194][300/391]	lr: 1.000e-04, eta: 0:02:57, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8125
2022-11-21 02:12:05,155 - mmcls - INFO - Epoch(val) [194][79]	train_accuracy: 87.0880, accuracy_top-1: 79.4300, accuracy_top-5: 95.4200
2022-11-21 02:12:16,113 - mmcls - INFO - Epoch [195][100/391]	lr: 1.000e-04, eta: 0:02:43, time: 0.109, data_time: 0.021, memory: 1669, loss: 0.8062
2022-11-21 02:12:24,971 - mmcls - INFO - Epoch [195][200/391]	lr: 1.000e-04, eta: 0:02:36, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9791
2022-11-21 02:12:33,843 - mmcls - INFO - Epoch [195][300/391]	lr: 1.000e-04, eta: 0:02:29, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.7764
2022-11-21 02:12:43,873 - mmcls - INFO - Epoch(val) [195][79]	train_accuracy: 85.6760, accuracy_top-1: 79.3500, accuracy_top-5: 95.4000
2022-11-21 02:12:54,625 - mmcls - INFO - Epoch [196][100/391]	lr: 1.000e-04, eta: 0:02:15, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9636
2022-11-21 02:13:03,624 - mmcls - INFO - Epoch [196][200/391]	lr: 1.000e-04, eta: 0:02:08, time: 0.090, data_time: 0.001, memory: 1669, loss: 0.9557
2022-11-21 02:13:12,566 - mmcls - INFO - Epoch [196][300/391]	lr: 1.000e-04, eta: 0:02:00, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9850
2022-11-21 02:13:22,628 - mmcls - INFO - Epoch(val) [196][79]	train_accuracy: 84.1100, accuracy_top-1: 79.3600, accuracy_top-5: 95.4200
2022-11-21 02:13:33,335 - mmcls - INFO - Epoch [197][100/391]	lr: 1.000e-04, eta: 0:01:46, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0266
2022-11-21 02:13:42,223 - mmcls - INFO - Epoch [197][200/391]	lr: 1.000e-04, eta: 0:01:39, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0093
2022-11-21 02:13:51,229 - mmcls - INFO - Epoch [197][300/391]	lr: 1.000e-04, eta: 0:01:32, time: 0.090, data_time: 0.001, memory: 1669, loss: 0.7959
2022-11-21 02:14:01,143 - mmcls - INFO - Epoch(val) [197][79]	train_accuracy: 85.2120, accuracy_top-1: 79.3800, accuracy_top-5: 95.3900
2022-11-21 02:14:12,005 - mmcls - INFO - Epoch [198][100/391]	lr: 1.000e-04, eta: 0:01:18, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9736
2022-11-21 02:14:20,865 - mmcls - INFO - Epoch [198][200/391]	lr: 1.000e-04, eta: 0:01:11, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0456
2022-11-21 02:14:29,754 - mmcls - INFO - Epoch [198][300/391]	lr: 1.000e-04, eta: 0:01:03, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9794
2022-11-21 02:14:39,754 - mmcls - INFO - Epoch(val) [198][79]	train_accuracy: 84.1180, accuracy_top-1: 79.3800, accuracy_top-5: 95.3600
2022-11-21 02:14:50,598 - mmcls - INFO - Epoch [199][100/391]	lr: 1.000e-04, eta: 0:00:49, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.8407
2022-11-21 02:14:59,540 - mmcls - INFO - Epoch [199][200/391]	lr: 1.000e-04, eta: 0:00:42, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8800
2022-11-21 02:15:08,431 - mmcls - INFO - Epoch [199][300/391]	lr: 1.000e-04, eta: 0:00:35, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0259
2022-11-21 02:15:18,379 - mmcls - INFO - Epoch(val) [199][79]	train_accuracy: 85.5080, accuracy_top-1: 79.4200, accuracy_top-5: 95.4000
2022-11-21 02:15:28,991 - mmcls - INFO - Epoch [200][100/391]	lr: 1.000e-04, eta: 0:00:21, time: 0.106, data_time: 0.020, memory: 1669, loss: 0.8864
2022-11-21 02:15:37,876 - mmcls - INFO - Epoch [200][200/391]	lr: 1.000e-04, eta: 0:00:13, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8180
2022-11-21 02:15:46,789 - mmcls - INFO - Epoch [200][300/391]	lr: 1.000e-04, eta: 0:00:06, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0125
2022-11-21 02:15:54,869 - mmcls - INFO - Saving checkpoint at 200 epochs
2022-11-21 02:15:56,860 - mmcls - INFO - Epoch(val) [200][79]	train_accuracy: 85.4300, accuracy_top-1: 79.4500, accuracy_top-5: 95.3700
