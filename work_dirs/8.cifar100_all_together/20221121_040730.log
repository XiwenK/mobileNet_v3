2022-11-21 04:07:30,306 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Oct 21 2022, 23:50:54) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3070 Ti Laptop GPU
CUDA_HOME: /usr/local/cuda-11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.105
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.13.0
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.0
OpenCV: 4.6.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.7
MMClassification: 0.24.1+4e5bf17
------------------------------------------------------------

2022-11-21 04:07:30,306 - mmcls - INFO - Distributed training: False
2022-11-21 04:07:30,356 - mmcls - INFO - Config:
model = dict(
    type='BSConvClassifier',
    backbone=dict(
        type='MobileNetV3Cifar', arch='large', conv_cfg=dict(type='BSConvS')),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='StackedLinearClsHeadWithPred',
        num_classes=100,
        in_channels=960,
        mid_channels=[1280],
        act_cfg=dict(type='HSwish'),
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),
        topk=(1, 5)),
    train_cfg=dict(augments=[
        dict(type='BatchCutMix', alpha=1.0, prob=0.5, num_classes=100)
    ]))
dataset_type = 'CIFAR100'
img_norm_cfg = dict(
    mean=[129.304, 124.07, 112.434], std=[68.17, 65.392, 70.418], to_rgb=False)
train_pipeline = [
    dict(type='RandomCrop', size=32, padding=4),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(
        type='Normalize',
        mean=[129.304, 124.07, 112.434],
        std=[68.17, 65.392, 70.418],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(
        type='Normalize',
        mean=[129.304, 124.07, 112.434],
        std=[68.17, 65.392, 70.418],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=128,
    workers_per_gpu=2,
    train=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(type='RandomCrop', size=32, padding=4),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True),
    test=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True))
optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='poly',
    power=0.7,
    min_lr=0.0001,
    by_epoch=False,
    warmup='exp',
    warmup_ratio=0.1,
    warmup_iters=5,
    warmup_by_epoch=True)
runner = dict(type='EpochBasedRunner', max_epochs=200)
checkpoint_config = dict(interval=10, max_keep_ckpts=1)
log_config = dict(
    interval=100,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
work_dir = './work_dirs/8.cifar100_all_together'
gpu_ids = [0]

2022-11-21 04:07:30,357 - mmcls - INFO - Set random seed to 1410699102, deterministic: False
2022-11-21 04:07:30,412 - mmcls - INFO - initialize MobileNetV3Cifar with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d'], 'nonlinearity': 'leaky_relu'}, {'type': 'Normal', 'layer': ['Linear'], 'std': 0.01}, {'type': 'Constant', 'layer': ['BatchNorm2d'], 'val': 1}]
Name of parameter - Initialization information

backbone.layer0.conv.weight - torch.Size([16, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.depthwise_conv.conv.weight - torch.Size([16, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.depthwise_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.depthwise_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.linear_conv.conv.pw1.weight - torch.Size([4, 16, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.conv.pw2.weight - torch.Size([16, 4, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.conv.dw.weight - torch.Size([16, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer1.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer1.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.expand_conv.conv.weight - torch.Size([64, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.expand_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.expand_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.depthwise_conv.conv.weight - torch.Size([64, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.depthwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.depthwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.linear_conv.conv.pw1.weight - torch.Size([16, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.conv.pw2.weight - torch.Size([24, 16, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.conv.dw.weight - torch.Size([24, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer2.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer2.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.expand_conv.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.depthwise_conv.conv.weight - torch.Size([72, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.linear_conv.conv.pw1.weight - torch.Size([18, 72, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.conv.pw2.weight - torch.Size([24, 18, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.conv.dw.weight - torch.Size([24, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer3.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer3.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.expand_conv.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.depthwise_conv.conv.weight - torch.Size([72, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.se.conv1.conv.weight - torch.Size([24, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv1.conv.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.se.conv2.conv.weight - torch.Size([72, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv2.conv.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.linear_conv.conv.pw1.weight - torch.Size([18, 72, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.conv.pw2.weight - torch.Size([40, 18, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer4.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer4.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.linear_conv.conv.pw1.weight - torch.Size([30, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.conv.pw2.weight - torch.Size([40, 30, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer5.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer5.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.linear_conv.conv.pw1.weight - torch.Size([30, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.conv.pw2.weight - torch.Size([40, 30, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.conv.dw.weight - torch.Size([40, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer6.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer6.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.depthwise_conv.conv.weight - torch.Size([240, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.linear_conv.conv.pw1.weight - torch.Size([60, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.conv.pw2.weight - torch.Size([80, 60, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer7.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer7.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.expand_conv.conv.weight - torch.Size([200, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.expand_conv.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.expand_conv.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.depthwise_conv.conv.weight - torch.Size([200, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.depthwise_conv.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.depthwise_conv.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.linear_conv.conv.pw1.weight - torch.Size([50, 200, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.conv.pw2.weight - torch.Size([80, 50, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer8.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer8.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.expand_conv.conv.weight - torch.Size([184, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.expand_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.expand_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.depthwise_conv.conv.weight - torch.Size([184, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.depthwise_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.depthwise_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.linear_conv.conv.pw1.weight - torch.Size([46, 184, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.conv.pw2.weight - torch.Size([80, 46, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer9.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer9.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.expand_conv.conv.weight - torch.Size([184, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.expand_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.expand_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.depthwise_conv.conv.weight - torch.Size([184, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.depthwise_conv.bn.weight - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.depthwise_conv.bn.bias - torch.Size([184]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.linear_conv.conv.pw1.weight - torch.Size([46, 184, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.conv.pw2.weight - torch.Size([80, 46, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.conv.dw.weight - torch.Size([80, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer10.linear_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer10.linear_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.expand_conv.conv.weight - torch.Size([480, 80, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.expand_conv.bn.weight - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.expand_conv.bn.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.depthwise_conv.conv.weight - torch.Size([480, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.depthwise_conv.bn.weight - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.depthwise_conv.bn.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.se.conv1.conv.weight - torch.Size([120, 480, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv1.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.se.conv2.conv.weight - torch.Size([480, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv2.conv.bias - torch.Size([480]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.linear_conv.conv.pw1.weight - torch.Size([120, 480, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.conv.pw2.weight - torch.Size([112, 120, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.conv.dw.weight - torch.Size([112, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer11.linear_conv.bn.weight - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer11.linear_conv.bn.bias - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.expand_conv.conv.weight - torch.Size([672, 112, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.expand_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.expand_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.depthwise_conv.conv.weight - torch.Size([672, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.depthwise_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.depthwise_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.se.conv1.conv.weight - torch.Size([168, 672, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.se.conv1.conv.bias - torch.Size([168]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.se.conv2.conv.weight - torch.Size([672, 168, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.se.conv2.conv.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.linear_conv.conv.pw1.weight - torch.Size([168, 672, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.conv.pw2.weight - torch.Size([112, 168, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.conv.dw.weight - torch.Size([112, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer12.linear_conv.bn.weight - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer12.linear_conv.bn.bias - torch.Size([112]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.expand_conv.conv.weight - torch.Size([672, 112, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.expand_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.expand_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.depthwise_conv.conv.weight - torch.Size([672, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.depthwise_conv.bn.weight - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.depthwise_conv.bn.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.se.conv1.conv.weight - torch.Size([168, 672, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.se.conv1.conv.bias - torch.Size([168]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.se.conv2.conv.weight - torch.Size([672, 168, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer13.se.conv2.conv.bias - torch.Size([672]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.linear_conv.conv.pw1.weight - torch.Size([168, 672, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.conv.pw2.weight - torch.Size([160, 168, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer13.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer13.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.expand_conv.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.expand_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.expand_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.depthwise_conv.conv.weight - torch.Size([960, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.depthwise_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.depthwise_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.se.conv1.conv.weight - torch.Size([240, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.se.conv1.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.se.conv2.conv.weight - torch.Size([960, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer14.se.conv2.conv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.linear_conv.conv.pw1.weight - torch.Size([240, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.conv.pw2.weight - torch.Size([160, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer14.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer14.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.expand_conv.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.expand_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.expand_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.depthwise_conv.conv.weight - torch.Size([960, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.depthwise_conv.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.depthwise_conv.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.se.conv1.conv.weight - torch.Size([240, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.se.conv1.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.se.conv2.conv.weight - torch.Size([960, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer15.se.conv2.conv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.linear_conv.conv.pw1.weight - torch.Size([240, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.conv.pw2.weight - torch.Size([160, 240, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.conv.dw.weight - torch.Size([160, 1, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=leaky_relu, distribution =normal, bias=0 

backbone.layer15.linear_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer15.linear_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer16.conv.weight - torch.Size([960, 160, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer16.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

backbone.layer16.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.0.fc.weight - torch.Size([1280, 960]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.0.fc.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.1.fc.weight - torch.Size([100, 1280]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  

head.layers.1.fc.bias - torch.Size([100]): 
The value is the same before and after calling `init_weights` of BSConvClassifier  
2022-11-21 04:07:32,566 - mmcls - INFO - Start running, host: aoyuli@LAY-LAPTOP, work_dir: /home/aoyuli/Project/mmdl/work_dirs/8.cifar100_all_together
2022-11-21 04:07:32,567 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) TrainsetEvalHook                   
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) TrainsetEvalHook                   
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2022-11-21 04:07:32,567 - mmcls - INFO - workflow: [('train', 1)], max: 200 epochs
2022-11-21 04:07:32,567 - mmcls - INFO - Checkpoints will be saved to /home/aoyuli/Project/mmdl/work_dirs/8.cifar100_all_together by HardDiskBackend.
2022-11-21 04:07:44,588 - mmcls - INFO - Epoch [1][100/391]	lr: 1.123e-02, eta: 2:35:42, time: 0.120, data_time: 0.022, memory: 1669, loss: 4.5559
2022-11-21 04:07:53,075 - mmcls - INFO - Epoch [1][200/391]	lr: 1.262e-02, eta: 2:12:53, time: 0.085, data_time: 0.001, memory: 1669, loss: 4.4021
2022-11-21 04:08:01,588 - mmcls - INFO - Epoch [1][300/391]	lr: 1.418e-02, eta: 2:05:19, time: 0.085, data_time: 0.001, memory: 1669, loss: 4.2088
2022-11-21 04:08:11,460 - mmcls - INFO - Epoch(val) [1][79]	train_accuracy: 4.5620, accuracy_top-1: 1.0000, accuracy_top-5: 5.0000
2022-11-21 04:08:22,214 - mmcls - INFO - Epoch [2][100/391]	lr: 1.773e-02, eta: 1:44:40, time: 0.107, data_time: 0.021, memory: 1669, loss: 3.9934
2022-11-21 04:08:31,048 - mmcls - INFO - Epoch [2][200/391]	lr: 1.993e-02, eta: 1:46:11, time: 0.088, data_time: 0.001, memory: 1669, loss: 3.9245
2022-11-21 04:08:39,839 - mmcls - INFO - Epoch [2][300/391]	lr: 2.240e-02, eta: 1:47:08, time: 0.088, data_time: 0.001, memory: 1669, loss: 3.8243
2022-11-21 04:08:49,667 - mmcls - INFO - Epoch(val) [2][79]	train_accuracy: 11.1300, accuracy_top-1: 7.8800, accuracy_top-5: 27.0500
2022-11-21 04:09:00,290 - mmcls - INFO - Epoch [3][100/391]	lr: 2.800e-02, eta: 1:39:12, time: 0.106, data_time: 0.021, memory: 1669, loss: 3.6696
2022-11-21 04:09:09,148 - mmcls - INFO - Epoch [3][200/391]	lr: 3.147e-02, eta: 1:40:35, time: 0.089, data_time: 0.001, memory: 1669, loss: 3.6210
2022-11-21 04:09:17,990 - mmcls - INFO - Epoch [3][300/391]	lr: 3.538e-02, eta: 1:41:41, time: 0.088, data_time: 0.001, memory: 1669, loss: 3.4806
2022-11-21 04:09:27,861 - mmcls - INFO - Epoch(val) [3][79]	train_accuracy: 17.5520, accuracy_top-1: 9.0400, accuracy_top-5: 27.8900
2022-11-21 04:09:38,517 - mmcls - INFO - Epoch [4][100/391]	lr: 4.422e-02, eta: 1:36:55, time: 0.106, data_time: 0.021, memory: 1669, loss: 3.4039
2022-11-21 04:09:47,347 - mmcls - INFO - Epoch [4][200/391]	lr: 4.971e-02, eta: 1:37:58, time: 0.088, data_time: 0.001, memory: 1669, loss: 3.2158
2022-11-21 04:09:56,219 - mmcls - INFO - Epoch [4][300/391]	lr: 5.587e-02, eta: 1:38:54, time: 0.089, data_time: 0.001, memory: 1669, loss: 3.1543
2022-11-21 04:10:06,162 - mmcls - INFO - Epoch(val) [4][79]	train_accuracy: 23.6260, accuracy_top-1: 15.5100, accuracy_top-5: 41.0900
2022-11-21 04:10:16,841 - mmcls - INFO - Epoch [5][100/391]	lr: 6.984e-02, eta: 1:35:30, time: 0.107, data_time: 0.021, memory: 1669, loss: 3.1697
2022-11-21 04:10:25,762 - mmcls - INFO - Epoch [5][200/391]	lr: 7.850e-02, eta: 1:36:24, time: 0.089, data_time: 0.001, memory: 1669, loss: 3.1694
2022-11-21 04:10:34,501 - mmcls - INFO - Epoch [5][300/391]	lr: 8.823e-02, eta: 1:37:05, time: 0.087, data_time: 0.001, memory: 1669, loss: 2.9517
2022-11-21 04:10:44,408 - mmcls - INFO - Epoch(val) [5][79]	train_accuracy: 26.7900, accuracy_top-1: 13.3700, accuracy_top-5: 35.7300
2022-11-21 04:10:55,140 - mmcls - INFO - Epoch [6][100/391]	lr: 9.816e-02, eta: 1:34:27, time: 0.107, data_time: 0.021, memory: 1669, loss: 3.0262
2022-11-21 04:11:03,940 - mmcls - INFO - Epoch [6][200/391]	lr: 9.807e-02, eta: 1:35:07, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.9366
2022-11-21 04:11:12,654 - mmcls - INFO - Epoch [6][300/391]	lr: 9.798e-02, eta: 1:35:40, time: 0.087, data_time: 0.001, memory: 1669, loss: 2.9184
2022-11-21 04:11:22,455 - mmcls - INFO - Epoch(val) [6][79]	train_accuracy: 30.5680, accuracy_top-1: 32.5500, accuracy_top-5: 64.9500
2022-11-21 04:11:33,053 - mmcls - INFO - Epoch [7][100/391]	lr: 9.780e-02, eta: 1:33:26, time: 0.106, data_time: 0.021, memory: 1669, loss: 2.7443
2022-11-21 04:11:41,690 - mmcls - INFO - Epoch [7][200/391]	lr: 9.771e-02, eta: 1:33:55, time: 0.086, data_time: 0.001, memory: 1669, loss: 2.8061
2022-11-21 04:11:50,374 - mmcls - INFO - Epoch [7][300/391]	lr: 9.762e-02, eta: 1:34:23, time: 0.087, data_time: 0.001, memory: 1669, loss: 2.7099
2022-11-21 04:12:00,179 - mmcls - INFO - Epoch(val) [7][79]	train_accuracy: 35.2500, accuracy_top-1: 37.1700, accuracy_top-5: 68.9800
2022-11-21 04:12:10,995 - mmcls - INFO - Epoch [8][100/391]	lr: 9.745e-02, eta: 1:32:35, time: 0.108, data_time: 0.021, memory: 1669, loss: 2.5454
2022-11-21 04:12:19,915 - mmcls - INFO - Epoch [8][200/391]	lr: 9.736e-02, eta: 1:33:07, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.6143
2022-11-21 04:12:28,902 - mmcls - INFO - Epoch [8][300/391]	lr: 9.727e-02, eta: 1:33:38, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.6207
2022-11-21 04:12:38,755 - mmcls - INFO - Epoch(val) [8][79]	train_accuracy: 38.5480, accuracy_top-1: 41.1000, accuracy_top-5: 71.4600
2022-11-21 04:12:49,421 - mmcls - INFO - Epoch [9][100/391]	lr: 9.710e-02, eta: 1:31:59, time: 0.106, data_time: 0.021, memory: 1669, loss: 2.6172
2022-11-21 04:12:58,155 - mmcls - INFO - Epoch [9][200/391]	lr: 9.701e-02, eta: 1:32:23, time: 0.087, data_time: 0.001, memory: 1669, loss: 2.4774
2022-11-21 04:13:07,029 - mmcls - INFO - Epoch [9][300/391]	lr: 9.691e-02, eta: 1:32:48, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.5634
2022-11-21 04:13:16,980 - mmcls - INFO - Epoch(val) [9][79]	train_accuracy: 40.3240, accuracy_top-1: 40.2300, accuracy_top-5: 71.2000
2022-11-21 04:13:27,709 - mmcls - INFO - Epoch [10][100/391]	lr: 9.674e-02, eta: 1:31:21, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.4418
2022-11-21 04:13:36,519 - mmcls - INFO - Epoch [10][200/391]	lr: 9.665e-02, eta: 1:31:43, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.3394
2022-11-21 04:13:45,439 - mmcls - INFO - Epoch [10][300/391]	lr: 9.656e-02, eta: 1:32:05, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.5429
2022-11-21 04:13:53,444 - mmcls - INFO - Saving checkpoint at 10 epochs
2022-11-21 04:13:55,434 - mmcls - INFO - Epoch(val) [10][79]	train_accuracy: 42.7400, accuracy_top-1: 46.8100, accuracy_top-5: 78.0500
2022-11-21 04:14:06,087 - mmcls - INFO - Epoch [11][100/391]	lr: 9.639e-02, eta: 1:30:45, time: 0.106, data_time: 0.021, memory: 1669, loss: 2.3310
2022-11-21 04:14:14,993 - mmcls - INFO - Epoch [11][200/391]	lr: 9.630e-02, eta: 1:31:06, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.4661
2022-11-21 04:14:23,862 - mmcls - INFO - Epoch [11][300/391]	lr: 9.621e-02, eta: 1:31:24, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.4558
2022-11-21 04:14:33,882 - mmcls - INFO - Epoch(val) [11][79]	train_accuracy: 43.3640, accuracy_top-1: 45.6400, accuracy_top-5: 76.4100
2022-11-21 04:14:44,616 - mmcls - INFO - Epoch [12][100/391]	lr: 9.603e-02, eta: 1:30:12, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.2823
2022-11-21 04:14:53,412 - mmcls - INFO - Epoch [12][200/391]	lr: 9.594e-02, eta: 1:30:29, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.3407
2022-11-21 04:15:02,206 - mmcls - INFO - Epoch [12][300/391]	lr: 9.585e-02, eta: 1:30:44, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.2750
2022-11-21 04:15:12,065 - mmcls - INFO - Epoch(val) [12][79]	train_accuracy: 45.4880, accuracy_top-1: 45.1500, accuracy_top-5: 77.4800
2022-11-21 04:15:22,716 - mmcls - INFO - Epoch [13][100/391]	lr: 9.568e-02, eta: 1:29:37, time: 0.106, data_time: 0.021, memory: 1669, loss: 2.2275
2022-11-21 04:15:31,348 - mmcls - INFO - Epoch [13][200/391]	lr: 9.558e-02, eta: 1:29:49, time: 0.086, data_time: 0.001, memory: 1669, loss: 2.3854
2022-11-21 04:15:40,115 - mmcls - INFO - Epoch [13][300/391]	lr: 9.549e-02, eta: 1:30:02, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.2242
2022-11-21 04:15:49,840 - mmcls - INFO - Epoch(val) [13][79]	train_accuracy: 46.7780, accuracy_top-1: 45.0800, accuracy_top-5: 75.3700
2022-11-21 04:16:00,446 - mmcls - INFO - Epoch [14][100/391]	lr: 9.532e-02, eta: 1:28:59, time: 0.106, data_time: 0.021, memory: 1669, loss: 2.2616
2022-11-21 04:16:09,331 - mmcls - INFO - Epoch [14][200/391]	lr: 9.523e-02, eta: 1:29:13, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.3303
2022-11-21 04:16:18,283 - mmcls - INFO - Epoch [14][300/391]	lr: 9.514e-02, eta: 1:29:27, time: 0.090, data_time: 0.001, memory: 1669, loss: 2.4403
2022-11-21 04:16:28,237 - mmcls - INFO - Epoch(val) [14][79]	train_accuracy: 46.2560, accuracy_top-1: 48.0000, accuracy_top-5: 79.2600
2022-11-21 04:16:38,923 - mmcls - INFO - Epoch [15][100/391]	lr: 9.496e-02, eta: 1:28:29, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.2269
2022-11-21 04:16:47,728 - mmcls - INFO - Epoch [15][200/391]	lr: 9.487e-02, eta: 1:28:40, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.2844
2022-11-21 04:16:56,523 - mmcls - INFO - Epoch [15][300/391]	lr: 9.478e-02, eta: 1:28:51, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.2097
2022-11-21 04:17:06,410 - mmcls - INFO - Epoch(val) [15][79]	train_accuracy: 48.0860, accuracy_top-1: 51.4600, accuracy_top-5: 83.0400
2022-11-21 04:17:17,150 - mmcls - INFO - Epoch [16][100/391]	lr: 9.460e-02, eta: 1:27:57, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.1911
2022-11-21 04:17:26,033 - mmcls - INFO - Epoch [16][200/391]	lr: 9.451e-02, eta: 1:28:08, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.1269
2022-11-21 04:17:34,822 - mmcls - INFO - Epoch [16][300/391]	lr: 9.442e-02, eta: 1:28:18, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.1667
2022-11-21 04:17:44,670 - mmcls - INFO - Epoch(val) [16][79]	train_accuracy: 49.3340, accuracy_top-1: 52.5900, accuracy_top-5: 82.2800
2022-11-21 04:17:55,231 - mmcls - INFO - Epoch [17][100/391]	lr: 9.425e-02, eta: 1:27:24, time: 0.105, data_time: 0.021, memory: 1669, loss: 2.1388
2022-11-21 04:18:03,840 - mmcls - INFO - Epoch [17][200/391]	lr: 9.415e-02, eta: 1:27:31, time: 0.086, data_time: 0.001, memory: 1669, loss: 2.1190
2022-11-21 04:18:12,691 - mmcls - INFO - Epoch [17][300/391]	lr: 9.406e-02, eta: 1:27:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.2424
2022-11-21 04:18:22,588 - mmcls - INFO - Epoch(val) [17][79]	train_accuracy: 50.4860, accuracy_top-1: 49.9300, accuracy_top-5: 80.0700
2022-11-21 04:18:33,354 - mmcls - INFO - Epoch [18][100/391]	lr: 9.389e-02, eta: 1:26:52, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.1501
2022-11-21 04:18:42,193 - mmcls - INFO - Epoch [18][200/391]	lr: 9.379e-02, eta: 1:27:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.2120
2022-11-21 04:18:51,005 - mmcls - INFO - Epoch [18][300/391]	lr: 9.370e-02, eta: 1:27:09, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.1504
2022-11-21 04:19:00,996 - mmcls - INFO - Epoch(val) [18][79]	train_accuracy: 50.4740, accuracy_top-1: 49.4700, accuracy_top-5: 79.1100
2022-11-21 04:19:11,740 - mmcls - INFO - Epoch [19][100/391]	lr: 9.353e-02, eta: 1:26:22, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.0841
2022-11-21 04:19:20,538 - mmcls - INFO - Epoch [19][200/391]	lr: 9.343e-02, eta: 1:26:29, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.2656
2022-11-21 04:19:29,345 - mmcls - INFO - Epoch [19][300/391]	lr: 9.334e-02, eta: 1:26:36, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.2863
2022-11-21 04:19:39,160 - mmcls - INFO - Epoch(val) [19][79]	train_accuracy: 49.8580, accuracy_top-1: 46.4100, accuracy_top-5: 77.2400
2022-11-21 04:19:49,824 - mmcls - INFO - Epoch [20][100/391]	lr: 9.317e-02, eta: 1:25:51, time: 0.106, data_time: 0.021, memory: 1669, loss: 2.0730
2022-11-21 04:19:58,533 - mmcls - INFO - Epoch [20][200/391]	lr: 9.307e-02, eta: 1:25:56, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.9830
2022-11-21 04:20:07,357 - mmcls - INFO - Epoch [20][300/391]	lr: 9.298e-02, eta: 1:26:03, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.1692
2022-11-21 04:20:15,444 - mmcls - INFO - Saving checkpoint at 20 epochs
2022-11-21 04:20:17,434 - mmcls - INFO - Epoch(val) [20][79]	train_accuracy: 52.6320, accuracy_top-1: 53.6600, accuracy_top-5: 83.0400
2022-11-21 04:20:28,268 - mmcls - INFO - Epoch [21][100/391]	lr: 9.281e-02, eta: 1:25:21, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.9689
2022-11-21 04:20:37,096 - mmcls - INFO - Epoch [21][200/391]	lr: 9.271e-02, eta: 1:25:27, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.0770
2022-11-21 04:20:45,970 - mmcls - INFO - Epoch [21][300/391]	lr: 9.262e-02, eta: 1:25:33, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9686
2022-11-21 04:20:55,923 - mmcls - INFO - Epoch(val) [21][79]	train_accuracy: 51.9920, accuracy_top-1: 56.5700, accuracy_top-5: 84.1300
2022-11-21 04:21:06,655 - mmcls - INFO - Epoch [22][100/391]	lr: 9.244e-02, eta: 1:24:51, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.0598
2022-11-21 04:21:15,476 - mmcls - INFO - Epoch [22][200/391]	lr: 9.235e-02, eta: 1:24:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.0243
2022-11-21 04:21:24,381 - mmcls - INFO - Epoch [22][300/391]	lr: 9.226e-02, eta: 1:25:03, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.1128
2022-11-21 04:21:34,309 - mmcls - INFO - Epoch(val) [22][79]	train_accuracy: 52.3740, accuracy_top-1: 55.7000, accuracy_top-5: 84.0100
2022-11-21 04:21:44,915 - mmcls - INFO - Epoch [23][100/391]	lr: 9.208e-02, eta: 1:24:21, time: 0.106, data_time: 0.021, memory: 1669, loss: 2.0408
2022-11-21 04:21:53,619 - mmcls - INFO - Epoch [23][200/391]	lr: 9.199e-02, eta: 1:24:25, time: 0.087, data_time: 0.001, memory: 1669, loss: 2.0665
2022-11-21 04:22:02,319 - mmcls - INFO - Epoch [23][300/391]	lr: 9.190e-02, eta: 1:24:29, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.8773
2022-11-21 04:22:12,237 - mmcls - INFO - Epoch(val) [23][79]	train_accuracy: 53.5840, accuracy_top-1: 50.8100, accuracy_top-5: 78.4100
2022-11-21 04:22:22,995 - mmcls - INFO - Epoch [24][100/391]	lr: 9.172e-02, eta: 1:23:50, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8616
2022-11-21 04:22:31,823 - mmcls - INFO - Epoch [24][200/391]	lr: 9.163e-02, eta: 1:23:55, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9652
2022-11-21 04:22:40,623 - mmcls - INFO - Epoch [24][300/391]	lr: 9.153e-02, eta: 1:23:58, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.1578
2022-11-21 04:22:50,562 - mmcls - INFO - Epoch(val) [24][79]	train_accuracy: 54.9500, accuracy_top-1: 52.4900, accuracy_top-5: 81.8700
2022-11-21 04:23:01,259 - mmcls - INFO - Epoch [25][100/391]	lr: 9.136e-02, eta: 1:23:21, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9319
2022-11-21 04:23:10,096 - mmcls - INFO - Epoch [25][200/391]	lr: 9.126e-02, eta: 1:23:24, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9619
2022-11-21 04:23:18,849 - mmcls - INFO - Epoch [25][300/391]	lr: 9.117e-02, eta: 1:23:28, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.0753
2022-11-21 04:23:28,681 - mmcls - INFO - Epoch(val) [25][79]	train_accuracy: 53.7260, accuracy_top-1: 52.7700, accuracy_top-5: 81.7200
2022-11-21 04:23:39,470 - mmcls - INFO - Epoch [26][100/391]	lr: 9.099e-02, eta: 1:22:51, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.9686
2022-11-21 04:23:48,224 - mmcls - INFO - Epoch [26][200/391]	lr: 9.090e-02, eta: 1:22:54, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.0741
2022-11-21 04:23:57,013 - mmcls - INFO - Epoch [26][300/391]	lr: 9.081e-02, eta: 1:22:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.1058
2022-11-21 04:24:06,854 - mmcls - INFO - Epoch(val) [26][79]	train_accuracy: 53.4500, accuracy_top-1: 58.1300, accuracy_top-5: 85.2300
2022-11-21 04:24:17,653 - mmcls - INFO - Epoch [27][100/391]	lr: 9.063e-02, eta: 1:22:22, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.9382
2022-11-21 04:24:26,601 - mmcls - INFO - Epoch [27][200/391]	lr: 9.054e-02, eta: 1:22:26, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0837
2022-11-21 04:24:35,498 - mmcls - INFO - Epoch [27][300/391]	lr: 9.044e-02, eta: 1:22:29, time: 0.089, data_time: 0.001, memory: 1669, loss: 2.0052
2022-11-21 04:24:45,346 - mmcls - INFO - Epoch(val) [27][79]	train_accuracy: 55.0600, accuracy_top-1: 52.1900, accuracy_top-5: 81.1000
2022-11-21 04:24:55,949 - mmcls - INFO - Epoch [28][100/391]	lr: 9.026e-02, eta: 1:21:53, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.9916
2022-11-21 04:25:04,689 - mmcls - INFO - Epoch [28][200/391]	lr: 9.017e-02, eta: 1:21:55, time: 0.087, data_time: 0.001, memory: 1669, loss: 2.0024
2022-11-21 04:25:13,492 - mmcls - INFO - Epoch [28][300/391]	lr: 9.008e-02, eta: 1:21:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.0455
2022-11-21 04:25:23,386 - mmcls - INFO - Epoch(val) [28][79]	train_accuracy: 54.3820, accuracy_top-1: 59.4600, accuracy_top-5: 86.7900
2022-11-21 04:25:34,058 - mmcls - INFO - Epoch [29][100/391]	lr: 8.990e-02, eta: 1:21:23, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.9133
2022-11-21 04:25:42,881 - mmcls - INFO - Epoch [29][200/391]	lr: 8.980e-02, eta: 1:21:25, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9673
2022-11-21 04:25:51,701 - mmcls - INFO - Epoch [29][300/391]	lr: 8.971e-02, eta: 1:21:27, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9819
2022-11-21 04:26:01,557 - mmcls - INFO - Epoch(val) [29][79]	train_accuracy: 55.5000, accuracy_top-1: 56.1300, accuracy_top-5: 84.0700
2022-11-21 04:26:12,240 - mmcls - INFO - Epoch [30][100/391]	lr: 8.953e-02, eta: 1:20:54, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9410
2022-11-21 04:26:20,994 - mmcls - INFO - Epoch [30][200/391]	lr: 8.944e-02, eta: 1:20:55, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8925
2022-11-21 04:26:29,807 - mmcls - INFO - Epoch [30][300/391]	lr: 8.934e-02, eta: 1:20:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.0395
2022-11-21 04:26:37,760 - mmcls - INFO - Saving checkpoint at 30 epochs
2022-11-21 04:26:39,768 - mmcls - INFO - Epoch(val) [30][79]	train_accuracy: 55.4160, accuracy_top-1: 54.3600, accuracy_top-5: 83.9000
2022-11-21 04:26:50,504 - mmcls - INFO - Epoch [31][100/391]	lr: 8.916e-02, eta: 1:20:25, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.0133
2022-11-21 04:26:59,287 - mmcls - INFO - Epoch [31][200/391]	lr: 8.907e-02, eta: 1:20:26, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8793
2022-11-21 04:27:08,154 - mmcls - INFO - Epoch [31][300/391]	lr: 8.898e-02, eta: 1:20:27, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9266
2022-11-21 04:27:17,980 - mmcls - INFO - Epoch(val) [31][79]	train_accuracy: 55.4100, accuracy_top-1: 55.5600, accuracy_top-5: 83.7000
2022-11-21 04:27:28,653 - mmcls - INFO - Epoch [32][100/391]	lr: 8.880e-02, eta: 1:19:56, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.9049
2022-11-21 04:27:37,400 - mmcls - INFO - Epoch [32][200/391]	lr: 8.870e-02, eta: 1:19:56, time: 0.087, data_time: 0.001, memory: 1669, loss: 2.0147
2022-11-21 04:27:46,131 - mmcls - INFO - Epoch [32][300/391]	lr: 8.861e-02, eta: 1:19:57, time: 0.087, data_time: 0.001, memory: 1669, loss: 2.0864
2022-11-21 04:27:55,980 - mmcls - INFO - Epoch(val) [32][79]	train_accuracy: 56.1720, accuracy_top-1: 44.8500, accuracy_top-5: 74.6400
2022-11-21 04:28:06,669 - mmcls - INFO - Epoch [33][100/391]	lr: 8.843e-02, eta: 1:19:26, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7978
2022-11-21 04:28:15,598 - mmcls - INFO - Epoch [33][200/391]	lr: 8.833e-02, eta: 1:19:27, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8645
2022-11-21 04:28:24,454 - mmcls - INFO - Epoch [33][300/391]	lr: 8.824e-02, eta: 1:19:28, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9725
2022-11-21 04:28:34,455 - mmcls - INFO - Epoch(val) [33][79]	train_accuracy: 57.2160, accuracy_top-1: 58.5200, accuracy_top-5: 85.3000
2022-11-21 04:28:45,024 - mmcls - INFO - Epoch [34][100/391]	lr: 8.806e-02, eta: 1:18:57, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.9848
2022-11-21 04:28:53,734 - mmcls - INFO - Epoch [34][200/391]	lr: 8.797e-02, eta: 1:18:57, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.8995
2022-11-21 04:29:02,538 - mmcls - INFO - Epoch [34][300/391]	lr: 8.787e-02, eta: 1:18:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7756
2022-11-21 04:29:12,515 - mmcls - INFO - Epoch(val) [34][79]	train_accuracy: 57.5780, accuracy_top-1: 60.3300, accuracy_top-5: 87.3500
2022-11-21 04:29:23,275 - mmcls - INFO - Epoch [35][100/391]	lr: 8.769e-02, eta: 1:18:28, time: 0.107, data_time: 0.021, memory: 1669, loss: 2.1083
2022-11-21 04:29:32,052 - mmcls - INFO - Epoch [35][200/391]	lr: 8.760e-02, eta: 1:18:28, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8999
2022-11-21 04:29:40,723 - mmcls - INFO - Epoch [35][300/391]	lr: 8.750e-02, eta: 1:18:27, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.9475
2022-11-21 04:29:50,518 - mmcls - INFO - Epoch(val) [35][79]	train_accuracy: 56.1880, accuracy_top-1: 60.6700, accuracy_top-5: 87.3000
2022-11-21 04:30:01,103 - mmcls - INFO - Epoch [36][100/391]	lr: 8.732e-02, eta: 1:17:57, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.8538
2022-11-21 04:30:09,896 - mmcls - INFO - Epoch [36][200/391]	lr: 8.723e-02, eta: 1:17:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8776
2022-11-21 04:30:18,735 - mmcls - INFO - Epoch [36][300/391]	lr: 8.713e-02, eta: 1:17:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 2.1273
2022-11-21 04:30:28,572 - mmcls - INFO - Epoch(val) [36][79]	train_accuracy: 57.3180, accuracy_top-1: 47.2300, accuracy_top-5: 75.8900
2022-11-21 04:30:39,262 - mmcls - INFO - Epoch [37][100/391]	lr: 8.695e-02, eta: 1:17:28, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9714
2022-11-21 04:30:48,102 - mmcls - INFO - Epoch [37][200/391]	lr: 8.685e-02, eta: 1:17:28, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9617
2022-11-21 04:30:56,984 - mmcls - INFO - Epoch [37][300/391]	lr: 8.676e-02, eta: 1:17:28, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9687
2022-11-21 04:31:06,903 - mmcls - INFO - Epoch(val) [37][79]	train_accuracy: 56.6080, accuracy_top-1: 59.1500, accuracy_top-5: 86.1700
2022-11-21 04:31:17,597 - mmcls - INFO - Epoch [38][100/391]	lr: 8.658e-02, eta: 1:17:00, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9704
2022-11-21 04:31:26,431 - mmcls - INFO - Epoch [38][200/391]	lr: 8.648e-02, eta: 1:17:00, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8925
2022-11-21 04:31:35,214 - mmcls - INFO - Epoch [38][300/391]	lr: 8.639e-02, eta: 1:16:59, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8279
2022-11-21 04:31:45,008 - mmcls - INFO - Epoch(val) [38][79]	train_accuracy: 57.2620, accuracy_top-1: 58.0500, accuracy_top-5: 85.8900
2022-11-21 04:31:55,560 - mmcls - INFO - Epoch [39][100/391]	lr: 8.621e-02, eta: 1:16:31, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.7600
2022-11-21 04:32:04,255 - mmcls - INFO - Epoch [39][200/391]	lr: 8.611e-02, eta: 1:16:29, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.9914
2022-11-21 04:32:13,137 - mmcls - INFO - Epoch [39][300/391]	lr: 8.601e-02, eta: 1:16:29, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8182
2022-11-21 04:32:23,077 - mmcls - INFO - Epoch(val) [39][79]	train_accuracy: 58.2900, accuracy_top-1: 57.8900, accuracy_top-5: 84.9300
2022-11-21 04:32:33,864 - mmcls - INFO - Epoch [40][100/391]	lr: 8.583e-02, eta: 1:16:02, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7170
2022-11-21 04:32:42,563 - mmcls - INFO - Epoch [40][200/391]	lr: 8.574e-02, eta: 1:16:00, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.9820
2022-11-21 04:32:51,283 - mmcls - INFO - Epoch [40][300/391]	lr: 8.564e-02, eta: 1:15:59, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.8647
2022-11-21 04:32:59,266 - mmcls - INFO - Saving checkpoint at 40 epochs
2022-11-21 04:33:01,237 - mmcls - INFO - Epoch(val) [40][79]	train_accuracy: 58.2680, accuracy_top-1: 51.9300, accuracy_top-5: 81.7700
2022-11-21 04:33:11,925 - mmcls - INFO - Epoch [41][100/391]	lr: 8.546e-02, eta: 1:15:32, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7367
2022-11-21 04:33:20,858 - mmcls - INFO - Epoch [41][200/391]	lr: 8.536e-02, eta: 1:15:32, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8967
2022-11-21 04:33:29,556 - mmcls - INFO - Epoch [41][300/391]	lr: 8.527e-02, eta: 1:15:30, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.8212
2022-11-21 04:33:39,345 - mmcls - INFO - Epoch(val) [41][79]	train_accuracy: 59.0440, accuracy_top-1: 59.0700, accuracy_top-5: 85.9400
2022-11-21 04:33:49,842 - mmcls - INFO - Epoch [42][100/391]	lr: 8.508e-02, eta: 1:15:03, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.8001
2022-11-21 04:33:58,603 - mmcls - INFO - Epoch [42][200/391]	lr: 8.499e-02, eta: 1:15:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9397
2022-11-21 04:34:07,371 - mmcls - INFO - Epoch [42][300/391]	lr: 8.489e-02, eta: 1:15:00, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8200
2022-11-21 04:34:17,279 - mmcls - INFO - Epoch(val) [42][79]	train_accuracy: 58.2060, accuracy_top-1: 60.4400, accuracy_top-5: 87.0200
2022-11-21 04:34:28,021 - mmcls - INFO - Epoch [43][100/391]	lr: 8.471e-02, eta: 1:14:34, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7049
2022-11-21 04:34:36,769 - mmcls - INFO - Epoch [43][200/391]	lr: 8.461e-02, eta: 1:14:32, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.9397
2022-11-21 04:34:45,533 - mmcls - INFO - Epoch [43][300/391]	lr: 8.452e-02, eta: 1:14:31, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9005
2022-11-21 04:34:55,399 - mmcls - INFO - Epoch(val) [43][79]	train_accuracy: 58.5080, accuracy_top-1: 59.2300, accuracy_top-5: 85.9500
2022-11-21 04:35:06,025 - mmcls - INFO - Epoch [44][100/391]	lr: 8.433e-02, eta: 1:14:05, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.7678
2022-11-21 04:35:14,844 - mmcls - INFO - Epoch [44][200/391]	lr: 8.424e-02, eta: 1:14:03, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8951
2022-11-21 04:35:23,718 - mmcls - INFO - Epoch [44][300/391]	lr: 8.414e-02, eta: 1:14:02, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.5966
2022-11-21 04:35:33,523 - mmcls - INFO - Epoch(val) [44][79]	train_accuracy: 59.4580, accuracy_top-1: 59.8400, accuracy_top-5: 86.5600
2022-11-21 04:35:44,321 - mmcls - INFO - Epoch [45][100/391]	lr: 8.396e-02, eta: 1:13:37, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.6716
2022-11-21 04:35:53,244 - mmcls - INFO - Epoch [45][200/391]	lr: 8.386e-02, eta: 1:13:35, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8803
2022-11-21 04:36:02,099 - mmcls - INFO - Epoch [45][300/391]	lr: 8.376e-02, eta: 1:13:34, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8090
2022-11-21 04:36:11,983 - mmcls - INFO - Epoch(val) [45][79]	train_accuracy: 59.5540, accuracy_top-1: 55.2700, accuracy_top-5: 82.2200
2022-11-21 04:36:22,666 - mmcls - INFO - Epoch [46][100/391]	lr: 8.358e-02, eta: 1:13:09, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.9163
2022-11-21 04:36:31,556 - mmcls - INFO - Epoch [46][200/391]	lr: 8.348e-02, eta: 1:13:07, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.9345
2022-11-21 04:36:40,297 - mmcls - INFO - Epoch [46][300/391]	lr: 8.339e-02, eta: 1:13:05, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.9107
2022-11-21 04:36:50,193 - mmcls - INFO - Epoch(val) [46][79]	train_accuracy: 57.9220, accuracy_top-1: 59.5500, accuracy_top-5: 86.1000
2022-11-21 04:37:00,880 - mmcls - INFO - Epoch [47][100/391]	lr: 8.320e-02, eta: 1:12:40, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8867
2022-11-21 04:37:09,698 - mmcls - INFO - Epoch [47][200/391]	lr: 8.310e-02, eta: 1:12:38, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7387
2022-11-21 04:37:18,570 - mmcls - INFO - Epoch [47][300/391]	lr: 8.301e-02, eta: 1:12:36, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7148
2022-11-21 04:37:28,417 - mmcls - INFO - Epoch(val) [47][79]	train_accuracy: 60.2920, accuracy_top-1: 58.6700, accuracy_top-5: 86.9400
2022-11-21 04:37:38,991 - mmcls - INFO - Epoch [48][100/391]	lr: 8.282e-02, eta: 1:12:11, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.7223
2022-11-21 04:37:47,672 - mmcls - INFO - Epoch [48][200/391]	lr: 8.273e-02, eta: 1:12:08, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.7325
2022-11-21 04:37:56,345 - mmcls - INFO - Epoch [48][300/391]	lr: 8.263e-02, eta: 1:12:06, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.9177
2022-11-21 04:38:06,153 - mmcls - INFO - Epoch(val) [48][79]	train_accuracy: 59.0080, accuracy_top-1: 59.0700, accuracy_top-5: 86.8000
2022-11-21 04:38:16,842 - mmcls - INFO - Epoch [49][100/391]	lr: 8.244e-02, eta: 1:11:42, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7318
2022-11-21 04:38:25,638 - mmcls - INFO - Epoch [49][200/391]	lr: 8.235e-02, eta: 1:11:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9730
2022-11-21 04:38:34,451 - mmcls - INFO - Epoch [49][300/391]	lr: 8.225e-02, eta: 1:11:37, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9208
2022-11-21 04:38:44,427 - mmcls - INFO - Epoch(val) [49][79]	train_accuracy: 59.1180, accuracy_top-1: 58.2000, accuracy_top-5: 85.9500
2022-11-21 04:38:55,146 - mmcls - INFO - Epoch [50][100/391]	lr: 8.206e-02, eta: 1:11:13, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8475
2022-11-21 04:39:03,948 - mmcls - INFO - Epoch [50][200/391]	lr: 8.197e-02, eta: 1:11:11, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8427
2022-11-21 04:39:12,793 - mmcls - INFO - Epoch [50][300/391]	lr: 8.187e-02, eta: 1:11:08, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9008
2022-11-21 04:39:20,840 - mmcls - INFO - Saving checkpoint at 50 epochs
2022-11-21 04:39:22,827 - mmcls - INFO - Epoch(val) [50][79]	train_accuracy: 59.5720, accuracy_top-1: 61.4500, accuracy_top-5: 87.3800
2022-11-21 04:39:33,469 - mmcls - INFO - Epoch [51][100/391]	lr: 8.168e-02, eta: 1:10:45, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.6690
2022-11-21 04:39:42,114 - mmcls - INFO - Epoch [51][200/391]	lr: 8.158e-02, eta: 1:10:41, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.8088
2022-11-21 04:39:50,904 - mmcls - INFO - Epoch [51][300/391]	lr: 8.149e-02, eta: 1:10:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9210
2022-11-21 04:40:00,671 - mmcls - INFO - Epoch(val) [51][79]	train_accuracy: 60.1600, accuracy_top-1: 59.7400, accuracy_top-5: 85.7800
2022-11-21 04:40:11,232 - mmcls - INFO - Epoch [52][100/391]	lr: 8.130e-02, eta: 1:10:15, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.7477
2022-11-21 04:40:19,905 - mmcls - INFO - Epoch [52][200/391]	lr: 8.120e-02, eta: 1:10:12, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.7123
2022-11-21 04:40:28,580 - mmcls - INFO - Epoch [52][300/391]	lr: 8.110e-02, eta: 1:10:09, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.6856
2022-11-21 04:40:38,458 - mmcls - INFO - Epoch(val) [52][79]	train_accuracy: 60.8100, accuracy_top-1: 63.0900, accuracy_top-5: 88.5800
2022-11-21 04:40:49,060 - mmcls - INFO - Epoch [53][100/391]	lr: 8.092e-02, eta: 1:09:46, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.6263
2022-11-21 04:40:57,861 - mmcls - INFO - Epoch [53][200/391]	lr: 8.082e-02, eta: 1:09:43, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8278
2022-11-21 04:41:06,720 - mmcls - INFO - Epoch [53][300/391]	lr: 8.072e-02, eta: 1:09:40, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.8983
2022-11-21 04:41:16,732 - mmcls - INFO - Epoch(val) [53][79]	train_accuracy: 60.2820, accuracy_top-1: 53.6500, accuracy_top-5: 82.2700
2022-11-21 04:41:27,494 - mmcls - INFO - Epoch [54][100/391]	lr: 8.053e-02, eta: 1:09:17, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.8745
2022-11-21 04:41:36,342 - mmcls - INFO - Epoch [54][200/391]	lr: 8.044e-02, eta: 1:09:15, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6441
2022-11-21 04:41:45,184 - mmcls - INFO - Epoch [54][300/391]	lr: 8.034e-02, eta: 1:09:12, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9046
2022-11-21 04:41:55,073 - mmcls - INFO - Epoch(val) [54][79]	train_accuracy: 60.3240, accuracy_top-1: 61.2800, accuracy_top-5: 87.2500
2022-11-21 04:42:05,680 - mmcls - INFO - Epoch [55][100/391]	lr: 8.015e-02, eta: 1:08:49, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.5819
2022-11-21 04:42:14,502 - mmcls - INFO - Epoch [55][200/391]	lr: 8.005e-02, eta: 1:08:46, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7187
2022-11-21 04:42:23,328 - mmcls - INFO - Epoch [55][300/391]	lr: 7.995e-02, eta: 1:08:43, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6527
2022-11-21 04:42:33,196 - mmcls - INFO - Epoch(val) [55][79]	train_accuracy: 62.4100, accuracy_top-1: 59.4800, accuracy_top-5: 86.5100
2022-11-21 04:42:43,923 - mmcls - INFO - Epoch [56][100/391]	lr: 7.977e-02, eta: 1:08:21, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6737
2022-11-21 04:42:52,724 - mmcls - INFO - Epoch [56][200/391]	lr: 7.967e-02, eta: 1:08:17, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6163
2022-11-21 04:43:01,529 - mmcls - INFO - Epoch [56][300/391]	lr: 7.957e-02, eta: 1:08:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9373
2022-11-21 04:43:11,376 - mmcls - INFO - Epoch(val) [56][79]	train_accuracy: 61.2060, accuracy_top-1: 61.6900, accuracy_top-5: 87.3500
2022-11-21 04:43:22,014 - mmcls - INFO - Epoch [57][100/391]	lr: 7.938e-02, eta: 1:07:52, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.8140
2022-11-21 04:43:30,742 - mmcls - INFO - Epoch [57][200/391]	lr: 7.928e-02, eta: 1:07:48, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.6602
2022-11-21 04:43:39,443 - mmcls - INFO - Epoch [57][300/391]	lr: 7.918e-02, eta: 1:07:45, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.6969
2022-11-21 04:43:49,227 - mmcls - INFO - Epoch(val) [57][79]	train_accuracy: 62.1520, accuracy_top-1: 61.1500, accuracy_top-5: 86.7500
2022-11-21 04:43:59,798 - mmcls - INFO - Epoch [58][100/391]	lr: 7.899e-02, eta: 1:07:23, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.7125
2022-11-21 04:44:08,512 - mmcls - INFO - Epoch [58][200/391]	lr: 7.889e-02, eta: 1:07:19, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.6773
2022-11-21 04:44:17,335 - mmcls - INFO - Epoch [58][300/391]	lr: 7.880e-02, eta: 1:07:16, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6530
2022-11-21 04:44:27,315 - mmcls - INFO - Epoch(val) [58][79]	train_accuracy: 62.2020, accuracy_top-1: 62.1700, accuracy_top-5: 87.4200
2022-11-21 04:44:38,007 - mmcls - INFO - Epoch [59][100/391]	lr: 7.861e-02, eta: 1:06:54, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.5551
2022-11-21 04:44:46,778 - mmcls - INFO - Epoch [59][200/391]	lr: 7.851e-02, eta: 1:06:50, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7090
2022-11-21 04:44:55,530 - mmcls - INFO - Epoch [59][300/391]	lr: 7.841e-02, eta: 1:06:47, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.9653
2022-11-21 04:45:05,347 - mmcls - INFO - Epoch(val) [59][79]	train_accuracy: 60.7940, accuracy_top-1: 56.5000, accuracy_top-5: 84.1200
2022-11-21 04:45:16,023 - mmcls - INFO - Epoch [60][100/391]	lr: 7.822e-02, eta: 1:06:25, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.6641
2022-11-21 04:45:24,865 - mmcls - INFO - Epoch [60][200/391]	lr: 7.812e-02, eta: 1:06:22, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7600
2022-11-21 04:45:33,662 - mmcls - INFO - Epoch [60][300/391]	lr: 7.802e-02, eta: 1:06:18, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6943
2022-11-21 04:45:41,641 - mmcls - INFO - Saving checkpoint at 60 epochs
2022-11-21 04:45:43,660 - mmcls - INFO - Epoch(val) [60][79]	train_accuracy: 62.0520, accuracy_top-1: 62.2200, accuracy_top-5: 88.4100
2022-11-21 04:45:54,269 - mmcls - INFO - Epoch [61][100/391]	lr: 7.783e-02, eta: 1:05:57, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.5971
2022-11-21 04:46:02,936 - mmcls - INFO - Epoch [61][200/391]	lr: 7.773e-02, eta: 1:05:53, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.5524
2022-11-21 04:46:11,771 - mmcls - INFO - Epoch [61][300/391]	lr: 7.763e-02, eta: 1:05:49, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8476
2022-11-21 04:46:21,620 - mmcls - INFO - Epoch(val) [61][79]	train_accuracy: 62.7340, accuracy_top-1: 60.4100, accuracy_top-5: 86.7100
2022-11-21 04:46:32,346 - mmcls - INFO - Epoch [62][100/391]	lr: 7.744e-02, eta: 1:05:28, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6547
2022-11-21 04:46:41,164 - mmcls - INFO - Epoch [62][200/391]	lr: 7.734e-02, eta: 1:05:25, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7512
2022-11-21 04:46:50,021 - mmcls - INFO - Epoch [62][300/391]	lr: 7.724e-02, eta: 1:05:21, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7952
2022-11-21 04:47:00,020 - mmcls - INFO - Epoch(val) [62][79]	train_accuracy: 62.0200, accuracy_top-1: 62.2500, accuracy_top-5: 88.2300
2022-11-21 04:47:10,770 - mmcls - INFO - Epoch [63][100/391]	lr: 7.705e-02, eta: 1:05:00, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6150
2022-11-21 04:47:19,656 - mmcls - INFO - Epoch [63][200/391]	lr: 7.695e-02, eta: 1:04:56, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6513
2022-11-21 04:47:28,440 - mmcls - INFO - Epoch [63][300/391]	lr: 7.685e-02, eta: 1:04:53, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7132
2022-11-21 04:47:38,219 - mmcls - INFO - Epoch(val) [63][79]	train_accuracy: 62.3660, accuracy_top-1: 58.7700, accuracy_top-5: 85.6900
2022-11-21 04:47:49,064 - mmcls - INFO - Epoch [64][100/391]	lr: 7.666e-02, eta: 1:04:32, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.7444
2022-11-21 04:47:57,912 - mmcls - INFO - Epoch [64][200/391]	lr: 7.656e-02, eta: 1:04:28, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5579
2022-11-21 04:48:06,746 - mmcls - INFO - Epoch [64][300/391]	lr: 7.646e-02, eta: 1:04:24, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7320
2022-11-21 04:48:16,669 - mmcls - INFO - Epoch(val) [64][79]	train_accuracy: 62.0860, accuracy_top-1: 63.6700, accuracy_top-5: 88.8000
2022-11-21 04:48:27,449 - mmcls - INFO - Epoch [65][100/391]	lr: 7.626e-02, eta: 1:04:04, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.5329
2022-11-21 04:48:36,330 - mmcls - INFO - Epoch [65][200/391]	lr: 7.616e-02, eta: 1:04:00, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7145
2022-11-21 04:48:45,142 - mmcls - INFO - Epoch [65][300/391]	lr: 7.606e-02, eta: 1:03:56, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6743
2022-11-21 04:48:55,057 - mmcls - INFO - Epoch(val) [65][79]	train_accuracy: 62.9820, accuracy_top-1: 64.9200, accuracy_top-5: 88.9100
2022-11-21 04:49:05,756 - mmcls - INFO - Epoch [66][100/391]	lr: 7.587e-02, eta: 1:03:36, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6355
2022-11-21 04:49:14,650 - mmcls - INFO - Epoch [66][200/391]	lr: 7.577e-02, eta: 1:03:32, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7563
2022-11-21 04:49:23,540 - mmcls - INFO - Epoch [66][300/391]	lr: 7.567e-02, eta: 1:03:28, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7612
2022-11-21 04:49:33,400 - mmcls - INFO - Epoch(val) [66][79]	train_accuracy: 63.3720, accuracy_top-1: 63.0400, accuracy_top-5: 88.5800
2022-11-21 04:49:44,064 - mmcls - INFO - Epoch [67][100/391]	lr: 7.548e-02, eta: 1:03:08, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.6023
2022-11-21 04:49:52,769 - mmcls - INFO - Epoch [67][200/391]	lr: 7.538e-02, eta: 1:03:03, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.7583
2022-11-21 04:50:01,522 - mmcls - INFO - Epoch [67][300/391]	lr: 7.528e-02, eta: 1:02:59, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5132
2022-11-21 04:50:11,436 - mmcls - INFO - Epoch(val) [67][79]	train_accuracy: 63.5720, accuracy_top-1: 59.6900, accuracy_top-5: 85.6100
2022-11-21 04:50:22,189 - mmcls - INFO - Epoch [68][100/391]	lr: 7.508e-02, eta: 1:02:39, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6421
2022-11-21 04:50:31,119 - mmcls - INFO - Epoch [68][200/391]	lr: 7.498e-02, eta: 1:02:35, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7368
2022-11-21 04:50:39,904 - mmcls - INFO - Epoch [68][300/391]	lr: 7.488e-02, eta: 1:02:31, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6309
2022-11-21 04:50:49,862 - mmcls - INFO - Epoch(val) [68][79]	train_accuracy: 62.5780, accuracy_top-1: 61.1000, accuracy_top-5: 87.5000
2022-11-21 04:51:00,605 - mmcls - INFO - Epoch [69][100/391]	lr: 7.469e-02, eta: 1:02:11, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6365
2022-11-21 04:51:09,433 - mmcls - INFO - Epoch [69][200/391]	lr: 7.459e-02, eta: 1:02:07, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6767
2022-11-21 04:51:18,174 - mmcls - INFO - Epoch [69][300/391]	lr: 7.448e-02, eta: 1:02:02, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.5265
2022-11-21 04:51:27,983 - mmcls - INFO - Epoch(val) [69][79]	train_accuracy: 64.2100, accuracy_top-1: 65.3400, accuracy_top-5: 89.9500
2022-11-21 04:51:38,678 - mmcls - INFO - Epoch [70][100/391]	lr: 7.429e-02, eta: 1:01:42, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7094
2022-11-21 04:51:47,409 - mmcls - INFO - Epoch [70][200/391]	lr: 7.419e-02, eta: 1:01:38, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.8349
2022-11-21 04:51:56,106 - mmcls - INFO - Epoch [70][300/391]	lr: 7.409e-02, eta: 1:01:33, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.7879
2022-11-21 04:52:04,006 - mmcls - INFO - Saving checkpoint at 70 epochs
2022-11-21 04:52:05,994 - mmcls - INFO - Epoch(val) [70][79]	train_accuracy: 62.9700, accuracy_top-1: 64.8100, accuracy_top-5: 89.0900
2022-11-21 04:52:16,770 - mmcls - INFO - Epoch [71][100/391]	lr: 7.389e-02, eta: 1:01:14, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7255
2022-11-21 04:52:25,725 - mmcls - INFO - Epoch [71][200/391]	lr: 7.379e-02, eta: 1:01:10, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7325
2022-11-21 04:52:34,615 - mmcls - INFO - Epoch [71][300/391]	lr: 7.369e-02, eta: 1:01:05, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6600
2022-11-21 04:52:44,454 - mmcls - INFO - Epoch(val) [71][79]	train_accuracy: 62.8800, accuracy_top-1: 59.8300, accuracy_top-5: 87.1100
2022-11-21 04:52:55,053 - mmcls - INFO - Epoch [72][100/391]	lr: 7.349e-02, eta: 1:00:46, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.6660
2022-11-21 04:53:03,886 - mmcls - INFO - Epoch [72][200/391]	lr: 7.339e-02, eta: 1:00:41, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6161
2022-11-21 04:53:12,710 - mmcls - INFO - Epoch [72][300/391]	lr: 7.329e-02, eta: 1:00:37, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7609
2022-11-21 04:53:22,548 - mmcls - INFO - Epoch(val) [72][79]	train_accuracy: 62.9600, accuracy_top-1: 60.9600, accuracy_top-5: 86.7700
2022-11-21 04:53:33,244 - mmcls - INFO - Epoch [73][100/391]	lr: 7.309e-02, eta: 1:00:17, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6516
2022-11-21 04:53:41,980 - mmcls - INFO - Epoch [73][200/391]	lr: 7.299e-02, eta: 1:00:13, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.6707
2022-11-21 04:53:50,854 - mmcls - INFO - Epoch [73][300/391]	lr: 7.289e-02, eta: 1:00:08, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.5784
2022-11-21 04:54:00,696 - mmcls - INFO - Epoch(val) [73][79]	train_accuracy: 63.9360, accuracy_top-1: 65.3700, accuracy_top-5: 89.9200
2022-11-21 04:54:11,572 - mmcls - INFO - Epoch [74][100/391]	lr: 7.269e-02, eta: 0:59:49, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.8519
2022-11-21 04:54:20,460 - mmcls - INFO - Epoch [74][200/391]	lr: 7.259e-02, eta: 0:59:45, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6124
2022-11-21 04:54:29,363 - mmcls - INFO - Epoch [74][300/391]	lr: 7.249e-02, eta: 0:59:40, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7561
2022-11-21 04:54:39,313 - mmcls - INFO - Epoch(val) [74][79]	train_accuracy: 62.3000, accuracy_top-1: 58.7700, accuracy_top-5: 86.0900
2022-11-21 04:54:50,066 - mmcls - INFO - Epoch [75][100/391]	lr: 7.229e-02, eta: 0:59:21, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.4964
2022-11-21 04:54:58,796 - mmcls - INFO - Epoch [75][200/391]	lr: 7.219e-02, eta: 0:59:17, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.6716
2022-11-21 04:55:07,626 - mmcls - INFO - Epoch [75][300/391]	lr: 7.209e-02, eta: 0:59:12, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5751
2022-11-21 04:55:17,439 - mmcls - INFO - Epoch(val) [75][79]	train_accuracy: 65.0060, accuracy_top-1: 61.4800, accuracy_top-5: 87.3000
2022-11-21 04:55:28,072 - mmcls - INFO - Epoch [76][100/391]	lr: 7.189e-02, eta: 0:58:53, time: 0.106, data_time: 0.020, memory: 1669, loss: 1.6296
2022-11-21 04:55:36,694 - mmcls - INFO - Epoch [76][200/391]	lr: 7.179e-02, eta: 0:58:48, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.5898
2022-11-21 04:55:45,272 - mmcls - INFO - Epoch [76][300/391]	lr: 7.168e-02, eta: 0:58:43, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.6149
2022-11-21 04:55:55,016 - mmcls - INFO - Epoch(val) [76][79]	train_accuracy: 64.3440, accuracy_top-1: 66.5900, accuracy_top-5: 90.7500
2022-11-21 04:56:05,663 - mmcls - INFO - Epoch [77][100/391]	lr: 7.149e-02, eta: 0:58:24, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.6593
2022-11-21 04:56:14,542 - mmcls - INFO - Epoch [77][200/391]	lr: 7.138e-02, eta: 0:58:19, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.5648
2022-11-21 04:56:23,494 - mmcls - INFO - Epoch [77][300/391]	lr: 7.128e-02, eta: 0:58:14, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.6572
2022-11-21 04:56:33,490 - mmcls - INFO - Epoch(val) [77][79]	train_accuracy: 65.3260, accuracy_top-1: 62.2500, accuracy_top-5: 87.4200
2022-11-21 04:56:44,222 - mmcls - INFO - Epoch [78][100/391]	lr: 7.108e-02, eta: 0:57:56, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.5284
2022-11-21 04:56:52,935 - mmcls - INFO - Epoch [78][200/391]	lr: 7.098e-02, eta: 0:57:51, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.5860
2022-11-21 04:57:01,853 - mmcls - INFO - Epoch [78][300/391]	lr: 7.088e-02, eta: 0:57:46, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6475
2022-11-21 04:57:11,731 - mmcls - INFO - Epoch(val) [78][79]	train_accuracy: 65.9220, accuracy_top-1: 64.4500, accuracy_top-5: 88.0700
2022-11-21 04:57:22,426 - mmcls - INFO - Epoch [79][100/391]	lr: 7.068e-02, eta: 0:57:27, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6138
2022-11-21 04:57:31,184 - mmcls - INFO - Epoch [79][200/391]	lr: 7.057e-02, eta: 0:57:22, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.8704
2022-11-21 04:57:40,041 - mmcls - INFO - Epoch [79][300/391]	lr: 7.047e-02, eta: 0:57:18, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6833
2022-11-21 04:57:49,851 - mmcls - INFO - Epoch(val) [79][79]	train_accuracy: 64.1180, accuracy_top-1: 62.4900, accuracy_top-5: 87.3900
2022-11-21 04:58:00,408 - mmcls - INFO - Epoch [80][100/391]	lr: 7.027e-02, eta: 0:56:59, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.5538
2022-11-21 04:58:09,147 - mmcls - INFO - Epoch [80][200/391]	lr: 7.017e-02, eta: 0:56:54, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.7483
2022-11-21 04:58:17,973 - mmcls - INFO - Epoch [80][300/391]	lr: 7.006e-02, eta: 0:56:49, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6349
2022-11-21 04:58:26,002 - mmcls - INFO - Saving checkpoint at 80 epochs
2022-11-21 04:58:27,962 - mmcls - INFO - Epoch(val) [80][79]	train_accuracy: 64.7120, accuracy_top-1: 63.7700, accuracy_top-5: 89.2200
2022-11-21 04:58:38,655 - mmcls - INFO - Epoch [81][100/391]	lr: 6.986e-02, eta: 0:56:30, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.5841
2022-11-21 04:58:47,486 - mmcls - INFO - Epoch [81][200/391]	lr: 6.976e-02, eta: 0:56:25, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5811
2022-11-21 04:58:56,454 - mmcls - INFO - Epoch [81][300/391]	lr: 6.965e-02, eta: 0:56:21, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.5718
2022-11-21 04:59:06,450 - mmcls - INFO - Epoch(val) [81][79]	train_accuracy: 65.5860, accuracy_top-1: 65.7200, accuracy_top-5: 89.7300
2022-11-21 04:59:17,120 - mmcls - INFO - Epoch [82][100/391]	lr: 6.946e-02, eta: 0:56:02, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.6557
2022-11-21 04:59:25,876 - mmcls - INFO - Epoch [82][200/391]	lr: 6.935e-02, eta: 0:55:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5771
2022-11-21 04:59:34,643 - mmcls - INFO - Epoch [82][300/391]	lr: 6.925e-02, eta: 0:55:52, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4271
2022-11-21 04:59:44,409 - mmcls - INFO - Epoch(val) [82][79]	train_accuracy: 65.6140, accuracy_top-1: 65.5000, accuracy_top-5: 89.3600
2022-11-21 04:59:55,149 - mmcls - INFO - Epoch [83][100/391]	lr: 6.905e-02, eta: 0:55:34, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.4242
2022-11-21 05:00:04,051 - mmcls - INFO - Epoch [83][200/391]	lr: 6.894e-02, eta: 0:55:29, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4808
2022-11-21 05:00:12,955 - mmcls - INFO - Epoch [83][300/391]	lr: 6.884e-02, eta: 0:55:24, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6375
2022-11-21 05:00:22,774 - mmcls - INFO - Epoch(val) [83][79]	train_accuracy: 66.2420, accuracy_top-1: 63.7400, accuracy_top-5: 88.0900
2022-11-21 05:00:33,618 - mmcls - INFO - Epoch [84][100/391]	lr: 6.864e-02, eta: 0:55:06, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.5613
2022-11-21 05:00:42,365 - mmcls - INFO - Epoch [84][200/391]	lr: 6.853e-02, eta: 0:55:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6504
2022-11-21 05:00:51,140 - mmcls - INFO - Epoch [84][300/391]	lr: 6.843e-02, eta: 0:54:55, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6576
2022-11-21 05:01:00,995 - mmcls - INFO - Epoch(val) [84][79]	train_accuracy: 64.9560, accuracy_top-1: 66.4100, accuracy_top-5: 90.4100
2022-11-21 05:01:11,702 - mmcls - INFO - Epoch [85][100/391]	lr: 6.822e-02, eta: 0:54:37, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.5183
2022-11-21 05:01:20,470 - mmcls - INFO - Epoch [85][200/391]	lr: 6.812e-02, eta: 0:54:32, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4139
2022-11-21 05:01:29,211 - mmcls - INFO - Epoch [85][300/391]	lr: 6.801e-02, eta: 0:54:27, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.5532
2022-11-21 05:01:39,028 - mmcls - INFO - Epoch(val) [85][79]	train_accuracy: 66.1440, accuracy_top-1: 66.7600, accuracy_top-5: 90.4800
2022-11-21 05:01:49,582 - mmcls - INFO - Epoch [86][100/391]	lr: 6.781e-02, eta: 0:54:08, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.6911
2022-11-21 05:01:58,315 - mmcls - INFO - Epoch [86][200/391]	lr: 6.771e-02, eta: 0:54:03, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2991
2022-11-21 05:02:07,076 - mmcls - INFO - Epoch [86][300/391]	lr: 6.760e-02, eta: 0:53:58, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7220
2022-11-21 05:02:16,970 - mmcls - INFO - Epoch(val) [86][79]	train_accuracy: 65.4180, accuracy_top-1: 64.2800, accuracy_top-5: 89.1800
2022-11-21 05:02:27,764 - mmcls - INFO - Epoch [87][100/391]	lr: 6.740e-02, eta: 0:53:40, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.5912
2022-11-21 05:02:36,567 - mmcls - INFO - Epoch [87][200/391]	lr: 6.729e-02, eta: 0:53:35, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4196
2022-11-21 05:02:45,365 - mmcls - INFO - Epoch [87][300/391]	lr: 6.719e-02, eta: 0:53:30, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.7534
2022-11-21 05:02:55,224 - mmcls - INFO - Epoch(val) [87][79]	train_accuracy: 65.9440, accuracy_top-1: 60.4000, accuracy_top-5: 86.1500
2022-11-21 05:03:05,955 - mmcls - INFO - Epoch [88][100/391]	lr: 6.698e-02, eta: 0:53:12, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.7092
2022-11-21 05:03:14,720 - mmcls - INFO - Epoch [88][200/391]	lr: 6.688e-02, eta: 0:53:06, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5751
2022-11-21 05:03:23,469 - mmcls - INFO - Epoch [88][300/391]	lr: 6.677e-02, eta: 0:53:01, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.4708
2022-11-21 05:03:33,297 - mmcls - INFO - Epoch(val) [88][79]	train_accuracy: 66.2520, accuracy_top-1: 64.5600, accuracy_top-5: 88.2500
2022-11-21 05:03:43,870 - mmcls - INFO - Epoch [89][100/391]	lr: 6.657e-02, eta: 0:52:43, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.3901
2022-11-21 05:03:52,496 - mmcls - INFO - Epoch [89][200/391]	lr: 6.646e-02, eta: 0:52:38, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.7279
2022-11-21 05:04:01,120 - mmcls - INFO - Epoch [89][300/391]	lr: 6.635e-02, eta: 0:52:32, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.4687
2022-11-21 05:04:11,015 - mmcls - INFO - Epoch(val) [89][79]	train_accuracy: 67.5320, accuracy_top-1: 66.7900, accuracy_top-5: 90.4800
2022-11-21 05:04:21,782 - mmcls - INFO - Epoch [90][100/391]	lr: 6.615e-02, eta: 0:52:14, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.6337
2022-11-21 05:04:30,590 - mmcls - INFO - Epoch [90][200/391]	lr: 6.604e-02, eta: 0:52:09, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3743
2022-11-21 05:04:39,370 - mmcls - INFO - Epoch [90][300/391]	lr: 6.594e-02, eta: 0:52:04, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6574
2022-11-21 05:04:47,313 - mmcls - INFO - Saving checkpoint at 90 epochs
2022-11-21 05:04:49,343 - mmcls - INFO - Epoch(val) [90][79]	train_accuracy: 66.1360, accuracy_top-1: 62.5500, accuracy_top-5: 87.7800
2022-11-21 05:04:59,953 - mmcls - INFO - Epoch [91][100/391]	lr: 6.573e-02, eta: 0:51:46, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.5945
2022-11-21 05:05:08,718 - mmcls - INFO - Epoch [91][200/391]	lr: 6.563e-02, eta: 0:51:41, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3471
2022-11-21 05:05:17,501 - mmcls - INFO - Epoch [91][300/391]	lr: 6.552e-02, eta: 0:51:35, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5964
2022-11-21 05:05:27,375 - mmcls - INFO - Epoch(val) [91][79]	train_accuracy: 67.7960, accuracy_top-1: 63.8300, accuracy_top-5: 87.8800
2022-11-21 05:05:38,035 - mmcls - INFO - Epoch [92][100/391]	lr: 6.531e-02, eta: 0:51:17, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.4408
2022-11-21 05:05:46,843 - mmcls - INFO - Epoch [92][200/391]	lr: 6.521e-02, eta: 0:51:12, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5719
2022-11-21 05:05:55,681 - mmcls - INFO - Epoch [92][300/391]	lr: 6.510e-02, eta: 0:51:07, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4860
2022-11-21 05:06:05,574 - mmcls - INFO - Epoch(val) [92][79]	train_accuracy: 67.6160, accuracy_top-1: 62.4200, accuracy_top-5: 87.4700
2022-11-21 05:06:16,324 - mmcls - INFO - Epoch [93][100/391]	lr: 6.489e-02, eta: 0:50:49, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.3975
2022-11-21 05:06:25,062 - mmcls - INFO - Epoch [93][200/391]	lr: 6.479e-02, eta: 0:50:44, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.5760
2022-11-21 05:06:34,009 - mmcls - INFO - Epoch [93][300/391]	lr: 6.468e-02, eta: 0:50:38, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4957
2022-11-21 05:06:43,826 - mmcls - INFO - Epoch(val) [93][79]	train_accuracy: 67.9860, accuracy_top-1: 63.6400, accuracy_top-5: 88.4300
2022-11-21 05:06:54,617 - mmcls - INFO - Epoch [94][100/391]	lr: 6.447e-02, eta: 0:50:21, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.6548
2022-11-21 05:07:03,555 - mmcls - INFO - Epoch [94][200/391]	lr: 6.436e-02, eta: 0:50:16, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.7103
2022-11-21 05:07:12,409 - mmcls - INFO - Epoch [94][300/391]	lr: 6.426e-02, eta: 0:50:10, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4637
2022-11-21 05:07:22,251 - mmcls - INFO - Epoch(val) [94][79]	train_accuracy: 66.8180, accuracy_top-1: 62.8300, accuracy_top-5: 87.8300
2022-11-21 05:07:32,850 - mmcls - INFO - Epoch [95][100/391]	lr: 6.405e-02, eta: 0:49:53, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.5247
2022-11-21 05:07:41,622 - mmcls - INFO - Epoch [95][200/391]	lr: 6.394e-02, eta: 0:49:47, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6447
2022-11-21 05:07:50,405 - mmcls - INFO - Epoch [95][300/391]	lr: 6.383e-02, eta: 0:49:42, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5169
2022-11-21 05:08:00,177 - mmcls - INFO - Epoch(val) [95][79]	train_accuracy: 67.2960, accuracy_top-1: 62.1500, accuracy_top-5: 87.8300
2022-11-21 05:08:10,981 - mmcls - INFO - Epoch [96][100/391]	lr: 6.362e-02, eta: 0:49:25, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.4861
2022-11-21 05:08:19,995 - mmcls - INFO - Epoch [96][200/391]	lr: 6.352e-02, eta: 0:49:19, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.7283
2022-11-21 05:08:28,841 - mmcls - INFO - Epoch [96][300/391]	lr: 6.341e-02, eta: 0:49:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5598
2022-11-21 05:08:38,714 - mmcls - INFO - Epoch(val) [96][79]	train_accuracy: 66.4180, accuracy_top-1: 65.8600, accuracy_top-5: 89.8200
2022-11-21 05:08:49,285 - mmcls - INFO - Epoch [97][100/391]	lr: 6.320e-02, eta: 0:48:56, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.3799
2022-11-21 05:08:58,128 - mmcls - INFO - Epoch [97][200/391]	lr: 6.309e-02, eta: 0:48:51, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5892
2022-11-21 05:09:06,940 - mmcls - INFO - Epoch [97][300/391]	lr: 6.298e-02, eta: 0:48:45, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5110
2022-11-21 05:09:16,862 - mmcls - INFO - Epoch(val) [97][79]	train_accuracy: 68.1500, accuracy_top-1: 62.2600, accuracy_top-5: 88.1000
2022-11-21 05:09:27,552 - mmcls - INFO - Epoch [98][100/391]	lr: 6.277e-02, eta: 0:48:28, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.5759
2022-11-21 05:09:36,428 - mmcls - INFO - Epoch [98][200/391]	lr: 6.266e-02, eta: 0:48:23, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4120
2022-11-21 05:09:45,245 - mmcls - INFO - Epoch [98][300/391]	lr: 6.255e-02, eta: 0:48:17, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5608
2022-11-21 05:09:55,159 - mmcls - INFO - Epoch(val) [98][79]	train_accuracy: 67.5640, accuracy_top-1: 65.3400, accuracy_top-5: 89.8200
2022-11-21 05:10:05,729 - mmcls - INFO - Epoch [99][100/391]	lr: 6.235e-02, eta: 0:48:00, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.6524
2022-11-21 05:10:14,484 - mmcls - INFO - Epoch [99][200/391]	lr: 6.224e-02, eta: 0:47:54, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5679
2022-11-21 05:10:23,344 - mmcls - INFO - Epoch [99][300/391]	lr: 6.213e-02, eta: 0:47:48, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6089
2022-11-21 05:10:33,219 - mmcls - INFO - Epoch(val) [99][79]	train_accuracy: 66.6340, accuracy_top-1: 66.9300, accuracy_top-5: 90.0000
2022-11-21 05:10:44,004 - mmcls - INFO - Epoch [100][100/391]	lr: 6.192e-02, eta: 0:47:31, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.4656
2022-11-21 05:10:52,835 - mmcls - INFO - Epoch [100][200/391]	lr: 6.181e-02, eta: 0:47:26, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5195
2022-11-21 05:11:01,677 - mmcls - INFO - Epoch [100][300/391]	lr: 6.170e-02, eta: 0:47:20, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5227
2022-11-21 05:11:09,607 - mmcls - INFO - Saving checkpoint at 100 epochs
2022-11-21 05:11:11,600 - mmcls - INFO - Epoch(val) [100][79]	train_accuracy: 68.5260, accuracy_top-1: 65.8100, accuracy_top-5: 89.1100
2022-11-21 05:11:22,324 - mmcls - INFO - Epoch [101][100/391]	lr: 6.149e-02, eta: 0:47:03, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.4752
2022-11-21 05:11:31,028 - mmcls - INFO - Epoch [101][200/391]	lr: 6.138e-02, eta: 0:46:57, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.4648
2022-11-21 05:11:39,653 - mmcls - INFO - Epoch [101][300/391]	lr: 6.127e-02, eta: 0:46:51, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.4979
2022-11-21 05:11:49,432 - mmcls - INFO - Epoch(val) [101][79]	train_accuracy: 67.8220, accuracy_top-1: 66.8200, accuracy_top-5: 89.8800
2022-11-21 05:11:59,978 - mmcls - INFO - Epoch [102][100/391]	lr: 6.106e-02, eta: 0:46:34, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.4650
2022-11-21 05:12:08,881 - mmcls - INFO - Epoch [102][200/391]	lr: 6.094e-02, eta: 0:46:29, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6054
2022-11-21 05:12:17,753 - mmcls - INFO - Epoch [102][300/391]	lr: 6.083e-02, eta: 0:46:23, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.6053
2022-11-21 05:12:27,676 - mmcls - INFO - Epoch(val) [102][79]	train_accuracy: 66.9240, accuracy_top-1: 62.8900, accuracy_top-5: 87.2800
2022-11-21 05:12:38,314 - mmcls - INFO - Epoch [103][100/391]	lr: 6.062e-02, eta: 0:46:06, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3936
2022-11-21 05:12:47,027 - mmcls - INFO - Epoch [103][200/391]	lr: 6.051e-02, eta: 0:46:00, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.3703
2022-11-21 05:12:55,867 - mmcls - INFO - Epoch [103][300/391]	lr: 6.040e-02, eta: 0:45:55, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4123
2022-11-21 05:13:05,732 - mmcls - INFO - Epoch(val) [103][79]	train_accuracy: 68.9820, accuracy_top-1: 64.9900, accuracy_top-5: 89.7600
2022-11-21 05:13:16,387 - mmcls - INFO - Epoch [104][100/391]	lr: 6.019e-02, eta: 0:45:38, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3004
2022-11-21 05:13:25,142 - mmcls - INFO - Epoch [104][200/391]	lr: 6.008e-02, eta: 0:45:32, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4679
2022-11-21 05:13:33,920 - mmcls - INFO - Epoch [104][300/391]	lr: 5.997e-02, eta: 0:45:26, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3788
2022-11-21 05:13:43,719 - mmcls - INFO - Epoch(val) [104][79]	train_accuracy: 69.8800, accuracy_top-1: 62.5700, accuracy_top-5: 87.5500
2022-11-21 05:13:54,331 - mmcls - INFO - Epoch [105][100/391]	lr: 5.975e-02, eta: 0:45:09, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.4357
2022-11-21 05:14:02,935 - mmcls - INFO - Epoch [105][200/391]	lr: 5.964e-02, eta: 0:45:03, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.5082
2022-11-21 05:14:11,708 - mmcls - INFO - Epoch [105][300/391]	lr: 5.953e-02, eta: 0:44:57, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3332
2022-11-21 05:14:21,489 - mmcls - INFO - Epoch(val) [105][79]	train_accuracy: 69.1700, accuracy_top-1: 65.2200, accuracy_top-5: 89.6800
2022-11-21 05:14:32,019 - mmcls - INFO - Epoch [106][100/391]	lr: 5.932e-02, eta: 0:44:41, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.3038
2022-11-21 05:14:40,879 - mmcls - INFO - Epoch [106][200/391]	lr: 5.920e-02, eta: 0:44:35, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4655
2022-11-21 05:14:49,687 - mmcls - INFO - Epoch [106][300/391]	lr: 5.909e-02, eta: 0:44:29, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4337
2022-11-21 05:14:59,683 - mmcls - INFO - Epoch(val) [106][79]	train_accuracy: 70.1180, accuracy_top-1: 63.5400, accuracy_top-5: 88.4000
2022-11-21 05:15:10,361 - mmcls - INFO - Epoch [107][100/391]	lr: 5.888e-02, eta: 0:44:12, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3608
2022-11-21 05:15:19,169 - mmcls - INFO - Epoch [107][200/391]	lr: 5.877e-02, eta: 0:44:06, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.6640
2022-11-21 05:15:27,954 - mmcls - INFO - Epoch [107][300/391]	lr: 5.865e-02, eta: 0:44:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2926
2022-11-21 05:15:37,705 - mmcls - INFO - Epoch(val) [107][79]	train_accuracy: 68.3320, accuracy_top-1: 67.9200, accuracy_top-5: 90.8400
2022-11-21 05:15:48,539 - mmcls - INFO - Epoch [108][100/391]	lr: 5.844e-02, eta: 0:43:44, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.4060
2022-11-21 05:15:57,537 - mmcls - INFO - Epoch [108][200/391]	lr: 5.833e-02, eta: 0:43:38, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.5981
2022-11-21 05:16:06,357 - mmcls - INFO - Epoch [108][300/391]	lr: 5.821e-02, eta: 0:43:32, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3243
2022-11-21 05:16:16,282 - mmcls - INFO - Epoch(val) [108][79]	train_accuracy: 69.7440, accuracy_top-1: 66.7600, accuracy_top-5: 90.5800
2022-11-21 05:16:26,924 - mmcls - INFO - Epoch [109][100/391]	lr: 5.800e-02, eta: 0:43:16, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.2718
2022-11-21 05:16:35,536 - mmcls - INFO - Epoch [109][200/391]	lr: 5.788e-02, eta: 0:43:10, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.4949
2022-11-21 05:16:44,254 - mmcls - INFO - Epoch [109][300/391]	lr: 5.777e-02, eta: 0:43:04, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.4465
2022-11-21 05:16:54,077 - mmcls - INFO - Epoch(val) [109][79]	train_accuracy: 69.1640, accuracy_top-1: 65.4400, accuracy_top-5: 88.6900
2022-11-21 05:17:04,729 - mmcls - INFO - Epoch [110][100/391]	lr: 5.755e-02, eta: 0:42:47, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.4925
2022-11-21 05:17:13,530 - mmcls - INFO - Epoch [110][200/391]	lr: 5.744e-02, eta: 0:42:41, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4052
2022-11-21 05:17:22,358 - mmcls - INFO - Epoch [110][300/391]	lr: 5.733e-02, eta: 0:42:35, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4421
2022-11-21 05:17:30,313 - mmcls - INFO - Saving checkpoint at 110 epochs
2022-11-21 05:17:32,288 - mmcls - INFO - Epoch(val) [110][79]	train_accuracy: 69.5420, accuracy_top-1: 65.3400, accuracy_top-5: 88.7400
2022-11-21 05:17:42,943 - mmcls - INFO - Epoch [111][100/391]	lr: 5.711e-02, eta: 0:42:19, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.4046
2022-11-21 05:17:51,572 - mmcls - INFO - Epoch [111][200/391]	lr: 5.700e-02, eta: 0:42:13, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.3731
2022-11-21 05:18:00,188 - mmcls - INFO - Epoch [111][300/391]	lr: 5.688e-02, eta: 0:42:07, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.4552
2022-11-21 05:18:10,065 - mmcls - INFO - Epoch(val) [111][79]	train_accuracy: 71.1180, accuracy_top-1: 66.2700, accuracy_top-5: 89.9600
2022-11-21 05:18:20,788 - mmcls - INFO - Epoch [112][100/391]	lr: 5.667e-02, eta: 0:41:50, time: 0.107, data_time: 0.020, memory: 1669, loss: 1.5049
2022-11-21 05:18:29,548 - mmcls - INFO - Epoch [112][200/391]	lr: 5.655e-02, eta: 0:41:44, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5434
2022-11-21 05:18:38,299 - mmcls - INFO - Epoch [112][300/391]	lr: 5.644e-02, eta: 0:41:38, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.4817
2022-11-21 05:18:48,220 - mmcls - INFO - Epoch(val) [112][79]	train_accuracy: 68.3240, accuracy_top-1: 66.9100, accuracy_top-5: 90.5000
2022-11-21 05:18:58,948 - mmcls - INFO - Epoch [113][100/391]	lr: 5.622e-02, eta: 0:41:22, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.4399
2022-11-21 05:19:07,775 - mmcls - INFO - Epoch [113][200/391]	lr: 5.610e-02, eta: 0:41:16, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4468
2022-11-21 05:19:16,536 - mmcls - INFO - Epoch [113][300/391]	lr: 5.599e-02, eta: 0:41:10, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4851
2022-11-21 05:19:26,324 - mmcls - INFO - Epoch(val) [113][79]	train_accuracy: 70.0500, accuracy_top-1: 64.8200, accuracy_top-5: 89.5600
2022-11-21 05:19:36,947 - mmcls - INFO - Epoch [114][100/391]	lr: 5.577e-02, eta: 0:40:54, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.4031
2022-11-21 05:19:45,760 - mmcls - INFO - Epoch [114][200/391]	lr: 5.566e-02, eta: 0:40:48, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5935
2022-11-21 05:19:54,623 - mmcls - INFO - Epoch [114][300/391]	lr: 5.554e-02, eta: 0:40:42, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2853
2022-11-21 05:20:04,569 - mmcls - INFO - Epoch(val) [114][79]	train_accuracy: 69.8980, accuracy_top-1: 68.7900, accuracy_top-5: 91.3700
2022-11-21 05:20:15,247 - mmcls - INFO - Epoch [115][100/391]	lr: 5.532e-02, eta: 0:40:25, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3240
2022-11-21 05:20:24,154 - mmcls - INFO - Epoch [115][200/391]	lr: 5.520e-02, eta: 0:40:19, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3669
2022-11-21 05:20:32,928 - mmcls - INFO - Epoch [115][300/391]	lr: 5.509e-02, eta: 0:40:13, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3978
2022-11-21 05:20:42,699 - mmcls - INFO - Epoch(val) [115][79]	train_accuracy: 70.9420, accuracy_top-1: 66.6800, accuracy_top-5: 90.4900
2022-11-21 05:20:53,343 - mmcls - INFO - Epoch [116][100/391]	lr: 5.487e-02, eta: 0:39:57, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3939
2022-11-21 05:21:02,036 - mmcls - INFO - Epoch [116][200/391]	lr: 5.475e-02, eta: 0:39:51, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.4001
2022-11-21 05:21:10,829 - mmcls - INFO - Epoch [116][300/391]	lr: 5.464e-02, eta: 0:39:45, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5059
2022-11-21 05:21:20,723 - mmcls - INFO - Epoch(val) [116][79]	train_accuracy: 69.8940, accuracy_top-1: 65.8500, accuracy_top-5: 89.7300
2022-11-21 05:21:31,520 - mmcls - INFO - Epoch [117][100/391]	lr: 5.442e-02, eta: 0:39:29, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.3352
2022-11-21 05:21:40,241 - mmcls - INFO - Epoch [117][200/391]	lr: 5.430e-02, eta: 0:39:23, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.5106
2022-11-21 05:21:48,945 - mmcls - INFO - Epoch [117][300/391]	lr: 5.418e-02, eta: 0:39:16, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.3542
2022-11-21 05:21:58,740 - mmcls - INFO - Epoch(val) [117][79]	train_accuracy: 71.6340, accuracy_top-1: 68.6900, accuracy_top-5: 91.1800
2022-11-21 05:22:09,364 - mmcls - INFO - Epoch [118][100/391]	lr: 5.396e-02, eta: 0:39:00, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3288
2022-11-21 05:22:18,169 - mmcls - INFO - Epoch [118][200/391]	lr: 5.384e-02, eta: 0:38:54, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4463
2022-11-21 05:22:27,002 - mmcls - INFO - Epoch [118][300/391]	lr: 5.373e-02, eta: 0:38:48, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5093
2022-11-21 05:22:36,855 - mmcls - INFO - Epoch(val) [118][79]	train_accuracy: 70.3160, accuracy_top-1: 66.6000, accuracy_top-5: 90.0200
2022-11-21 05:22:47,593 - mmcls - INFO - Epoch [119][100/391]	lr: 5.350e-02, eta: 0:38:32, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.3225
2022-11-21 05:22:56,426 - mmcls - INFO - Epoch [119][200/391]	lr: 5.339e-02, eta: 0:38:26, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3273
2022-11-21 05:23:05,234 - mmcls - INFO - Epoch [119][300/391]	lr: 5.327e-02, eta: 0:38:20, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2885
2022-11-21 05:23:15,053 - mmcls - INFO - Epoch(val) [119][79]	train_accuracy: 71.7640, accuracy_top-1: 67.3300, accuracy_top-5: 90.9400
2022-11-21 05:23:25,707 - mmcls - INFO - Epoch [120][100/391]	lr: 5.305e-02, eta: 0:38:04, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.2547
2022-11-21 05:23:34,447 - mmcls - INFO - Epoch [120][200/391]	lr: 5.293e-02, eta: 0:37:57, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.5976
2022-11-21 05:23:43,105 - mmcls - INFO - Epoch [120][300/391]	lr: 5.281e-02, eta: 0:37:51, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.3590
2022-11-21 05:23:50,870 - mmcls - INFO - Saving checkpoint at 120 epochs
2022-11-21 05:23:52,889 - mmcls - INFO - Epoch(val) [120][79]	train_accuracy: 70.3820, accuracy_top-1: 69.9100, accuracy_top-5: 91.5800
2022-11-21 05:24:03,426 - mmcls - INFO - Epoch [121][100/391]	lr: 5.259e-02, eta: 0:37:35, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.3506
2022-11-21 05:24:12,330 - mmcls - INFO - Epoch [121][200/391]	lr: 5.247e-02, eta: 0:37:29, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4134
2022-11-21 05:24:21,233 - mmcls - INFO - Epoch [121][300/391]	lr: 5.235e-02, eta: 0:37:23, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3654
2022-11-21 05:24:31,155 - mmcls - INFO - Epoch(val) [121][79]	train_accuracy: 70.6080, accuracy_top-1: 66.9100, accuracy_top-5: 89.7000
2022-11-21 05:24:41,783 - mmcls - INFO - Epoch [122][100/391]	lr: 5.212e-02, eta: 0:37:07, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3458
2022-11-21 05:24:50,628 - mmcls - INFO - Epoch [122][200/391]	lr: 5.201e-02, eta: 0:37:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3239
2022-11-21 05:24:59,461 - mmcls - INFO - Epoch [122][300/391]	lr: 5.189e-02, eta: 0:36:55, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3633
2022-11-21 05:25:09,342 - mmcls - INFO - Epoch(val) [122][79]	train_accuracy: 72.6180, accuracy_top-1: 66.9800, accuracy_top-5: 90.3300
2022-11-21 05:25:20,084 - mmcls - INFO - Epoch [123][100/391]	lr: 5.166e-02, eta: 0:36:39, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.3492
2022-11-21 05:25:28,976 - mmcls - INFO - Epoch [123][200/391]	lr: 5.154e-02, eta: 0:36:33, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4058
2022-11-21 05:25:37,884 - mmcls - INFO - Epoch [123][300/391]	lr: 5.142e-02, eta: 0:36:26, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3551
2022-11-21 05:25:47,838 - mmcls - INFO - Epoch(val) [123][79]	train_accuracy: 70.8540, accuracy_top-1: 68.3900, accuracy_top-5: 91.2500
2022-11-21 05:25:58,376 - mmcls - INFO - Epoch [124][100/391]	lr: 5.120e-02, eta: 0:36:10, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.1995
2022-11-21 05:26:07,196 - mmcls - INFO - Epoch [124][200/391]	lr: 5.108e-02, eta: 0:36:04, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1970
2022-11-21 05:26:16,050 - mmcls - INFO - Epoch [124][300/391]	lr: 5.096e-02, eta: 0:35:58, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3568
2022-11-21 05:26:25,936 - mmcls - INFO - Epoch(val) [124][79]	train_accuracy: 72.0640, accuracy_top-1: 68.1100, accuracy_top-5: 91.0400
2022-11-21 05:26:36,712 - mmcls - INFO - Epoch [125][100/391]	lr: 5.073e-02, eta: 0:35:42, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.3028
2022-11-21 05:26:45,567 - mmcls - INFO - Epoch [125][200/391]	lr: 5.061e-02, eta: 0:35:36, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4575
2022-11-21 05:26:54,448 - mmcls - INFO - Epoch [125][300/391]	lr: 5.049e-02, eta: 0:35:30, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3541
2022-11-21 05:27:04,344 - mmcls - INFO - Epoch(val) [125][79]	train_accuracy: 72.1240, accuracy_top-1: 67.1200, accuracy_top-5: 90.3700
2022-11-21 05:27:15,029 - mmcls - INFO - Epoch [126][100/391]	lr: 5.026e-02, eta: 0:35:14, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.4071
2022-11-21 05:27:23,713 - mmcls - INFO - Epoch [126][200/391]	lr: 5.014e-02, eta: 0:35:08, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.3528
2022-11-21 05:27:32,475 - mmcls - INFO - Epoch [126][300/391]	lr: 5.002e-02, eta: 0:35:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2936
2022-11-21 05:27:42,216 - mmcls - INFO - Epoch(val) [126][79]	train_accuracy: 71.7220, accuracy_top-1: 68.6300, accuracy_top-5: 91.3700
2022-11-21 05:27:52,769 - mmcls - INFO - Epoch [127][100/391]	lr: 4.979e-02, eta: 0:34:46, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.3604
2022-11-21 05:28:01,484 - mmcls - INFO - Epoch [127][200/391]	lr: 4.967e-02, eta: 0:34:39, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2768
2022-11-21 05:28:10,380 - mmcls - INFO - Epoch [127][300/391]	lr: 4.955e-02, eta: 0:34:33, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4294
2022-11-21 05:28:20,328 - mmcls - INFO - Epoch(val) [127][79]	train_accuracy: 71.9140, accuracy_top-1: 68.3500, accuracy_top-5: 91.3700
2022-11-21 05:28:31,080 - mmcls - INFO - Epoch [128][100/391]	lr: 4.932e-02, eta: 0:34:17, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.1334
2022-11-21 05:28:39,797 - mmcls - INFO - Epoch [128][200/391]	lr: 4.920e-02, eta: 0:34:11, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2450
2022-11-21 05:28:48,606 - mmcls - INFO - Epoch [128][300/391]	lr: 4.907e-02, eta: 0:34:05, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3752
2022-11-21 05:28:58,458 - mmcls - INFO - Epoch(val) [128][79]	train_accuracy: 75.0240, accuracy_top-1: 64.3800, accuracy_top-5: 88.5500
2022-11-21 05:29:09,249 - mmcls - INFO - Epoch [129][100/391]	lr: 4.884e-02, eta: 0:33:49, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.2900
2022-11-21 05:29:18,071 - mmcls - INFO - Epoch [129][200/391]	lr: 4.872e-02, eta: 0:33:43, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2041
2022-11-21 05:29:26,864 - mmcls - INFO - Epoch [129][300/391]	lr: 4.860e-02, eta: 0:33:36, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5059
2022-11-21 05:29:36,674 - mmcls - INFO - Epoch(val) [129][79]	train_accuracy: 72.3540, accuracy_top-1: 68.4400, accuracy_top-5: 91.4600
2022-11-21 05:29:47,214 - mmcls - INFO - Epoch [130][100/391]	lr: 4.837e-02, eta: 0:33:21, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.1688
2022-11-21 05:29:55,858 - mmcls - INFO - Epoch [130][200/391]	lr: 4.824e-02, eta: 0:33:14, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.4634
2022-11-21 05:30:04,608 - mmcls - INFO - Epoch [130][300/391]	lr: 4.812e-02, eta: 0:33:08, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.3658
2022-11-21 05:30:12,560 - mmcls - INFO - Saving checkpoint at 130 epochs
2022-11-21 05:30:14,544 - mmcls - INFO - Epoch(val) [130][79]	train_accuracy: 72.7700, accuracy_top-1: 66.7400, accuracy_top-5: 90.3600
2022-11-21 05:30:25,215 - mmcls - INFO - Epoch [131][100/391]	lr: 4.789e-02, eta: 0:32:52, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3657
2022-11-21 05:30:34,031 - mmcls - INFO - Epoch [131][200/391]	lr: 4.776e-02, eta: 0:32:46, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1832
2022-11-21 05:30:42,872 - mmcls - INFO - Epoch [131][300/391]	lr: 4.764e-02, eta: 0:32:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.5345
2022-11-21 05:30:52,786 - mmcls - INFO - Epoch(val) [131][79]	train_accuracy: 71.8840, accuracy_top-1: 70.1100, accuracy_top-5: 91.6100
2022-11-21 05:31:03,630 - mmcls - INFO - Epoch [132][100/391]	lr: 4.741e-02, eta: 0:32:24, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.4691
2022-11-21 05:31:12,312 - mmcls - INFO - Epoch [132][200/391]	lr: 4.728e-02, eta: 0:32:18, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.4039
2022-11-21 05:31:21,081 - mmcls - INFO - Epoch [132][300/391]	lr: 4.716e-02, eta: 0:32:11, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4288
2022-11-21 05:31:30,887 - mmcls - INFO - Epoch(val) [132][79]	train_accuracy: 70.4940, accuracy_top-1: 68.9800, accuracy_top-5: 91.2100
2022-11-21 05:31:41,662 - mmcls - INFO - Epoch [133][100/391]	lr: 4.692e-02, eta: 0:31:56, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.2741
2022-11-21 05:31:50,596 - mmcls - INFO - Epoch [133][200/391]	lr: 4.680e-02, eta: 0:31:49, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2875
2022-11-21 05:31:59,516 - mmcls - INFO - Epoch [133][300/391]	lr: 4.668e-02, eta: 0:31:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2619
2022-11-21 05:32:09,374 - mmcls - INFO - Epoch(val) [133][79]	train_accuracy: 73.8300, accuracy_top-1: 68.5500, accuracy_top-5: 90.7400
2022-11-21 05:32:20,125 - mmcls - INFO - Epoch [134][100/391]	lr: 4.644e-02, eta: 0:31:28, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.3325
2022-11-21 05:32:29,031 - mmcls - INFO - Epoch [134][200/391]	lr: 4.631e-02, eta: 0:31:21, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.4076
2022-11-21 05:32:37,800 - mmcls - INFO - Epoch [134][300/391]	lr: 4.619e-02, eta: 0:31:15, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2691
2022-11-21 05:32:47,638 - mmcls - INFO - Epoch(val) [134][79]	train_accuracy: 71.9420, accuracy_top-1: 66.1200, accuracy_top-5: 89.5500
2022-11-21 05:32:58,202 - mmcls - INFO - Epoch [135][100/391]	lr: 4.595e-02, eta: 0:30:59, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.1817
2022-11-21 05:33:06,907 - mmcls - INFO - Epoch [135][200/391]	lr: 4.583e-02, eta: 0:30:53, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2558
2022-11-21 05:33:15,701 - mmcls - INFO - Epoch [135][300/391]	lr: 4.570e-02, eta: 0:30:46, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2226
2022-11-21 05:33:25,562 - mmcls - INFO - Epoch(val) [135][79]	train_accuracy: 74.2520, accuracy_top-1: 69.6200, accuracy_top-5: 91.8400
2022-11-21 05:33:36,133 - mmcls - INFO - Epoch [136][100/391]	lr: 4.546e-02, eta: 0:30:31, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.2150
2022-11-21 05:33:44,896 - mmcls - INFO - Epoch [136][200/391]	lr: 4.534e-02, eta: 0:30:24, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3433
2022-11-21 05:33:53,433 - mmcls - INFO - Epoch [136][300/391]	lr: 4.521e-02, eta: 0:30:18, time: 0.085, data_time: 0.001, memory: 1669, loss: 1.1361
2022-11-21 05:34:03,133 - mmcls - INFO - Epoch(val) [136][79]	train_accuracy: 75.6800, accuracy_top-1: 71.4200, accuracy_top-5: 92.3600
2022-11-21 05:34:13,872 - mmcls - INFO - Epoch [137][100/391]	lr: 4.497e-02, eta: 0:30:02, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.1718
2022-11-21 05:34:22,562 - mmcls - INFO - Epoch [137][200/391]	lr: 4.484e-02, eta: 0:29:56, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.3975
2022-11-21 05:34:31,389 - mmcls - INFO - Epoch [137][300/391]	lr: 4.472e-02, eta: 0:29:49, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.4605
2022-11-21 05:34:41,224 - mmcls - INFO - Epoch(val) [137][79]	train_accuracy: 74.0820, accuracy_top-1: 71.8000, accuracy_top-5: 93.1100
2022-11-21 05:34:51,883 - mmcls - INFO - Epoch [138][100/391]	lr: 4.448e-02, eta: 0:29:34, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3020
2022-11-21 05:35:00,729 - mmcls - INFO - Epoch [138][200/391]	lr: 4.435e-02, eta: 0:29:28, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3549
2022-11-21 05:35:09,461 - mmcls - INFO - Epoch [138][300/391]	lr: 4.422e-02, eta: 0:29:21, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.3737
2022-11-21 05:35:19,275 - mmcls - INFO - Epoch(val) [138][79]	train_accuracy: 73.5640, accuracy_top-1: 70.3100, accuracy_top-5: 91.9100
2022-11-21 05:35:29,750 - mmcls - INFO - Epoch [139][100/391]	lr: 4.398e-02, eta: 0:29:06, time: 0.104, data_time: 0.021, memory: 1669, loss: 1.2259
2022-11-21 05:35:38,491 - mmcls - INFO - Epoch [139][200/391]	lr: 4.385e-02, eta: 0:28:59, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.1501
2022-11-21 05:35:47,122 - mmcls - INFO - Epoch [139][300/391]	lr: 4.373e-02, eta: 0:28:52, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.3772
2022-11-21 05:35:56,800 - mmcls - INFO - Epoch(val) [139][79]	train_accuracy: 75.1620, accuracy_top-1: 71.8300, accuracy_top-5: 92.7500
2022-11-21 05:36:07,405 - mmcls - INFO - Epoch [140][100/391]	lr: 4.348e-02, eta: 0:28:37, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.2342
2022-11-21 05:36:16,210 - mmcls - INFO - Epoch [140][200/391]	lr: 4.335e-02, eta: 0:28:31, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2441
2022-11-21 05:36:24,977 - mmcls - INFO - Epoch [140][300/391]	lr: 4.323e-02, eta: 0:28:24, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3384
2022-11-21 05:36:32,935 - mmcls - INFO - Saving checkpoint at 140 epochs
2022-11-21 05:36:34,891 - mmcls - INFO - Epoch(val) [140][79]	train_accuracy: 73.2460, accuracy_top-1: 71.1200, accuracy_top-5: 92.4000
2022-11-21 05:36:45,540 - mmcls - INFO - Epoch [141][100/391]	lr: 4.298e-02, eta: 0:28:09, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.2605
2022-11-21 05:36:54,183 - mmcls - INFO - Epoch [141][200/391]	lr: 4.285e-02, eta: 0:28:02, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.3538
2022-11-21 05:37:02,894 - mmcls - INFO - Epoch [141][300/391]	lr: 4.272e-02, eta: 0:27:56, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.4764
2022-11-21 05:37:12,787 - mmcls - INFO - Epoch(val) [141][79]	train_accuracy: 72.8200, accuracy_top-1: 68.2700, accuracy_top-5: 90.5900
2022-11-21 05:37:23,481 - mmcls - INFO - Epoch [142][100/391]	lr: 4.248e-02, eta: 0:27:41, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0594
2022-11-21 05:37:32,247 - mmcls - INFO - Epoch [142][200/391]	lr: 4.235e-02, eta: 0:27:34, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2037
2022-11-21 05:37:41,054 - mmcls - INFO - Epoch [142][300/391]	lr: 4.222e-02, eta: 0:27:27, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1984
2022-11-21 05:37:50,996 - mmcls - INFO - Epoch(val) [142][79]	train_accuracy: 75.8340, accuracy_top-1: 69.1100, accuracy_top-5: 91.2400
2022-11-21 05:38:01,600 - mmcls - INFO - Epoch [143][100/391]	lr: 4.197e-02, eta: 0:27:12, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0274
2022-11-21 05:38:10,419 - mmcls - INFO - Epoch [143][200/391]	lr: 4.184e-02, eta: 0:27:06, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3203
2022-11-21 05:38:19,164 - mmcls - INFO - Epoch [143][300/391]	lr: 4.171e-02, eta: 0:26:59, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.3070
2022-11-21 05:38:29,079 - mmcls - INFO - Epoch(val) [143][79]	train_accuracy: 75.1100, accuracy_top-1: 69.9300, accuracy_top-5: 91.7700
2022-11-21 05:38:39,849 - mmcls - INFO - Epoch [144][100/391]	lr: 4.146e-02, eta: 0:26:44, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.3533
2022-11-21 05:38:48,721 - mmcls - INFO - Epoch [144][200/391]	lr: 4.133e-02, eta: 0:26:37, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.3436
2022-11-21 05:38:57,578 - mmcls - INFO - Epoch [144][300/391]	lr: 4.120e-02, eta: 0:26:31, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1564
2022-11-21 05:39:07,490 - mmcls - INFO - Epoch(val) [144][79]	train_accuracy: 73.1240, accuracy_top-1: 70.4200, accuracy_top-5: 91.9400
2022-11-21 05:39:18,175 - mmcls - INFO - Epoch [145][100/391]	lr: 4.095e-02, eta: 0:26:16, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.2469
2022-11-21 05:39:27,004 - mmcls - INFO - Epoch [145][200/391]	lr: 4.082e-02, eta: 0:26:09, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2489
2022-11-21 05:39:35,818 - mmcls - INFO - Epoch [145][300/391]	lr: 4.069e-02, eta: 0:26:02, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2546
2022-11-21 05:39:45,669 - mmcls - INFO - Epoch(val) [145][79]	train_accuracy: 75.4740, accuracy_top-1: 68.0900, accuracy_top-5: 91.2000
2022-11-21 05:39:56,347 - mmcls - INFO - Epoch [146][100/391]	lr: 4.044e-02, eta: 0:25:47, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1080
2022-11-21 05:40:05,213 - mmcls - INFO - Epoch [146][200/391]	lr: 4.030e-02, eta: 0:25:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1597
2022-11-21 05:40:14,200 - mmcls - INFO - Epoch [146][300/391]	lr: 4.017e-02, eta: 0:25:34, time: 0.090, data_time: 0.001, memory: 1669, loss: 1.3571
2022-11-21 05:40:24,125 - mmcls - INFO - Epoch(val) [146][79]	train_accuracy: 75.9120, accuracy_top-1: 71.6400, accuracy_top-5: 92.5800
2022-11-21 05:40:34,918 - mmcls - INFO - Epoch [147][100/391]	lr: 3.992e-02, eta: 0:25:19, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.2005
2022-11-21 05:40:43,844 - mmcls - INFO - Epoch [147][200/391]	lr: 3.979e-02, eta: 0:25:13, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2631
2022-11-21 05:40:52,661 - mmcls - INFO - Epoch [147][300/391]	lr: 3.965e-02, eta: 0:25:06, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0914
2022-11-21 05:41:02,676 - mmcls - INFO - Epoch(val) [147][79]	train_accuracy: 75.5440, accuracy_top-1: 69.3800, accuracy_top-5: 90.9500
2022-11-21 05:41:13,516 - mmcls - INFO - Epoch [148][100/391]	lr: 3.940e-02, eta: 0:24:51, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.1881
2022-11-21 05:41:22,442 - mmcls - INFO - Epoch [148][200/391]	lr: 3.927e-02, eta: 0:24:44, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2007
2022-11-21 05:41:31,335 - mmcls - INFO - Epoch [148][300/391]	lr: 3.913e-02, eta: 0:24:38, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1732
2022-11-21 05:41:41,317 - mmcls - INFO - Epoch(val) [148][79]	train_accuracy: 76.7780, accuracy_top-1: 71.0000, accuracy_top-5: 92.1600
2022-11-21 05:41:51,951 - mmcls - INFO - Epoch [149][100/391]	lr: 3.888e-02, eta: 0:24:23, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.2609
2022-11-21 05:42:00,701 - mmcls - INFO - Epoch [149][200/391]	lr: 3.874e-02, eta: 0:24:16, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2768
2022-11-21 05:42:09,504 - mmcls - INFO - Epoch [149][300/391]	lr: 3.861e-02, eta: 0:24:09, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0231
2022-11-21 05:42:19,423 - mmcls - INFO - Epoch(val) [149][79]	train_accuracy: 75.8180, accuracy_top-1: 69.0100, accuracy_top-5: 91.3200
2022-11-21 05:42:30,188 - mmcls - INFO - Epoch [150][100/391]	lr: 3.835e-02, eta: 0:23:55, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.2804
2022-11-21 05:42:39,060 - mmcls - INFO - Epoch [150][200/391]	lr: 3.821e-02, eta: 0:23:48, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2089
2022-11-21 05:42:47,947 - mmcls - INFO - Epoch [150][300/391]	lr: 3.808e-02, eta: 0:23:41, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1792
2022-11-21 05:42:55,955 - mmcls - INFO - Saving checkpoint at 150 epochs
2022-11-21 05:42:57,934 - mmcls - INFO - Epoch(val) [150][79]	train_accuracy: 75.5460, accuracy_top-1: 71.7800, accuracy_top-5: 92.2600
2022-11-21 05:43:08,551 - mmcls - INFO - Epoch [151][100/391]	lr: 3.782e-02, eta: 0:23:26, time: 0.106, data_time: 0.020, memory: 1669, loss: 1.1405
2022-11-21 05:43:17,383 - mmcls - INFO - Epoch [151][200/391]	lr: 3.768e-02, eta: 0:23:20, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2053
2022-11-21 05:43:26,121 - mmcls - INFO - Epoch [151][300/391]	lr: 3.755e-02, eta: 0:23:13, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2739
2022-11-21 05:43:35,922 - mmcls - INFO - Epoch(val) [151][79]	train_accuracy: 76.2140, accuracy_top-1: 72.1300, accuracy_top-5: 92.8100
2022-11-21 05:43:46,427 - mmcls - INFO - Epoch [152][100/391]	lr: 3.729e-02, eta: 0:22:58, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.1145
2022-11-21 05:43:55,124 - mmcls - INFO - Epoch [152][200/391]	lr: 3.715e-02, eta: 0:22:51, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0947
2022-11-21 05:44:03,791 - mmcls - INFO - Epoch [152][300/391]	lr: 3.701e-02, eta: 0:22:44, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.4960
2022-11-21 05:44:13,754 - mmcls - INFO - Epoch(val) [152][79]	train_accuracy: 75.7700, accuracy_top-1: 71.9800, accuracy_top-5: 92.5700
2022-11-21 05:44:24,565 - mmcls - INFO - Epoch [153][100/391]	lr: 3.675e-02, eta: 0:22:30, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.1619
2022-11-21 05:44:33,373 - mmcls - INFO - Epoch [153][200/391]	lr: 3.662e-02, eta: 0:22:23, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3488
2022-11-21 05:44:42,147 - mmcls - INFO - Epoch [153][300/391]	lr: 3.648e-02, eta: 0:22:16, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.3732
2022-11-21 05:44:52,057 - mmcls - INFO - Epoch(val) [153][79]	train_accuracy: 75.3080, accuracy_top-1: 68.6200, accuracy_top-5: 91.1300
2022-11-21 05:45:02,697 - mmcls - INFO - Epoch [154][100/391]	lr: 3.621e-02, eta: 0:22:01, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3930
2022-11-21 05:45:11,440 - mmcls - INFO - Epoch [154][200/391]	lr: 3.608e-02, eta: 0:21:55, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2311
2022-11-21 05:45:20,218 - mmcls - INFO - Epoch [154][300/391]	lr: 3.594e-02, eta: 0:21:48, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0792
2022-11-21 05:45:30,032 - mmcls - INFO - Epoch(val) [154][79]	train_accuracy: 75.8100, accuracy_top-1: 71.9700, accuracy_top-5: 92.6200
2022-11-21 05:45:40,780 - mmcls - INFO - Epoch [155][100/391]	lr: 3.567e-02, eta: 0:21:33, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.1294
2022-11-21 05:45:49,719 - mmcls - INFO - Epoch [155][200/391]	lr: 3.553e-02, eta: 0:21:26, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9738
2022-11-21 05:45:58,625 - mmcls - INFO - Epoch [155][300/391]	lr: 3.539e-02, eta: 0:21:20, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.2276
2022-11-21 05:46:08,544 - mmcls - INFO - Epoch(val) [155][79]	train_accuracy: 79.4140, accuracy_top-1: 71.7800, accuracy_top-5: 92.1200
2022-11-21 05:46:19,299 - mmcls - INFO - Epoch [156][100/391]	lr: 3.512e-02, eta: 0:21:05, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9409
2022-11-21 05:46:28,125 - mmcls - INFO - Epoch [156][200/391]	lr: 3.498e-02, eta: 0:20:58, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2633
2022-11-21 05:46:36,930 - mmcls - INFO - Epoch [156][300/391]	lr: 3.484e-02, eta: 0:20:51, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0457
2022-11-21 05:46:46,814 - mmcls - INFO - Epoch(val) [156][79]	train_accuracy: 78.9340, accuracy_top-1: 73.1100, accuracy_top-5: 92.7600
2022-11-21 05:46:57,471 - mmcls - INFO - Epoch [157][100/391]	lr: 3.458e-02, eta: 0:20:37, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1509
2022-11-21 05:47:06,227 - mmcls - INFO - Epoch [157][200/391]	lr: 3.443e-02, eta: 0:20:30, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.2364
2022-11-21 05:47:14,946 - mmcls - INFO - Epoch [157][300/391]	lr: 3.429e-02, eta: 0:20:23, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2882
2022-11-21 05:47:24,679 - mmcls - INFO - Epoch(val) [157][79]	train_accuracy: 76.4440, accuracy_top-1: 72.2500, accuracy_top-5: 93.1600
2022-11-21 05:47:35,323 - mmcls - INFO - Epoch [158][100/391]	lr: 3.402e-02, eta: 0:20:08, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.3145
2022-11-21 05:47:43,949 - mmcls - INFO - Epoch [158][200/391]	lr: 3.388e-02, eta: 0:20:01, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.2531
2022-11-21 05:47:52,486 - mmcls - INFO - Epoch [158][300/391]	lr: 3.374e-02, eta: 0:19:54, time: 0.085, data_time: 0.001, memory: 1669, loss: 1.1619
2022-11-21 05:48:02,220 - mmcls - INFO - Epoch(val) [158][79]	train_accuracy: 76.7460, accuracy_top-1: 72.5300, accuracy_top-5: 92.5800
2022-11-21 05:48:12,922 - mmcls - INFO - Epoch [159][100/391]	lr: 3.346e-02, eta: 0:19:40, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.1243
2022-11-21 05:48:21,742 - mmcls - INFO - Epoch [159][200/391]	lr: 3.332e-02, eta: 0:19:33, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0288
2022-11-21 05:48:30,576 - mmcls - INFO - Epoch [159][300/391]	lr: 3.318e-02, eta: 0:19:26, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1108
2022-11-21 05:48:40,289 - mmcls - INFO - Epoch(val) [159][79]	train_accuracy: 79.2880, accuracy_top-1: 73.5700, accuracy_top-5: 93.1700
2022-11-21 05:48:50,843 - mmcls - INFO - Epoch [160][100/391]	lr: 3.290e-02, eta: 0:19:12, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.1061
2022-11-21 05:48:59,543 - mmcls - INFO - Epoch [160][200/391]	lr: 3.276e-02, eta: 0:19:05, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.1452
2022-11-21 05:49:08,348 - mmcls - INFO - Epoch [160][300/391]	lr: 3.261e-02, eta: 0:18:58, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0558
2022-11-21 05:49:16,216 - mmcls - INFO - Saving checkpoint at 160 epochs
2022-11-21 05:49:18,212 - mmcls - INFO - Epoch(val) [160][79]	train_accuracy: 78.3700, accuracy_top-1: 73.2300, accuracy_top-5: 92.8300
2022-11-21 05:49:28,835 - mmcls - INFO - Epoch [161][100/391]	lr: 3.234e-02, eta: 0:18:43, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0987
2022-11-21 05:49:37,634 - mmcls - INFO - Epoch [161][200/391]	lr: 3.219e-02, eta: 0:18:36, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0170
2022-11-21 05:49:46,449 - mmcls - INFO - Epoch [161][300/391]	lr: 3.205e-02, eta: 0:18:30, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1529
2022-11-21 05:49:56,197 - mmcls - INFO - Epoch(val) [161][79]	train_accuracy: 79.2500, accuracy_top-1: 72.3200, accuracy_top-5: 92.5900
2022-11-21 05:50:06,924 - mmcls - INFO - Epoch [162][100/391]	lr: 3.177e-02, eta: 0:18:15, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.2086
2022-11-21 05:50:15,651 - mmcls - INFO - Epoch [162][200/391]	lr: 3.162e-02, eta: 0:18:08, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2737
2022-11-21 05:50:24,431 - mmcls - INFO - Epoch [162][300/391]	lr: 3.147e-02, eta: 0:18:01, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1374
2022-11-21 05:50:34,260 - mmcls - INFO - Epoch(val) [162][79]	train_accuracy: 79.1260, accuracy_top-1: 73.5300, accuracy_top-5: 93.3700
2022-11-21 05:50:44,837 - mmcls - INFO - Epoch [163][100/391]	lr: 3.119e-02, eta: 0:17:47, time: 0.105, data_time: 0.021, memory: 1669, loss: 1.0463
2022-11-21 05:50:53,574 - mmcls - INFO - Epoch [163][200/391]	lr: 3.105e-02, eta: 0:17:40, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0559
2022-11-21 05:51:02,303 - mmcls - INFO - Epoch [163][300/391]	lr: 3.090e-02, eta: 0:17:33, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.2371
2022-11-21 05:51:12,103 - mmcls - INFO - Epoch(val) [163][79]	train_accuracy: 78.1400, accuracy_top-1: 73.4100, accuracy_top-5: 93.0600
2022-11-21 05:51:22,638 - mmcls - INFO - Epoch [164][100/391]	lr: 3.061e-02, eta: 0:17:18, time: 0.105, data_time: 0.021, memory: 1669, loss: 0.9787
2022-11-21 05:51:31,200 - mmcls - INFO - Epoch [164][200/391]	lr: 3.047e-02, eta: 0:17:11, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.1512
2022-11-21 05:51:39,770 - mmcls - INFO - Epoch [164][300/391]	lr: 3.032e-02, eta: 0:17:04, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.1502
2022-11-21 05:51:49,464 - mmcls - INFO - Epoch(val) [164][79]	train_accuracy: 79.2500, accuracy_top-1: 72.1900, accuracy_top-5: 92.8700
2022-11-21 05:52:00,260 - mmcls - INFO - Epoch [165][100/391]	lr: 3.003e-02, eta: 0:16:50, time: 0.108, data_time: 0.021, memory: 1669, loss: 1.2272
2022-11-21 05:52:09,073 - mmcls - INFO - Epoch [165][200/391]	lr: 2.988e-02, eta: 0:16:43, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0696
2022-11-21 05:52:17,917 - mmcls - INFO - Epoch [165][300/391]	lr: 2.973e-02, eta: 0:16:36, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1212
2022-11-21 05:52:27,766 - mmcls - INFO - Epoch(val) [165][79]	train_accuracy: 77.5080, accuracy_top-1: 73.6100, accuracy_top-5: 93.1800
2022-11-21 05:52:38,353 - mmcls - INFO - Epoch [166][100/391]	lr: 2.944e-02, eta: 0:16:22, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1444
2022-11-21 05:52:47,120 - mmcls - INFO - Epoch [166][200/391]	lr: 2.929e-02, eta: 0:16:15, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9938
2022-11-21 05:52:55,856 - mmcls - INFO - Epoch [166][300/391]	lr: 2.914e-02, eta: 0:16:08, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0595
2022-11-21 05:53:05,639 - mmcls - INFO - Epoch(val) [166][79]	train_accuracy: 79.8020, accuracy_top-1: 72.9400, accuracy_top-5: 93.4100
2022-11-21 05:53:16,319 - mmcls - INFO - Epoch [167][100/391]	lr: 2.885e-02, eta: 0:15:53, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0238
2022-11-21 05:53:25,006 - mmcls - INFO - Epoch [167][200/391]	lr: 2.870e-02, eta: 0:15:46, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9880
2022-11-21 05:53:33,694 - mmcls - INFO - Epoch [167][300/391]	lr: 2.854e-02, eta: 0:15:39, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0590
2022-11-21 05:53:43,471 - mmcls - INFO - Epoch(val) [167][79]	train_accuracy: 80.6180, accuracy_top-1: 72.7600, accuracy_top-5: 92.8000
2022-11-21 05:53:54,250 - mmcls - INFO - Epoch [168][100/391]	lr: 2.825e-02, eta: 0:15:25, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.2044
2022-11-21 05:54:03,112 - mmcls - INFO - Epoch [168][200/391]	lr: 2.809e-02, eta: 0:15:18, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9446
2022-11-21 05:54:11,924 - mmcls - INFO - Epoch [168][300/391]	lr: 2.794e-02, eta: 0:15:11, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9542
2022-11-21 05:54:21,866 - mmcls - INFO - Epoch(val) [168][79]	train_accuracy: 80.0020, accuracy_top-1: 73.0100, accuracy_top-5: 93.0300
2022-11-21 05:54:32,567 - mmcls - INFO - Epoch [169][100/391]	lr: 2.764e-02, eta: 0:14:57, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9786
2022-11-21 05:54:41,419 - mmcls - INFO - Epoch [169][200/391]	lr: 2.749e-02, eta: 0:14:50, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1760
2022-11-21 05:54:50,327 - mmcls - INFO - Epoch [169][300/391]	lr: 2.733e-02, eta: 0:14:43, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1307
2022-11-21 05:55:00,218 - mmcls - INFO - Epoch(val) [169][79]	train_accuracy: 79.4900, accuracy_top-1: 74.3400, accuracy_top-5: 93.7000
2022-11-21 05:55:10,841 - mmcls - INFO - Epoch [170][100/391]	lr: 2.703e-02, eta: 0:14:29, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.8383
2022-11-21 05:55:19,577 - mmcls - INFO - Epoch [170][200/391]	lr: 2.688e-02, eta: 0:14:22, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0741
2022-11-21 05:55:28,321 - mmcls - INFO - Epoch [170][300/391]	lr: 2.672e-02, eta: 0:14:15, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0713
2022-11-21 05:55:36,233 - mmcls - INFO - Saving checkpoint at 170 epochs
2022-11-21 05:55:38,214 - mmcls - INFO - Epoch(val) [170][79]	train_accuracy: 81.9200, accuracy_top-1: 73.3500, accuracy_top-5: 93.1200
2022-11-21 05:55:48,748 - mmcls - INFO - Epoch [171][100/391]	lr: 2.642e-02, eta: 0:14:00, time: 0.105, data_time: 0.021, memory: 1669, loss: 0.9456
2022-11-21 05:55:57,348 - mmcls - INFO - Epoch [171][200/391]	lr: 2.626e-02, eta: 0:13:53, time: 0.086, data_time: 0.001, memory: 1669, loss: 1.1850
2022-11-21 05:56:06,138 - mmcls - INFO - Epoch [171][300/391]	lr: 2.610e-02, eta: 0:13:46, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1034
2022-11-21 05:56:16,140 - mmcls - INFO - Epoch(val) [171][79]	train_accuracy: 80.8240, accuracy_top-1: 74.3700, accuracy_top-5: 93.7300
2022-11-21 05:56:26,884 - mmcls - INFO - Epoch [172][100/391]	lr: 2.580e-02, eta: 0:13:32, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.1840
2022-11-21 05:56:35,725 - mmcls - INFO - Epoch [172][200/391]	lr: 2.564e-02, eta: 0:13:25, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0155
2022-11-21 05:56:44,524 - mmcls - INFO - Epoch [172][300/391]	lr: 2.547e-02, eta: 0:13:18, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8965
2022-11-21 05:56:54,391 - mmcls - INFO - Epoch(val) [172][79]	train_accuracy: 81.8360, accuracy_top-1: 74.3000, accuracy_top-5: 93.3400
2022-11-21 05:57:05,020 - mmcls - INFO - Epoch [173][100/391]	lr: 2.517e-02, eta: 0:13:04, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.9403
2022-11-21 05:57:13,910 - mmcls - INFO - Epoch [173][200/391]	lr: 2.500e-02, eta: 0:12:57, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1796
2022-11-21 05:57:22,627 - mmcls - INFO - Epoch [173][300/391]	lr: 2.484e-02, eta: 0:12:50, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9324
2022-11-21 05:57:32,495 - mmcls - INFO - Epoch(val) [173][79]	train_accuracy: 81.5280, accuracy_top-1: 72.4900, accuracy_top-5: 92.7000
2022-11-21 05:57:43,018 - mmcls - INFO - Epoch [174][100/391]	lr: 2.453e-02, eta: 0:12:35, time: 0.105, data_time: 0.021, memory: 1669, loss: 0.8937
2022-11-21 05:57:51,680 - mmcls - INFO - Epoch [174][200/391]	lr: 2.437e-02, eta: 0:12:28, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0001
2022-11-21 05:58:00,392 - mmcls - INFO - Epoch [174][300/391]	lr: 2.420e-02, eta: 0:12:21, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9129
2022-11-21 05:58:10,200 - mmcls - INFO - Epoch(val) [174][79]	train_accuracy: 82.5500, accuracy_top-1: 75.3900, accuracy_top-5: 93.6900
2022-11-21 05:58:20,941 - mmcls - INFO - Epoch [175][100/391]	lr: 2.389e-02, eta: 0:12:07, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9081
2022-11-21 05:58:29,770 - mmcls - INFO - Epoch [175][200/391]	lr: 2.372e-02, eta: 0:12:00, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0572
2022-11-21 05:58:38,604 - mmcls - INFO - Epoch [175][300/391]	lr: 2.356e-02, eta: 0:11:53, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1935
2022-11-21 05:58:48,470 - mmcls - INFO - Epoch(val) [175][79]	train_accuracy: 81.1400, accuracy_top-1: 74.8400, accuracy_top-5: 93.6500
2022-11-21 05:58:59,240 - mmcls - INFO - Epoch [176][100/391]	lr: 2.324e-02, eta: 0:11:39, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9563
2022-11-21 05:59:07,976 - mmcls - INFO - Epoch [176][200/391]	lr: 2.307e-02, eta: 0:11:32, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0325
2022-11-21 05:59:16,802 - mmcls - INFO - Epoch [176][300/391]	lr: 2.290e-02, eta: 0:11:25, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0163
2022-11-21 05:59:26,585 - mmcls - INFO - Epoch(val) [176][79]	train_accuracy: 82.2620, accuracy_top-1: 74.8700, accuracy_top-5: 93.7500
2022-11-21 05:59:37,220 - mmcls - INFO - Epoch [177][100/391]	lr: 2.258e-02, eta: 0:11:11, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1443
2022-11-21 05:59:45,929 - mmcls - INFO - Epoch [177][200/391]	lr: 2.241e-02, eta: 0:11:04, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.8437
2022-11-21 05:59:54,638 - mmcls - INFO - Epoch [177][300/391]	lr: 2.224e-02, eta: 0:10:57, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.1116
2022-11-21 06:00:04,440 - mmcls - INFO - Epoch(val) [177][79]	train_accuracy: 81.6960, accuracy_top-1: 75.4300, accuracy_top-5: 93.7700
2022-11-21 06:00:15,163 - mmcls - INFO - Epoch [178][100/391]	lr: 2.191e-02, eta: 0:10:42, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0454
2022-11-21 06:00:24,103 - mmcls - INFO - Epoch [178][200/391]	lr: 2.174e-02, eta: 0:10:35, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9565
2022-11-21 06:00:32,952 - mmcls - INFO - Epoch [178][300/391]	lr: 2.157e-02, eta: 0:10:28, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.1564
2022-11-21 06:00:42,802 - mmcls - INFO - Epoch(val) [178][79]	train_accuracy: 81.3440, accuracy_top-1: 76.1500, accuracy_top-5: 94.0600
2022-11-21 06:00:53,407 - mmcls - INFO - Epoch [179][100/391]	lr: 2.124e-02, eta: 0:10:14, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0284
2022-11-21 06:01:02,139 - mmcls - INFO - Epoch [179][200/391]	lr: 2.106e-02, eta: 0:10:07, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9387
2022-11-21 06:01:11,000 - mmcls - INFO - Epoch [179][300/391]	lr: 2.089e-02, eta: 0:10:00, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9789
2022-11-21 06:01:20,904 - mmcls - INFO - Epoch(val) [179][79]	train_accuracy: 82.4980, accuracy_top-1: 75.7700, accuracy_top-5: 94.0400
2022-11-21 06:01:31,564 - mmcls - INFO - Epoch [180][100/391]	lr: 2.055e-02, eta: 0:09:46, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.1058
2022-11-21 06:01:40,365 - mmcls - INFO - Epoch [180][200/391]	lr: 2.037e-02, eta: 0:09:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9909
2022-11-21 06:01:49,100 - mmcls - INFO - Epoch [180][300/391]	lr: 2.020e-02, eta: 0:09:32, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9692
2022-11-21 06:01:57,043 - mmcls - INFO - Saving checkpoint at 180 epochs
2022-11-21 06:01:59,096 - mmcls - INFO - Epoch(val) [180][79]	train_accuracy: 81.8320, accuracy_top-1: 75.9400, accuracy_top-5: 94.0400
2022-11-21 06:02:09,783 - mmcls - INFO - Epoch [181][100/391]	lr: 1.986e-02, eta: 0:09:18, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9707
2022-11-21 06:02:18,517 - mmcls - INFO - Epoch [181][200/391]	lr: 1.968e-02, eta: 0:09:10, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0718
2022-11-21 06:02:27,282 - mmcls - INFO - Epoch [181][300/391]	lr: 1.950e-02, eta: 0:09:03, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0406
2022-11-21 06:02:37,160 - mmcls - INFO - Epoch(val) [181][79]	train_accuracy: 82.3660, accuracy_top-1: 76.1800, accuracy_top-5: 94.1300
2022-11-21 06:02:47,771 - mmcls - INFO - Epoch [182][100/391]	lr: 1.915e-02, eta: 0:08:49, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.8756
2022-11-21 06:02:56,700 - mmcls - INFO - Epoch [182][200/391]	lr: 1.897e-02, eta: 0:08:42, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9368
2022-11-21 06:03:05,516 - mmcls - INFO - Epoch [182][300/391]	lr: 1.878e-02, eta: 0:08:35, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.0117
2022-11-21 06:03:15,343 - mmcls - INFO - Epoch(val) [182][79]	train_accuracy: 84.4420, accuracy_top-1: 75.6900, accuracy_top-5: 94.1400
2022-11-21 06:03:25,989 - mmcls - INFO - Epoch [183][100/391]	lr: 1.843e-02, eta: 0:08:21, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0167
2022-11-21 06:03:34,763 - mmcls - INFO - Epoch [183][200/391]	lr: 1.825e-02, eta: 0:08:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1247
2022-11-21 06:03:43,621 - mmcls - INFO - Epoch [183][300/391]	lr: 1.806e-02, eta: 0:08:07, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9578
2022-11-21 06:03:53,575 - mmcls - INFO - Epoch(val) [183][79]	train_accuracy: 83.1320, accuracy_top-1: 76.9000, accuracy_top-5: 94.3400
2022-11-21 06:04:04,341 - mmcls - INFO - Epoch [184][100/391]	lr: 1.770e-02, eta: 0:07:53, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.7840
2022-11-21 06:04:13,147 - mmcls - INFO - Epoch [184][200/391]	lr: 1.751e-02, eta: 0:07:46, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8273
2022-11-21 06:04:21,967 - mmcls - INFO - Epoch [184][300/391]	lr: 1.733e-02, eta: 0:07:39, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8863
2022-11-21 06:04:31,870 - mmcls - INFO - Epoch(val) [184][79]	train_accuracy: 84.8360, accuracy_top-1: 77.2100, accuracy_top-5: 94.6400
2022-11-21 06:04:42,561 - mmcls - INFO - Epoch [185][100/391]	lr: 1.696e-02, eta: 0:07:24, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.7760
2022-11-21 06:04:51,263 - mmcls - INFO - Epoch [185][200/391]	lr: 1.677e-02, eta: 0:07:17, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0575
2022-11-21 06:05:00,019 - mmcls - INFO - Epoch [185][300/391]	lr: 1.658e-02, eta: 0:07:10, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1499
2022-11-21 06:05:09,962 - mmcls - INFO - Epoch(val) [185][79]	train_accuracy: 83.3540, accuracy_top-1: 77.2300, accuracy_top-5: 94.5800
2022-11-21 06:05:20,700 - mmcls - INFO - Epoch [186][100/391]	lr: 1.620e-02, eta: 0:06:56, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9491
2022-11-21 06:05:29,515 - mmcls - INFO - Epoch [186][200/391]	lr: 1.601e-02, eta: 0:06:49, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9306
2022-11-21 06:05:38,341 - mmcls - INFO - Epoch [186][300/391]	lr: 1.581e-02, eta: 0:06:42, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1564
2022-11-21 06:05:48,121 - mmcls - INFO - Epoch(val) [186][79]	train_accuracy: 82.6340, accuracy_top-1: 77.5800, accuracy_top-5: 94.8500
2022-11-21 06:05:58,651 - mmcls - INFO - Epoch [187][100/391]	lr: 1.543e-02, eta: 0:06:28, time: 0.105, data_time: 0.021, memory: 1669, loss: 0.8935
2022-11-21 06:06:07,399 - mmcls - INFO - Epoch [187][200/391]	lr: 1.523e-02, eta: 0:06:21, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0081
2022-11-21 06:06:16,163 - mmcls - INFO - Epoch [187][300/391]	lr: 1.503e-02, eta: 0:06:14, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8995
2022-11-21 06:06:26,056 - mmcls - INFO - Epoch(val) [187][79]	train_accuracy: 84.2340, accuracy_top-1: 77.5300, accuracy_top-5: 94.9400
2022-11-21 06:06:36,697 - mmcls - INFO - Epoch [188][100/391]	lr: 1.464e-02, eta: 0:06:00, time: 0.106, data_time: 0.021, memory: 1669, loss: 1.0123
2022-11-21 06:06:45,616 - mmcls - INFO - Epoch [188][200/391]	lr: 1.444e-02, eta: 0:05:53, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8843
2022-11-21 06:06:54,474 - mmcls - INFO - Epoch [188][300/391]	lr: 1.423e-02, eta: 0:05:45, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0212
2022-11-21 06:07:04,401 - mmcls - INFO - Epoch(val) [188][79]	train_accuracy: 83.5520, accuracy_top-1: 78.1600, accuracy_top-5: 95.0000
2022-11-21 06:07:15,096 - mmcls - INFO - Epoch [189][100/391]	lr: 1.383e-02, eta: 0:05:31, time: 0.107, data_time: 0.021, memory: 1669, loss: 1.0474
2022-11-21 06:07:23,812 - mmcls - INFO - Epoch [189][200/391]	lr: 1.362e-02, eta: 0:05:24, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9514
2022-11-21 06:07:32,552 - mmcls - INFO - Epoch [189][300/391]	lr: 1.341e-02, eta: 0:05:17, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0326
2022-11-21 06:07:42,500 - mmcls - INFO - Epoch(val) [189][79]	train_accuracy: 83.3380, accuracy_top-1: 79.0200, accuracy_top-5: 94.8700
2022-11-21 06:07:53,177 - mmcls - INFO - Epoch [190][100/391]	lr: 1.300e-02, eta: 0:05:03, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.8707
2022-11-21 06:08:01,807 - mmcls - INFO - Epoch [190][200/391]	lr: 1.279e-02, eta: 0:04:56, time: 0.086, data_time: 0.001, memory: 1669, loss: 0.8782
2022-11-21 06:08:10,714 - mmcls - INFO - Epoch [190][300/391]	lr: 1.257e-02, eta: 0:04:49, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8443
2022-11-21 06:08:18,764 - mmcls - INFO - Saving checkpoint at 190 epochs
2022-11-21 06:08:20,723 - mmcls - INFO - Epoch(val) [190][79]	train_accuracy: 85.5140, accuracy_top-1: 77.5900, accuracy_top-5: 94.7800
2022-11-21 06:08:31,435 - mmcls - INFO - Epoch [191][100/391]	lr: 1.215e-02, eta: 0:04:35, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9597
2022-11-21 06:08:40,313 - mmcls - INFO - Epoch [191][200/391]	lr: 1.193e-02, eta: 0:04:28, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0303
2022-11-21 06:08:49,137 - mmcls - INFO - Epoch [191][300/391]	lr: 1.171e-02, eta: 0:04:21, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7463
2022-11-21 06:08:58,987 - mmcls - INFO - Epoch(val) [191][79]	train_accuracy: 85.4200, accuracy_top-1: 78.7200, accuracy_top-5: 95.0500
2022-11-21 06:09:09,686 - mmcls - INFO - Epoch [192][100/391]	lr: 1.127e-02, eta: 0:04:07, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.9717
2022-11-21 06:09:18,459 - mmcls - INFO - Epoch [192][200/391]	lr: 1.104e-02, eta: 0:03:59, time: 0.088, data_time: 0.001, memory: 1669, loss: 1.1004
2022-11-21 06:09:27,232 - mmcls - INFO - Epoch [192][300/391]	lr: 1.081e-02, eta: 0:03:52, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9541
2022-11-21 06:09:37,075 - mmcls - INFO - Epoch(val) [192][79]	train_accuracy: 84.1920, accuracy_top-1: 78.5700, accuracy_top-5: 95.0400
2022-11-21 06:09:47,955 - mmcls - INFO - Epoch [193][100/391]	lr: 1.036e-02, eta: 0:03:38, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.9542
2022-11-21 06:09:56,879 - mmcls - INFO - Epoch [193][200/391]	lr: 1.012e-02, eta: 0:03:31, time: 0.089, data_time: 0.001, memory: 1669, loss: 1.0199
2022-11-21 06:10:05,835 - mmcls - INFO - Epoch [193][300/391]	lr: 9.883e-03, eta: 0:03:24, time: 0.090, data_time: 0.001, memory: 1669, loss: 0.7699
2022-11-21 06:10:15,769 - mmcls - INFO - Epoch(val) [193][79]	train_accuracy: 85.6060, accuracy_top-1: 79.6000, accuracy_top-5: 95.4000
2022-11-21 06:10:26,456 - mmcls - INFO - Epoch [194][100/391]	lr: 9.416e-03, eta: 0:03:10, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.7759
2022-11-21 06:10:35,332 - mmcls - INFO - Epoch [194][200/391]	lr: 9.167e-03, eta: 0:03:03, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9566
2022-11-21 06:10:44,165 - mmcls - INFO - Epoch [194][300/391]	lr: 8.915e-03, eta: 0:02:56, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.8023
2022-11-21 06:10:54,106 - mmcls - INFO - Epoch(val) [194][79]	train_accuracy: 86.9920, accuracy_top-1: 79.7400, accuracy_top-5: 95.1700
2022-11-21 06:11:04,894 - mmcls - INFO - Epoch [195][100/391]	lr: 8.426e-03, eta: 0:02:42, time: 0.108, data_time: 0.021, memory: 1669, loss: 0.8601
2022-11-21 06:11:13,629 - mmcls - INFO - Epoch [195][200/391]	lr: 8.165e-03, eta: 0:02:35, time: 0.087, data_time: 0.001, memory: 1669, loss: 1.0617
2022-11-21 06:11:22,426 - mmcls - INFO - Epoch [195][300/391]	lr: 7.900e-03, eta: 0:02:27, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7199
2022-11-21 06:11:32,293 - mmcls - INFO - Epoch(val) [195][79]	train_accuracy: 85.8020, accuracy_top-1: 79.4200, accuracy_top-5: 95.2200
2022-11-21 06:11:42,904 - mmcls - INFO - Epoch [196][100/391]	lr: 7.383e-03, eta: 0:02:14, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.8213
2022-11-21 06:11:51,652 - mmcls - INFO - Epoch [196][200/391]	lr: 7.106e-03, eta: 0:02:06, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.9858
2022-11-21 06:12:00,416 - mmcls - INFO - Epoch [196][300/391]	lr: 6.825e-03, eta: 0:01:59, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7678
2022-11-21 06:12:10,389 - mmcls - INFO - Epoch(val) [196][79]	train_accuracy: 86.4500, accuracy_top-1: 79.9200, accuracy_top-5: 95.5600
2022-11-21 06:12:21,151 - mmcls - INFO - Epoch [197][100/391]	lr: 6.272e-03, eta: 0:01:45, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.8957
2022-11-21 06:12:30,055 - mmcls - INFO - Epoch [197][200/391]	lr: 5.974e-03, eta: 0:01:38, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.9340
2022-11-21 06:12:38,832 - mmcls - INFO - Epoch [197][300/391]	lr: 5.669e-03, eta: 0:01:31, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7688
2022-11-21 06:12:48,679 - mmcls - INFO - Epoch(val) [197][79]	train_accuracy: 87.2880, accuracy_top-1: 80.5900, accuracy_top-5: 95.7700
2022-11-21 06:12:59,369 - mmcls - INFO - Epoch [198][100/391]	lr: 5.066e-03, eta: 0:01:17, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.8043
2022-11-21 06:13:08,280 - mmcls - INFO - Epoch [198][200/391]	lr: 4.738e-03, eta: 0:01:10, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.7179
2022-11-21 06:13:17,047 - mmcls - INFO - Epoch [198][300/391]	lr: 4.399e-03, eta: 0:01:03, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.7907
2022-11-21 06:13:26,943 - mmcls - INFO - Epoch(val) [198][79]	train_accuracy: 86.7420, accuracy_top-1: 80.3500, accuracy_top-5: 95.5900
2022-11-21 06:13:37,570 - mmcls - INFO - Epoch [199][100/391]	lr: 3.718e-03, eta: 0:00:49, time: 0.106, data_time: 0.021, memory: 1669, loss: 0.9482
2022-11-21 06:13:46,214 - mmcls - INFO - Epoch [199][200/391]	lr: 3.338e-03, eta: 0:00:42, time: 0.086, data_time: 0.001, memory: 1669, loss: 0.9551
2022-11-21 06:13:54,872 - mmcls - INFO - Epoch [199][300/391]	lr: 2.938e-03, eta: 0:00:34, time: 0.087, data_time: 0.001, memory: 1669, loss: 0.8838
2022-11-21 06:14:04,681 - mmcls - INFO - Epoch(val) [199][79]	train_accuracy: 85.5500, accuracy_top-1: 80.7700, accuracy_top-5: 95.6900
2022-11-21 06:14:15,419 - mmcls - INFO - Epoch [200][100/391]	lr: 2.096e-03, eta: 0:00:21, time: 0.107, data_time: 0.021, memory: 1669, loss: 0.7616
2022-11-21 06:14:24,280 - mmcls - INFO - Epoch [200][200/391]	lr: 1.588e-03, eta: 0:00:13, time: 0.089, data_time: 0.001, memory: 1669, loss: 0.8674
2022-11-21 06:14:33,107 - mmcls - INFO - Epoch [200][300/391]	lr: 9.891e-04, eta: 0:00:06, time: 0.088, data_time: 0.001, memory: 1669, loss: 0.9319
2022-11-21 06:14:41,066 - mmcls - INFO - Saving checkpoint at 200 epochs
2022-11-21 06:14:43,057 - mmcls - INFO - Epoch(val) [200][79]	train_accuracy: 86.2740, accuracy_top-1: 80.9000, accuracy_top-5: 95.7100
